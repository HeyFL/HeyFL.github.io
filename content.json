{"posts":[{"title":"","text":"蔡振谦的个人简历 联系方式 手机：13682540660 Email：361389383@qq.com 微信号：13682540660 博客: https://heyfl.github.io 个人信息 姓名性别年龄：蔡振谦/男/31 学历：吉林大学珠海学院/统招本科/软件工程 工作年限：8年 期望职位：Java开发/Leader 期望行业: 互联网/金融 期望城市：深圳 语言能力: 粤语&amp;普通话 自我描述 本人曾就职于顺丰科技有限公司,目前在团队中进行过多套公司核心系统研发工作,主要优势: 有较丰富的高可用、高并发、大数据量的大型分布式中台系统及ToC系统研发经验 参与过顺丰2套核心系统(共11套)的研发工作 多次为系统实现降本增效目标，大幅提高系统性能、降低资源使用情况 有基于敏捷开发的7人小团队Leader经验 曾为部门预备架构师有较好的架构设计能力 工作经历 顺丰科技有限公司(正编) （ 2019年11月 ~ 2022年12月 ） 任职于顺丰科技有限公司核心团队-OMS研发部，该部门主要负责公司物流数据中台相关服务，提供公司数十亿级订/运单承载、存储、分发、实时查询等一系列科技核心服务； 项目为基于SFDubbo(Spring+dubbo)与SFOpen框架搭建的服务体系项目，服务之间通过Kfk、http、dubbo通讯，核心查询服务QPS&gt;3w； 在该部门主要负责中台系统的需求分析、设计开发、重构、优化，并选择合理的方案实现核心难题 项目亮点/难点: 集团数据中台，读写要求很高 保证系统的高可用性（异常补数、故障自动恢复、灰度发布、上线前后验证方案） 保证系统的高吞吐（本地缓存、系统性能优化、系统性能监控、系统性能预警） 存储要求高，数据量大（数据压缩、数据分库、数据倾斜） 缓存/并发消费的一致性/顺序性要求较高（分布式锁、版本号、redis lua脚本等） 大数据查询（ES、Hbase、Hive） 为全科技11套核心系统中的2套系统进行了业务开发、重构优化、架构设计等工作，包含并不仅限于: 查单性能提高90%(ES查询耗时降低90%,ES查询量降低99.8%;ES内存负载降低85.7%,CPU降低50%) OMS数据库数据倾斜解决(由根据城市生成分库号,改成完全随机) Redis缓存压缩减少70%存储(且存取耗时有一定的提升,21年双十一节约14.5T内存) 通过熔断降级（合理使用配置）提高外部系统无响应时的系统可用性 Hbase region数据倾斜导致的超时问题(设定新RowKey规则) Hbase数据压缩,解决Region数过多,占用存储过多问题(新数据region分区数减少越80%至3000+) 防止暴力调用设计（防爬） 灰度上线设计（消息中间件消费端AB分流、接口分流） 零拷贝技术优化优化转发型文件下载效率 深圳市递四方信息科技有限公司 （ 2017年09月 ~ 2019年9月 ） 递四方信息科技有限公司(阿里系,跨境物流),目前团队中作为TeamLeader/预备架构师 项目为基于SpringCloud框架微的服务体系项目，通过Jenkins构建发布到对应服务器，服务之间通过RabbitMQ、http、dubbo通讯； 在该部门主要负责GRID产品线/G2G产品线的需求分析与设计，并选择合理的方案实现核心难题。 期间,自发为部门开发共用模块/优化,包含但不仅限如下: 1. 基础依赖: 1. 统一的业务异常/系统异常 2. Http统一的返回对象 2. Redis分布式锁工具类 3. 基于Redis的幂等注解 4. 消息级延迟补偿 5. MQ预警&amp;手动迁移服务 6. 统一异常处理(统一解决了异常日志输出及返回问题) 7. 统一国际化工具类(减少了团队对[前端]请求的后端国际化的工作量) 其他 定义异常处理/抛出规范 定义Consul配置规范(减少发版比对时的困难) 定义RabbitMQ在SpringBoot下的队列定义规范 其他一些研发规范 北京思特奇信息技术股份有限公司 （ 2015年04月 ~ 2017年08月 ） 为基于dubbo+zk+nginx的前后分离、动静分离的项目，前端平台化，通过Nginx反向代理到多个不同业务的微服务化后端中，服务之间通过dubbo通讯； 负责新系统-联通业务平台，作为其主研发及其运维 技能清单 以下均为我使用的技能 精通Java、熟悉JVM： 熟悉各种集合使用及其原理，熟悉jvm内存结构、java内存模型，熟悉各种垃圾回收算法与回收器并可以适当进行调优，通读《深入理解Java虚拟机》 熟悉常见数据结构与算法： 熟悉常见数据结构、算法的优缺点及其使用场景 精通Spring： 通读getBean、AOP、事务、MVC、整合Mybatis等源码，理解原理，并能进行二次开发、扩展 熟悉常见高可用上线方案 熟练使用灰度发布方案，并有较多的实践经验：如面向前端、普通后端服务、面向消费端服务等 熟悉常见SpringCloud等微服务框架： 熟悉熔断、降级、Feign等使用 熟悉使用及了解常见MQ ，Redis原理： RabbitMQ，消息路由，延迟队列，独占队列，事务消息，消息不丢，顺序消费等 Kafka的分区、消费 熟练使用常见Redis数据结构，理解Redis线程模型，熟悉缓存一致性等方案 熟悉MySQL： 理解MVCC，事务及其实现原理 熟悉Zookeeper/dubbo 熟悉SVN/Git/Jenkins 理解分布式事务 理解常见大数据技术并有一定的使用与优化经验 使用ElasticSearch、Hbase、Flink等并有一定的理解，同时对Hbase与ES的项目应用有过优化经验 致谢 感谢您花时间阅读我的简历，期待能有机会和您共事。 更多具体项目见博客: 附录","link":"/about/about.html"},{"title":"附录","text":"附录 对应项目经验 顺丰OMS产品线(订/运单) [订/运单中台系统] OMS为公司的订单/运单业务中台系统，承接B类客户（BSP）与C类客户（CX）的所有订单，以及其他所有大网相关的运单数据，提供补充、分发、实时查询服务 包括以下系统 OMS订单服务（主） OMS运单服务 订单、运单查询服务 难点、亮点 在尽可能不改代码的情况下，实现对上下游新增字段的支持 保证系统的高可用性（异常补数、故障自动恢复、灰度发布、上线前后验证方案） 保证系统的高性能（系统性能优化、系统性能监控、系统性能预警） 个人在项目职责： 系统存储、性能优化、系统升级设计 其核心业务模块(订单、查询服务)的详细设计/开发/对接 系统故障分析排查处理 提高系统容错性可用性 顺丰SISP产品线 [ToC端系统] SISP产品线原为公司面向客服、仓管人员的包裹信息查询系统，为期提供一站式服务。后扩展承接OMS产品线的订运单查询服务后，为公司内部提供一系列实时的订、运单查询服务。 个人在项目负责： 以动静分离+业务切分部署的方式升级重构老的单体SISP服务 系统故障分析排查处理 日常业务开发、多部门新业务模块协调开发 提高系统容错性可用性 顺丰BSP产品线(协助重构) [企业B类客户下单系统] BSP为公司主要的订单以及收入来源, 该系统为公司的核心系统, 但是由于历史原因, 系统的可维护性和可扩展性较差, 该系统的重构工作主要是为了提高系统的可维护性和可扩展性, 以便于后续的业务扩展和系统升级 协助重构BSP系统，主要协助负责梳理BSP系统的业务逻辑，对BSP系统进行重构，提高系统的可维护性和 可扩展性 项目重构目的: Oracle转Mysql 框架升级为SF微服务框架(SFOpen) 删除冗余代码、删除0流量的业务 系统性能优化 递四方G2G产品线(启运仓相关) 项目描述 跨国部署的微服务体系，含2个业务项目 : G2G仓内运营调度系统 主要是解析处理调度系统下发的任务单，拆分为对应的作业单下发给下游的作业系统并反馈操作结果 G2G仓内作业系统 主要是对上游下发的作业单进行作业，并且反馈操作结果 个人在项目职责(Leader)： 系统的架构设计 其核心模块(预报/调度分发/结果回传/数据权限等)的详细设计/开发 递四方末端GRID产品线(包括接单/调度/运营/门店作业部分) 项目描述 跨国部署的微服务体系，含4个业务项目（主要） : 接单平台 调度中心 运营中心 作业系统（提供门店PC端，派送揽收APP端服务） 个人在项目职责： 负责核心模块(下单/其他接单系统与客户系统对接的预报/共用模块) [参与]系统的架构设计 思特奇联通业务支撑平台 项目描述 联通内部员工使用的交尾正统的分布式业务受理系统，包括：业务受理、IT 需求、调账管理、销售支撑、产品管理、系统管理、经营分析等；技术体系包含: 大概技术:Nginx+Keepalive+zookeeper+工作流 +共享session单点登录+类似SpringMVC+Spring+Ibatis/Mybatis+Maven 个人在项目职责 业支-调账管理模块: 分析设计开发、产品管理模块的维护 业支系统前台整体架构 与 后台整体架构维护、改造","link":"/about/about2.html"},{"title":"生产故障分析：线程池配置错误导致的阻塞问题","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Bug-Log-Optimization/thread-pool-use-error.html 在生产环境中，我们遇到了一个由线程池配置错误导致的阻塞问题。本文将对这个问题进行详细分析，并提出相应的解决方案。 问题背景 后端在接收到前端用户请求后，会将请求分成4个线程交给一个线程池处理。这4个线程分别负责请求不同的查询接口，以获取查询结果。最后，将这些结果合并并同步返回给前端用户。 12345678910111213141516// 提交任务到线程池waybillNoQueryFuture = submitTask(waybillNoQueryService, waybillNo, currentUserName)orderInfoQueryFuture = submitTask(orderInfoQueryService, waybillNo, currentUserName)appointmentQueryFuture = submitTask(appointmentQueryService, waybillNo, currentUserName)operationWaybillQueryFuture = submitTask(operationWaybillQueryService, waybillNo, currentUserName)// 获取任务结果waybillNoDto = waybillNoQueryFuture.getResult()orderInfoDto = orderInfoQueryFuture.getResult()appointmentDto = appointmentQueryFuture.getResult()operationWaybillDto = operationWaybillQueryFuture.getResult()// 合并结果并返回给前端用户result = mergeResults(waybillNoDto, orderInfoDto, appointmentDto, operationWaybillDto)return result 相关线程池基本原理 Java线程池（ThreadPoolExecutor）是一种基于线程的Executor框架，它主要用于管理并行执行的任务。线程池中的线程会被复用，从而降低了线程创建和销毁的开销 线程池的主要组成部分包括： 核心线程数（corePoolSize）：线程池中始终保持的线程数量 最大线程数（maximumPoolSize）：线程池中允许的最大线程数量 工作队列（BlockingQueue）：用于存放待处理任务的队列当线程池中的线程数量达到核心线程数时，新的任务会被放入工作队列中等待执行 拒绝策略（RejectedExecutionHandler）：当线程池中的线程数量达到最大值，并且工作队列已满时，新的任务会触发拒绝策略 线程池队列的作用是在线程池中的线程数达到核心线程数时，将新的任务暂存起来，等待空闲线程来处理 如果工作队列长度设置得过短，当线程池中的线程数达到核心线程数，并且工作队列已满时，新的任务将触发拒绝策略 不同的拒绝策略会有不同的处理方式，例如抛出异常、丢弃任务等 问题分析 线程池配置错误 在这个案例中，线程池的配置出现了错误。线程池的等待队列长度被错误地设置为1： 1234corePoolSize = 10; maxPoolSize = 20; queueCapacity = 1;createThreadPool(corePoolSize, maxPoolSize, queueCapacity, rejectionPolicy); 由于线程池等待队列长度设置过小，每当前端发来一个请求，同时向线程池提交4个任务时，就会超过队列长度。这导致触发了线程池的拒绝策略。在这个案例中，拒绝策略的设置是什么都不做。 1234rejectionPolicy = (task, executor) -&gt; { // 什么都不做，丢弃任务，记录日志 log.error(&quot;Task rejected&quot;); }; } 因此，主线程无法获得任务执行结果，从而导致一直阻塞。 解决方案 方案1 为了解决这个问题，可以考虑调整线程池的配置，将等待队列长度设置为一个合理的值，以避免触发拒绝策略 12// 调整队列长度 queueCapacity = 50; // 或 100 方案2 修改拒绝策略 1234567rejectionPolicy = (task, executor) -&gt; { // 线程池繁忙，记录日志，提交让主线程处理 logger.info(&quot;thread pool is busy-&gt;{},{}&quot;, executor.getPoolSize(), executor.getQueue().size()); if (!executor.isShutdown()) { task.run(); }} 总结 这次分享了一个由线程池配置错误导致的阻塞问题，并给出了相应的解决方案。 在实际开发中，我们应当注意合理地配置线程池参数，并加强应用监控，以避免类似问题的发生。 理解线程池的原理和配置参数对于合理地利用线程池资源至关重要。在实际项目中，应该根据业务需求和系统资源来设置合适的线程池参数，以保证系统的稳定运行和良好性能。","link":"/Bug-Log-Optimization/thread-pool-use-error.html"},{"title":"Spring-Cloud服务在Consul中的异常注册","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Bug-Log-Optimization/bug_in_spring-cloud_instance_registered_with_consul.html 优雅停机脚本见: shell-系统优雅停机 背景 公司实现微服务化并原来使用的Dubbo+Zookeeper实现应用间的服务调用，考虑到Dubbo不在维护最近想要切换为Spring Cloud+Consul 环境 Spring Cloud: Edgware.SR3 Spring-boot: 1.5.13.RELEASE 12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.13.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.SR3&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 根据网上流传的博客我们使用的配置为: 1spring.cloud.consul.discovery.instance-id=${spring.application.name}-${server.port} 也就是【服务名】+【端口】的形式来标识Consul上的一个服务 1. 第一个问题 已注册上Consul的服务被后启动的提供者覆盖(采用【服务名】+【端口】的形式) 在我们实际开发测试时候发现 无论服务起了多少个实例，最终展示到Consul都只有一个 : 怀疑是Consul以【服务名】+【端口】为实例的唯一标示，导致【后起来的服务】覆盖掉【原来已经注册到Consul上的服务】了 ，我们通过Feign调用时发现也确实是如此 1.1. Kill 第一个问题 上Spring官方文档轻松找到解决方案(有问题还是官方文档好) 1${spring.application.name}:${vcap.application.instance_id:${spring.application.instance_id:${random.value}}} 原理就是每次启动时注册的实例ID都为【服务名】+【随机数】： 通过这种形式，可以让每一个服务提供者（实例）都有效地注册到Consul上，并且Consul上的每一个Instance都能唯一映射到每一个提供者上 2. 第二、第三个问题 2.1. 服务器通过Kill -9的重启脚本快速重启导致一个提供者在Consul上注册了多次(Consul注册的实例数&gt;实际提供者数) 首先，我们要知道当系统执行kill-9命令的时候会立马强制关闭该进程，程序很可能正在处理请求中，同时也占用了一些的资源，本来需要做一些善后才能正常、安全的结束，但是你一个 kill-9命令过来，程序就措手不及了。 结合上述情况，实际上程序非正常重启，已经注册在consul上的服务没有被反注册，服务重新启动之后又重新的注册了一个新的服务上去了（而且重启后以前的服务在Consul心跳机制下海认为是可用的），一个服务就在Consul注册了多次了 这种情况可以修改重启脚本解决： 通过Kill -15直接关闭提供者进程 可以参考这篇文章 2.2. 【服务名】+【随机数】的InstanceID不能提供足够信息帮助我们快速定位问题 上面的方案可以解决我们遇到的问题，但是有一点不足的是，Consul上看到的InstanceID都是【服务名】+【随机数】，随机数没有可读性可言， 我们压根不能根据这个InstanceID一眼看出的它的服务提供者是谁。不便于我们排查问题 进一步优化 其实最好就是使用【服务名】+【机器IP】+【端口】的形式，这样既能通过唯一标示服务提供者解决 Consul服务被覆盖的问题 也能方便我们运维开发时快速知道当前服务的提供者列表，快速定位问题 最终方案 1spring.cloud.consul.discovery.instance-id=${spring.application.name}:${spring.cloud.client.ipAddress}:${server.port}","link":"/Bug-Log-Optimization/bug_in_spring-cloud_instance_registered_with_consul.html"},{"title":"数据库数据倾斜","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Bug-Log-Optimization/database-skew.html 其实改动不是很大，这里简单记录下 背景 OMS订单系统，日数据量较大平均近3kw/日,高峰达8kw+/日的订单需要存到数据库中（之前64库，现在扩到了128库）； 运维后台监控看到，各个库的压力不一，江浙沪，京津冀，深圳755等地区对应的数据库压力很高，而其他地区的数据库压力很低； 分析 数据库通过mycat，以分库号字段进行分库，以内部订单号分表 内部订单号规则： 3位分库号+系统来源（2位）+MMDDHHmmssSSS+订单类型+6位随机数+1位校验码=26位 分库号生成规则为根据地区、网点进行生成； 因此，可以看出，同一地区的订单，分库号是一样的，因此，同一地区的订单，会落在同一个库中； 解决 直接粗暴修改分库号生成规则为0~127区间随机生成，因为原有订单的删、改、查最终都会带上原有的内部订单号，所以不会影响到历史数据，只是新的订单会落在不同的库中； 上线方案 因为是S级系统，上线加了开关，如若有问题，可以快速回滚，因为是中台消费者系统，期间如果出问题的数据通过关闭开关+kfk重置偏移量解决。 上线后效果 （此处应有截图）","link":"/Bug-Log-Optimization/database-skew.html"},{"title":"缓存密集加载导致数据库崩溃问题","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Bug-Log-Optimization/cache-load-database-crash.html 背景 SISP自己基本不存储业务数据，但是每个节点都需要本地缓存了一些网点、员工信息、月结用户信息等基础数据，生产监控发现数据库定期压力飙升，数据库CPU压力到达80+%如图： 用脚趾头分析 从图中可以看出，每天小时飙升一次，明显就是定时任务大批量查询数据库导致的，在SISP系统，也就只有加载缓存可能会导致 找到运维获取慢日志，发现大量的查询语句，如下： 12345SELECT DISTINCT nd.division_code AS city_code, nnd.dist_cn_name , nnd.dist_en_name FROM tm_new_district nd, tm_new_district nnd WHERE nd.division_code IN( SELECT DISTINCT t.CITY_CODE FROM tm_department t,tm_district d WHERE t.DIST_CODE = d.DIST_CODE AND t.DELETE_FLG = 0 AND d.DIST_NAME LIKE '%/%' )AND nnd.dist_code = nd.city_code 因为是单库，数据量也大，单条sql查询耗时近40s，因此，大量查询导致数据库压力飙升 解决 解决手段1：缓存刷新时间分散开，错峰加载缓存 因为是通用方法，这里8分钟内刷新一次的小任务就忽略了。我们对大于8分钟的任务，增加了随机时间间隔，如下代码所示（其中delayPercent = 0.2，表示随机减少时间定时任务0~20%的间隔时间）： 123456789101112131415161718192021/** * 将日期加上一个随机的时间间隔 * @param date 原始日期 * @return 计算后的新日期 */private Date scheduleTimeAddRandom(Date date) { // 获取当前时间戳 long now = System.currentTimeMillis(); // 计算初始时间间隔 long initialDelay = date.getTime() - now; // 获取当前线程的随机数生成器 ThreadLocalRandom random = ThreadLocalRandom.current(); // 对于间隔超过8分钟的任务，随机减少一部分时间间隔 if (initialDelay * delayPercent &gt; (8 * 60 * 1000 * delayPercent) &amp;&amp; initialDelay &gt; 0) { initialDelay = initialDelay - random.nextLong((long) (initialDelay * delayPercent)); } // 计算最终的下次执行时间 Date nextExecuteTm = new Date(now + initialDelay); return nextExecuteTm;} 解决手段2： 优化慢查询sql 重新梳理业务逻辑，其实我们只是需要城市代码对应的多城市名而已，其在tm_new_district中就有了，只是我们没有从上游上同步到我们数据库罢了。 同步完对应表字段后，完全不需要连接表，用一条简单sql就可以了，新的SQL： 1SELECT DIST_CODE, DIVISION_CODE, CITY_CODE, dist_cn_name,dist_en_name FROM tm_new_district t WHERE t.division_code IS NOT NULL 新的sql查询耗时只有不到1s，因此，大量查询导致数据库压力飙升的问题得到了解决 上线后优化效果 优化前CPU压力图（单节点）： 手段1优化后： 结合手段1、手段2，优化后： 结论 经过优化后，数据库压力得到了很大的缓解，突发峰值也基本消失；应用CPU压力也从原来的15%降低到3%左右，整体系统性能得到了很大的提升。 结语 这次分享了：缓存短时间密集加载与sql慢查询（姑且算是吧）的处理。算是很经典的问题了，到处都会遇到，希望能帮助到大家。","link":"/Bug-Log-Optimization/cache-load-database-crash.html"},{"title":"分布式事务解法","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Distributed/How-To-Use-Distributed-Transaction.html 可搭配参考我的GitHub: 分布式事务.xmind 参见分布式事务有哪些 1. 基于XA协议的全局事务 (强一致性) 使用情况：一个工程对多个数据源（数据库需要支持XA协议） 基本功能：数据库时间功能+开源组件（知名的分布式事务管理器主要有atomikos、bitronix、narayana。其中，仅atomikos支持XA和TCC两种机制，bitronix、narayana仅支持XA机制。） 原理：2PC/3PC 单服务多数据库使用全局事务 缺点：XA协议比较简单，成本较低，但是其单点问题，以及不能支持高并发(由于同步阻塞)依然是其最大的弱点(主要),2PC本身的缺陷也是一方面原因(次要)。 2PC &amp; 3PC 2PC是两阶段提交协议（Two-Phase Commit） 它保证了所有参与节点在一个事务中要么全部提交，要么全部回滚。2PC有很高的可靠性和一致性，但需要进行两次网络通信和等待，从而导致性能上的一定损失。2PC适用于对事务强一致性要求高的系统，例如银行转账等 3PC是三阶段提交协议（Three-Phase Commit） 它在2PC的基础上增加了一个阶段，以减少等待时间和网络开销。3PC需要的网络通信比2PC更少，因此在性能方面略优于2PC。3PC适用于对事务一致性要求高，但是对性能有一定要求的系统，例如电子商务、在线游戏等 2PC &amp; 3PC区别 2PC(canCommit、doCommit): 只有协调者有超时机制，超时后，发送回滚指令 3PC(canCommit、preCommit、doCommit)：协调者和参与者都有超时机制 协调者触发超时：向所有参与者发送中断指令 参与者触发超时：当前为pre阶段进行中断，当前为do阶段进行提交 2PC &amp; 3PC使用场景 2PC协议是最基本的分布式事务协议，包含了准备阶段和提交阶段。相较于3PC协议，2PC协议的实现较为简单，且在正常情况下的事务处理效率较高。然而，2PC协议存在阻塞问题，即当协调者失效时，参与者会一直阻塞等待，从而影响整个系统的性能 3PC协议在2PC协议的基础上增加了一个回滚阶段，可以更好地解决2PC协议存在的阻塞问题，同时也能够避免由于一方的失败导致整个事务的失败。然而，3PC协议的实现较为复杂，且在异常情况下的处理效率相对较低 因此，对于对可靠性要求较高的系统，可以选择3PC协议；对于对效率要求较高的系统，可以选择2PC协议 2. TCC(强一致性) 使用情况：多系统 多数据源 原理：编程式事务，每个业务都要开发try，confirm，cancel 3个方法实现 try-&gt;调用所有服务,把所有资源设置为中间状态(如订单设置为支付中,库存设置为冻结) confirm-&gt;把所有资源状态设置为完成(支付完成) cancel-&gt; 把所有资源状态回滚回try前 缺点：程序复杂度高，confirm、cancel方法需要实现幂等 3. 基于可靠消息服务的分布式事务–MQ消息队列(最终一致性) 使用情况： 多系统 多数据源 原理：利用本地事务及MQ的事务消息（其实也不一定要用），确保本地事务未完成、消息发送出去；理想地认为对方一定能正确、成功消费消息； 缺点： 数据有一小段时间不一致 对方系统出现问题，不能正常消费信息，导致数据长期不一致 4. (最大努力通知)基于[不可靠]消息服务的分布式事务–MQ消息队列(最终一致性) 使用情况： 多系统 多数据源 原理：通过MQ延迟队列等实现的延迟通知服务, 通知服务会每隔1,5,10,30分钟重复通知 , 到达最大通知次数后, 需要人工通知或重置重试次数 优势(比基于可靠消息服务的分布式事务) 允许消费方短期异常(通过1,5,10,30分钟的间隔重试) 缺点： 数据有一小段时间不一致 对方系统出现问题，不能正常消费信息，导致数据长期不一致 编码比基于可靠消息服务的分布式事务复杂一些,需要实现延迟队列、自产自销+Http请求等实现重复通知 分布式事务选型 分布式事务选型主要要看场景，我们以流量充值作为例子 流量充值涉及到订单支付 金钱交易严格用tcc 订单支付完后要给用户增加积分 这种情况这个必要成功（毕竟是内部系统），用最终消息一致性方案就行了; 订单支付完后还要给用户发送一条短信 短信一般是跟电信运营商的第三方接口对接，有可能成功有可能失败，用最大努力通知方案(每隔1,5,10,30分钟重复通知 直到达到最大重试次数)","link":"/Distributed/How-To-Use-Distributed-Transaction.html"},{"title":"Kafka整理","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/MQ/kafka-remark.html kafka为什么快 1. 通过生产和缓冲区减少网络开销 生产者发送消息时，会将多条消息打包为一个batch（发送缓冲区）一起发送，等缓冲区大小达到阈值或者一定时间，批量发送 2. 根据不同ack配置，可以不刷盘、少刷盘就响应ack ack=0 生产者发送消息后，不会等待Broker的响应，不保证消息是否到达Broker ack=1 生产者发送消息后，等待Leader Broker接收到消息后，返回ACK响应。 acks=all或acks=-1 生产者发送消息后，等待Leader Broker接收到消息，并且等待其他所有副本都成功复制消息（落盘），才会返回ACK响应。 注 节点接收到数据后不会立马刷盘，会先暂存到pagecache里，等到一定的大小或者时间后才会刷盘 3. 零拷贝 正常IO需要经过5次读写才能从磁盘读取数据发送给消费者 零拷贝可以实现内核态之间硬件的数据拷贝，只需要2~3次IO，尽可能不需要经过应用态，减少了2-3次非必要IO，也减少了用户态内核态的切换 kafka实现延迟队列 1. 分级主题循环等待 正常生产，消费时如果时间不到，丢回队尾 一般采用相同（如10分钟）级别的delayed-messages，以免前面的消息堵塞后面的数据 2. 生产者方延迟发送消息 生产者生产延迟消息丢到第三方存储 如Redis/RocksDB中，再启动异步线程任务将过期消息丢到目标主题完成延迟消息的消费 顺序消费 1. 单个分区+单个消费者 问题：慢 2. 多个分区+多个消费者 借助partitioner，把有先后顺序的同个业务单分到同个分区消费 需要注意的问题 阻塞问题 消息处理失败最好不要在消费时候重试或者等待，以免阻塞后面的数据 如：消息消费时，先查一下重试表有没有这个单号的数据，没有就正常消费，否则保存到重试表让重试逻辑自己处理 处理积压数据 各个partition数据分布不均 各个partition数据分布不均，个别因为数据分区规则导致个别partition数据量很大，而一些又很小 优化分区规则，如：把分区号由城市改为订单号 消息体过大、非必要消息量过多，导致IO问题（kfk2次网络IO，2次磁盘IO） 优化消息体与减少消息量 因为促销等业务高峰原因 1. 消费时改为多线程消费 2. 改代码: 消费并发布到新主题，新主题的分区数为原来的3倍 原业务代码开3倍的消费者消费新的主题 慢，麻烦，有风险，需要新机器*2 3. 消费者用高性能机器替换 这里以后最好可以做好风险预案，做动态线程池 保证消费数据不丢失 1. 生产者 ack!=0，确保至少落到Leader Borker的磁盘后才给生产者ack 2. 消费者 保证至少是At-least-once消费模式 1. at most onece模式 禁用自动提交偏移量 接收到消息立马ack，然后再处理 2. at least once 禁用自动提交偏移量 接收到消息先处理，再提交偏移量 3. exactly once 禁用自动提交偏移量 处理消息 &amp; 提交偏移量 &amp; 保存消息id信息到第三方存储 注: 需要在同一个分布式事务管理器 补数 配置上(重置偏移量) 消费者配置中，KafkaConsumer 类的 setProperty 方法设置『auto.offset.reset』配置： earliest，重头消费 lastest，从当前消费（默认） none，当前消费者组没有偏移量，报错 业务上 重置偏移量 上游重发 将需要补数的数据暂存到其他新主题，或外部存储，后续用特殊新逻辑重新消费 自动提交偏移量(enable.auto.commit) 默认打开 在默认情况下，消费者会在每隔 5 秒钟的时间内将最近一次已消费消息的偏移量提交给 Kafka 服务器 auto.commit.interval.ms 如何保证高可用 多副本数据冗余，保证数据『高可用』读写 ISR（In-Sync Replicas）机制，只有同步了Leader的副本才可以参与读写，保证了数据的『一致性』 zk保证broker的『可用性』，当broker上下线、宕机，可以实现『分区自平衡』 持久化机制 leader机制，kafka一个分区有一个leader+多个follower副本，leader负责读写，故障会选举出follower作为新的leader","link":"/MQ/kafka-remark.html"},{"title":"MQ常见问题及其处理方案","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/MQ/mq-common-problem.html 基于Rabbitmq：","link":"/MQ/mq-common-problem.html"},{"title":"线上ElasticJob堵塞问题排查","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Bug-Log-Optimization/elasticJob-bug-fix.html 背景 刚进新公司3天正逢双十一，领导生产补数出问题了，补数速度不稳定时快时慢，百万条数据补了好几个小时，之前都是几分钟搞定的，导致通了个宵； 早上我早到公司，领导截了个数据库的图给我，说交给我来看，然后刚通宵完的他就去开会汇报去了。。。我还没来得及熟悉环境，就被扔到了火坑里了，压力山大。。。 具体的过程没记录,这里只能凭回忆记录下了 问题描述 给我的截图大概长这样： 数据库分库号 需要补数的运单数量 分库0 12345 分库1 0 分库2 0 … *** 分库31 0 分库32 0 分库32 5w 分库33 4w 分库34 8w … *** 分库128 8w 知道的太少，跟同事了解业务,其实补数就是重推数据,把需要重推的单号记入表中,然后通过ElasticJob定时任务消费表中数据，实现重推数据 问题分析 没用过ElasticJob这类定时任务组件，先通过现象分析，发现分库32-128的数据都是好几w条，而且分库0-31的数据都是0，这就很奇怪了； 查看配置sharding-total-count=16，看现象猜测是只有一个分片在跑，且一轮跑16个分片，跑到第二轮； 问题分析 因为实在不熟悉定时任务组件逻辑，还是得去分析源码看原因才好解决问题； 看了下配置 12streaming-process=true sharding-total-count=16 streaming-process=true 代表流式处理； sharding-total-count=16 代表分片总数； 结合问题，猜测是只有一个分片在消费，且一轮跑16个分片，跑到第二轮； 查看流式计算源码发现流式计算逻辑其实是: 各个节点接收任务 切分16个分片,当前节点只消费一个分片 所有分片处理完后,分发触发下一(16个分片)次的任务 而我们系统对每个分片的处理实际上也是流式的,大致代码如下: 123while(fetchData()){ processData()} fetchData()每次获取200条数据，如果有数据就进行重推，直到结束； 结论 那么问题就很明显了，研发人员把重推任务设置为流式处理，但是每次重推只处理200条数据，导致每个分片处理完后，分发下一轮任务； 但是在第二轮任务因为这某个节点分片数据量很大，导致其他节点早就处理完了，而这个节点的数据迟迟处理不完，任务一直结束不了一直在等待这个分片的完成，消费效率滑坡； 处理方案 流式计算加入超时机制，每个分片最多只能处理一段时间，超过后就结束本次任务，分发下一轮任务 放弃流式计算，缩短定时任务间隔 这里推荐方案1，不过最终团队选择方案2，实现比较简单。。。","link":"/Bug-Log-Optimization/elasticJob-bug-fix.html"},{"title":"消息中间件-Rabbitmq","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/MQ/mq-rabbitmq.html RabbitMQ是一款开源的消息中间件，采用AMQP（高级消息队列协议）作为底层协议，提供了可靠的消息传递机制、灵活的路由方式以及多种消息发布/订阅模式等特性，被广泛应用于分布式系统、微服务架构等场景中 数据发布方式 RabbitMQ支持多种消息发布方式，主要包括以下几种： 1. P2P（点对点）模式 P2P模式是最简单的消息发布方式，即消息生产者直接将消息发送到指定的队列中，消费者通过消费该队列中的消息来获取数据 2. 发布/订阅模式 发布/订阅模式是指生产者将消息发送到一个交换机（exchange）中，而消费者则创建一个或多个队列并绑定到该交换机上，从而获取该交换机中的消息 在发布/订阅模式中，可以使用Fanout类型的exchange，该类型的交换机将消息广播给所有绑定到该交换机上的队列 3. Routing模式（路由模式） Routing模式是指生产者将消息发送到一个Direct类型的交换机中，交换机将消息交给符合指定routing key的队列来处理。routing key通常是一个字符串，可以是任何内容，但通常用于表示消息的类型、来源等信息 4. Topic模式（主题模式） Topic模式是指生产者将消息发送到一个Topic类型的交换机中，交换机将消息给到相关的几条Topic，Topic可以使用通配符进行匹配 例如，可以使用&quot;item.#“表示能够匹配&quot;item.spu.insert&quot;或者&quot;item.spu”，而&quot;item.*“只能匹配&quot;item.spu” 节点 RabbitMQ节点分为内存节点和磁盘节点两种类型。其中，内存节点将消息存储在内存中，读写性能较高，但节点重启后消息会丢失； 而磁盘节点则将消息存储在磁盘上，读写性能相对较低，但具有消息持久化的特性，即节点重启后消息不会丢失 在RabbitMQ集群中，至少需要一个磁盘节点来存储元数据信息，否则节点重启后元数据将丢失 集群模式 RabbitMQ提供了两种集群模式，分别是普通集群模式和镜像集群模式 1. 普通集群模式 普通集群模式下，各个节点只保存所有的队列、Exchange、Virtual Host等元数据，不保存队列中的消息本身。这种模式可以降低存储压力，提高系统吞吐量，但不能实现系统的高可用性 如果某个节点崩溃，而且消息没有被持久化，那么将导致该节点下所有未被消费的数据丢失 2. 镜像集群模式 镜像集群模式下，集群中的每个节点都有一份元数据以及消息数据，读写只在master节点进行，master接收命令后会向slave节点进行组播，slave节点会按照命令执行顺序执行 这种模式通过数据冗余极强地提高了可靠性，可以极大地减少数据丢失的风险。但是，由于镜像队列需要为每个节点同步所有的消息实体，因此会导致存储压力变大，可能会出现网络带宽和IO瓶颈等问题 3. After All 普通集群模式和镜像集群模式分别具有不同的优势和问题: 普通集群模式可以降低存储压力、提高系统吞吐量，但不能实现系统的高可用性 而镜像集群模式可以提高可用性、可靠性，但需要消耗更多的存储空间、网络带宽和IO资源 在选择集群模式时，需要根据具体的业务场景进行综合考虑，并根据需求选择合适的部署方案","link":"/MQ/mq-rabbitmq.html"},{"title":"消息中间件-kafka","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/MQ/mq-kafka.html 1. 为什么 Kafka 快 1.1 通过生产和缓冲区减少网络开销 Kafka 的生产者发送消息时，会将多条消息打包为一个 batch（发送缓冲区）一起发送，等缓冲区大小达到阈值或者一定时间，批量发送，从而减少网络开销 1.2 根据不同 ack 配置，可以不刷盘、少刷盘就响应 ack ack=0：生产者发送消息后，不会等待 Broker 的响应，不保证消息是否到达 Broker ack=1：生产者发送消息后，等待 Leader Broker 接收到消息后，返回 ACK 响应 acks=all 或 acks=-1：生产者发送消息后，等待 Leader Broker 接收到消息，并且等待其他所有副本都成功复制消息（落盘），才会返回 ACK 响应 **注**: 节点接收到数据后不会立即刷盘，会先暂存到 pagecache 里，等到一定的大小或者时间后才会刷盘 1.3 零拷贝 正常 IO 需要经过 5 次读写才能从磁盘读取数据发送给消费者，而零拷贝可以实现内核态之间硬件的数据拷贝，只需要 3 次 IO，不需要经过应用态，减少了 2 次非必要 IO 2. 如何实现 Kafka 延迟队列 2.1 分级主题循环等待 对于正常生产，如果消费时间未到，则丢回队尾，等待下次消费 一般采用相同（如 10 分钟）级别的 delayed-messages，以免前面的消息堵塞后面的数据 2.2 生产者方延迟发送消息 生产者可以将延迟消息丢到第三方存储（如 Redis/RocksDB）中，再启动异步线程任务将过期消息丢到目标主题完成延迟消息的消费 3. 如何实现 Kafka 顺序消费 3.1 单个分区+单个消费者 简单的处理方案,但也存在致命问题:慢，吞吐低，而且容易因为脏数据出现阻塞问题 3.2 多个分区+多个消费者 借助partitioner，将有先后顺序的同个业务的单分到同个分区消费 解决了大部分的吞吐低的场景,但也需要注意阻塞问题： 消息处理失败最好不要在消费时候重试或者等待，以免阻塞后面的数据。如，消息消费失败时，存到重试表让重试逻辑自己处理 4. 如何处理 Kafka 积压数据 4.2 各个 partition 数据分布不均 各个 partition 数据分布不均，个别因为数据分区规则导致个别 partition 数据量很大，而一些又很小 可以优化分区规则，如：把分区号由城市改为订单号 4.3 消息体过大、非必要消息量过多，导致 IO 问题（Kafka 2 次网络 IO，2 次磁盘 IO） 可以优化消息体与减少消息量 4.4 因为促销等业务高峰原因 可以制定风险预案，做动态线程池： 消费时改为多线程消费 改代码： 消费并发布到新主题，新主题的分区数为原来的 3 倍 原业务代码开 3 倍的消费者消费新的主题 消费者用高性能机器替换 5. 如何保证 Kafka 消费数据不丢失 5.1 生产者 配置为ack!=0，确保至少落到 Leader Broker 的磁盘后才给生产者 ack 5.2 消费者 保证至少是 At-least-once 消费模式： 5.2.1 消费端消费模式 及其一般实现方式 at most once 模式： 禁用自动提交偏移量 接收到消息立即 ack，然后再处理 at least once 模式： 禁用自动提交偏移量 接收到消息先处理，再提交偏移量 exactly once 模式： 禁用自动提交偏移量 处理消息，提交偏移量，保存消息 ID 信息到第三方存储 注: 需要在同一个分布式事务管理器 6. 如何处理 Kafka 补数 6.1 修改```auto.offset.reset`` 重新消费 消费者配置中，KafkaConsumer 类的 setProperty 方法设置 auto.offset.reset 配置： earliest，重头消费 latest，从当前消费（默认） none，当前消费者组没有偏移量，报错 6.2 可以通过以下方式进行补数： 重置偏移量 上游重发 将需要补数的数据暂存到其他新主题，或外部存储，后续用特殊新逻辑重新消费 7. 如何保证 Kafka 高可用 多副本数据容易，保证数据『高可用』读写 ISR（In-Sync Replicas）机制，只有同步了 Leader 的副本才可以参与读写，保证了数据的『一致性』 zk 保证 broker 的『可用性』，当 broker 上下线、宕机，可以实现『分区自平衡』 持久化机制 Leader 机制，Kafka 一个分区有一个 Leader + 多个 Follower 副本，Leader 负责读写，故障会选举出 Follower 作为新的 Leader","link":"/MQ/mq-kafka.html"},{"title":"每天进步一点点（持续更新）","text":"[原创]这篇只是做点记录备忘，个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Make-A-Little-Progress-Every-Day/Make-A-Little-Progress-Every-Day.html 2022-10-25 目前本地缓存使用的方式 订运单系统： SF自研的类Ehcache框架，存储的内容不是特别多，都是一些网点月结卡号信息，所有对象存在于Map，占200m左右 SISP系统： 使用了Caffeine，存储的内容，存储的内容很多，包括员工表（900m），人员表（bdus 800m） 客户表（1.2g），用户及权限相关表（500m） 关联后约占4g内存，目前采用Caffeine默认存储方式，启动即全量加载（极个别采用懒加载方式加载），全部存在于Map中，即堆存储 优化: 缓存为基础数据，数据量稳定，目前采用CMS回收器，堆空间8g，缓存存于堆中，占约4g，平时MajorGC达4~6s，曾出现高峰gc达52s， 应考虑将缓存存于堆外，减少GC的压力，提升性能（风险点，可能会导致内存溢出） 后面自己论证时行不通...因为java对象存到堆外时需要额外进行序列化，经测试，这会导致对象明显变大，浪费的内存有点多，在降本增效的背景下是行不通的 参考 guava、caffeine、ohc（堆外缓存）详解 2022-10-20 Spring中最常用的11个扩展点 Spring中最常用的11个扩展点 2022-09-02 Hystrix熔断配置 为让Hystrix的熔断降级配置更加合理，会议讨论结果需进行如下优化， 为每个已有Hystrix熔断的接口设置最高并发配置（execution.isolation.semaphore.maxConcurrentRequests），配置200~500之间，具体计算方式 单节点线程数 = QPS /节点数/ ( 1000 / 被熔断方法的P99耗时ms ) 翻译：方法单节点线程并发数 = QPS /节点数/1s内该方法能执行次数 把Hystrix配置提取到disconf，重启生效，无需发版 QPS和RT的关系： 对于单线程：QPS=1000/P99 对于多线程：QPS=1000线程数量/P99 对于多线程多接点：QPS=1000单节点线程数量*节点数量/P99 2022-08-11 前端跨域请求减少Option请求 后端对CorsConfiguration配置Access-Control-Max-Age，前端请求时接收到Access-Control-Max-Age，在该有效时间内不会再发出Option请求 CorsConfiguration config = new CorsConfiguration(); config.setMaxAge(600L); 后端返回的Access-Control-Max-Age 大于浏览器支持的最大值 那么取浏览器最大值作为缓存时间 否则取后端返回的Access-Control-Max-Age作为缓存时间 缓存时间内不会再发option请求 源码 2022-06-03 POJO、JavaBeans、BO、DTO 和 VO 、DO之间的区别 POJO，也称为普通旧 Java 对象，是一个普通的 Java 对象，它没有对任何特定框架的引用。 JavaBean/BO：有约束的POJO，国内用法一般为BO 实现Serializable接口 将属性标记为private 使用 getter/setter 方法来访问属性 DTO：也称为数据传输对象，封装值以在进程或网络之间传输数据。 DTO 没有任何显式行为。它基本上有助于通过将域模型与表示层解耦来使代码松散耦合 VO：外国作为值对象，不过国内用法是用来做视图对象，主要是返回前端用的对象 DO(Data Object) ，持久化对象，数据库对象 2021-06-01 System.arraycopy方法和Arrays.copyOf() System.arraycopy方法：是本地方法，如果是数组比较大，那么使用System.arraycopy会比较有优势，因为其使用的是内存复制，省去了大量的数组寻址访问等时间 Arrays.copyOf() Arrays.copyOf()在System.arraycopy()实现的基础上提供了额外的功能 会创建新数组 允许与原数组类型不同，但是这样会调用JVM的反射，性能较差 2021-05-20 ES 分词 text：用于全文索引，该类型的字段将通过分词器进行分词，最终用于构建索引 keyword：不分词，只能搜索该字段的完整的值，只~~~~用于条件精准查询 通常情况都以 keyworkd 字段进行搜索，因为全文索引的分词器不一定能够完全分词，可能会导致搜索不准确，所以一般都是用 keyword 字段进行搜索 2021-02-26 HBASE 列族,RowKey HBase是一种面向列的数据库,以row+列名作为key，data作为value，依次存放 假如某一行的某一个列没有数据，则直接跳过该列。对于稀疏矩阵的大表，HBase能节省空间 表是行的集合 行是列族的集合 列族是列的集合 列是键值对的集合 2021-02-08 最近要搞懂的事情 MySQL、HBase、ES的特点和区别 redo log和checkpoint机制 单机情况下，MySQL的innodb通过redo log和checkpoint机制来保证数据的完整性。因为怕log越写越大，占用过多磁盘，而且当log特别大的时候，恢复起来也比较耗时。而checkpoint的出现就是为了解决这些问题。 mysql主从架构 Master-Slave(主挂了可能会丢失一部分数据)和Group Replication 的架构(mgr采用paxos协议实现了数据节点的强同步，保证了所有节点都可以写数据，并且所有节点读到的也是最新的数据) 2021-02-07 稍稍记录一下2020年干过的那些P大点的事 协助完成Redis降存储–&gt;阉割无用字段,(没用上压缩) ,以前是存储整个对象,现在是存储个别有用的字段, 降低了60%~80%的存储 综合订单、CX、操作运单、公共redis，共节省redis资源9034G 团队共同完成灰度发版–&gt;中间加应用,数据先到分流应用,通过分流应用把对应城市、网点的数据分流到对应的应用 独立完成ES查询优化–&gt;优化判断索引逻辑,指定查询具体某个分片,提高性能550倍 生产某个节点线程数过多及CPU高–&gt;dump&amp;排查源码 elasticJob的采用了流式处理,有某个节点的一些线程一直能查到数据,就一直继续工作了; elastic-job流式处理导致最终只有一个线程在跑的问题排查&amp;修复 —&gt; 同上 重试模块加入根据重试次数逃生逻辑,防止异常时空跑把系统跑死 优化ES存储订单数据的结构 —&gt; 4亿+数据量减少到只剩下5kw数据量，降低了十倍左右 把orderExtendInfoList类型改为keyword类型（原来为嵌套类型）, 内部额外存储一个作为索引用的值为原orderExtendInfo的key和value对应的Map 描述起来比较麻烦 大概是把下图左边的变成变成右边的 数据造就业务—&gt;咋玩??? 目前手上有啥数据: 订单–&gt;可以对BSP客户进行分类, 对不同类型客户,可以特别推荐一些增值服务或产品 -----&gt;根据寄件商品的类型为其推荐增值服务 扩展信息…没啥用 增值服务 订单状态&lt;—监控? 存在很多很久不揽收的 进行告警通知小哥? 让其决定是取消，还是让其再设定一个较远的预约时间 FVP所有状态&lt;– 运单号生成 运单&lt;— 产品变更&lt;— 变更监控? 至少可以记录一下产品变化以及运费变化 2021-01-25 一、ZK事件回调原理 – 最近用得少老是忘记，还是记录一下吧 简单来说，就是客户端启动后，会在zk注册一个watcher监听某个我们关心的节点Node的变化； 同时客户端会把这个watcher存到本地的WatcherManager里; 当这个节点出现变化，zk会通知到对应的客户端，调用该watcher的回调方法（process方法）。 以此方式实现动态配置平台的配置刷新下发、分布式锁等功能 2020-12-14 一、 ElasticSearch原理 图解ElasticSearch原理 精确查询 term 查询是如何工作的？ Elasticsearch 会在倒排索引中查找包括某 term 的所有文档 Lucene Index(包含多个Segments)： Segments 是不可变的（immutable）： Segments Delete？当删除发生时，Lucene 做的只是将其标志位置为删除，但是文件还是会在它原来的地方，不会发生改变。 Segments Update？所以对于更新来说，本质上它做的工作是：先删除，然后重新索引（Re-index） 随处可见的压缩：Lucene 非常擅长压缩数据，基本上所有教科书上的压缩方式，都能在 Lucene 中找到 缓存所有的所有：Lucene 也会将所有的信息做缓存，这大大提高了它的查询效率 整体结构 Cluster由多个Node节点组成 每个Node节点由多个索引Index组成 每个索引由多个Share组成 每个Share(又叫Lucene Index)存在于集群中多个Node中,具体有多少个Share,看你索引的配置,由多个Segment组成 每个Segment(又称Mini索引),每个Segment都是不可变的,只会生成一个增量Segment(含修改后的/新增的数据),原来的数据只能标记为删除,当Segment多了之后会做merge合并操作; Segments的创建&amp;刷新 (没玩大数据 大概了解就行了) 进行索引文档后,看是否有达到flush条件的Segment,存在就flush该Segment将该数据刷到硬盘中,没找到就创建一个Segment?? 参考 -&gt; ES lucene写入流程，segment产生机制源码分析 2020-11-18 一、 MYSQL是怎么运行的 – 连接原理 –以下为内连接,驱动表为t1,如果t1通过where过滤完还有2条数据,那么会去t2表查询2次 select * from t1 join t2 where ***; select * from t1 inner join t2 where ***; select * from t1 cross join t2 where ***; (以上等价于)select * from t1,t2 where ***; select * from t1 left join t2 on t1.a=t2.a where ***; – 为外连接 on实际是给外连接用的,在内连接使用的话和where的作用是一样的; 在外连接中使用,如果匹配不上,不会过滤掉驱动表原有的值;如果要过滤掉这种连接不上的值,可以再加个where条件过滤 驱动表t1只会被访问一次，被驱动表t2会被访问多次 2020-09-24(好久没做记录了…) 一、 DB 看似匹配到索引,但是没有走索引的情况(注意事项) 因类型转换导致不走索引 摘自本文结论内容 建表语句cell的数据类型为Varchar create table t ( id int(20) primary key AUTO_INCREMENT, cell varchar(20) unique )engine=innodb; 建表的时候cell定义的是字符串类型 Explain 通过explain，基本已经可以判断： update t set cell=456 where cell=55555555555; 并没有和我们预想一样，走cell索引进行查询，而是走了PK索引进行了全表扫描。 实际问题 where语句cell类型与索引的不匹配，不会走索引，最终会走全表； 结论 类型转换，会导致全表扫描，出现锁升级，锁住全部记录 二、 DB 执行计划查看&amp;&amp;死锁排查 执行计划 select_type：SIMPLE 这是一个简单类型的SQL语句，不含子查询或者UNION。 type：index 访问类型，即找到所需数据使用的遍历方式，潜在的方式有： （1）ALL（Full Table Scan）：全表扫描； （2）index：走索引的全表扫描； （3）range：命中where子句的范围索引扫描； （4）ref/eq_ref：非唯一索引/唯一索引单值扫描； （5）const/system：常量扫描； （6）NULL：不用访问表； 上述扫描方式，ALL最慢，逐步变快，NULL最快。 possible_keys：NULL 可能在哪个索引找到记录。 key：PRIMARY 实际使用索引。 ref：NULL 哪些列，或者常量用于查找索引上的值。 rows：5 找到所需记录，预估需要读取的行数。 死锁排查 有权限的mysql账户执行: show engine innodb status; 根据查到的结果 分析LATEST DETECTED DEADLOCK里的内容 三、ES 提高查询效率 学习自: ES 在数据量很大的情况下（数十亿级别）如何提高查询效率 把尽可能多的索引放在filesystem cache中 不做复杂查询（Join等），如果有这样的需要，应以设计得更好的document（记录）来实现简单查询（单表） 使用ES+hbase架构: ES存索引，索引全放在filesystem cache，数据存HBase；通过ES进行条件查询，获取docId，用该docId去查HBase 禁止深度查询，使用scrollApi或search_after代替 四、ES存储结构 index -> type -> mapping -> document -> field 实例： order~2020-08-02/order/_mapping/记录/字段 翻译： 索引名称/表名/表结构/记录/字段 2019-12-19 Kafka 基础点 Topic&amp;消费组: 一个Topic的一个Partition只能一个Consumer Group的一个节点消费 一个【Topic】对应多个【Partition】(文件) 消息大小限制: 一条消息 默认最大只能为1000000B(976.56 kB),所以一般规定不允许发送&gt;900k的消息 版本区别: 0.8版本 (相对历史版本 支持了Replication高可用 ) 当时只有Consumer Coordinator coordinator需要依赖于ZK，通过zk监听/consumers//ids变化 与 brokers/topic的数据变化决定是否要 rebalanced rebalanced后,consumer自己决定自己要消费哪些Partition，然后抢先在/consumers//owners//下注册（通过这种方式实现一个Topic的一个Partition只能一个Consumer Group的一个节点消费`） 同时,各个Consumer Coordinator还需要进行位移的提交 弊端: 消费者自己决定消费哪些分区,各个Consumer Coordinator还需要进行位移的提交 并且分区的决定与位移的提交都需要依赖于ZK 0.8.2版本 0.8.2版本开始同时支持将 offset 存于 Zookeeper 中与将offset 存于专用的Kafka Topic 中,但是需要High Level API的支持，且BUG较多，目前公司用的还是Low Level Api 0.9.x版本 新增Group Coordinator,存在于Broker端 代替了0.8.x版本的zk，每个消费组对应一个，负责每个消费者位移的提交&amp;分区消费的决策 0.10+ 消息结构添加了时间戳，可根据这个时间戳实现延迟队列 0.11.x版本 新增了对【幂等】、【事务】的支持(依赖于Producer幂等) (exactly-once) 3.High Level和Low Level 将仅支持zookeeper维护offset方式的 高级抽象的API称为 Low Level Api,高度抽象, 将支持kafka broker 维护offset方式 抽象低的API的称为 High Level API ， High level consumer vs. Low level consumer 官方解释(看最下面的描述) 消息(生产)幂等 每个Topic的每个Partition对每个生产者都维护了一套ID(UUID) 生产者每次发送消息时候,消息体都带上这个ID+1，以此Broker可得知： 当消息的squence number等于broker维护的squence number + 1，表示消息有序且第一次消费 当消息的squence number小于或等于broker维护的squence number，表示重复消费额 当消息的squence number等于broker维护的squence number + n（n &gt; 1），表示存在消息丢失 参考1:Kafka Producer 幂等的原理 参考2:上半场的幂等性设计 消息的分区选择: 一条消息会根据Key被路由到某一【Partition】（key=0对应分区0）；如果没有指定key，消息会被均匀的分配到所有分区；目前我们封装的方案是，不管有没有Key，都会被随机打乱到每个分区） 每隔 topic.metadata.refresh.interval.ms 的时间，随机选择一个partition。这个时间窗口内的所有记录发送到这个partition。发送数据出错后也会重新选择一个partition 对key求hash，然后对partition数量求模: Utils.abs(key.hashCode) % numPartitions 代码: kafka.producer.async.DefaultEventHandler#handle Kafka支持的消息发送模式 At most once 消息可能会丢，但绝不会重复传输(例:读到先Commit,再处理) At least one 消息绝不会丢，但可能会重复传输(例:读到先处理,再Commit) Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的 (0.8.2版本还不支持) 高可用 kafka默认会重试3次 零碎小点 Kafka实现的是客户端软负载: 让producer决定丢到哪个partition里 Consumer端仅支持pull模式，这也有利于让Consumer端决定消费速率 Consumer不能消费太久(如Sleep),因为Kafka会认为程序宕了,分区会重新进行分配,把消息分给其他的Consumer (相关配置项: max.poll.interval.ms) Consumer每次可从Kafka取max.poll.records条数据进行处理 如果想要消息有序 那么就得保证同个业务key的消息都是发到1个分区里 Redis-Sentinel&amp;Jedis 通过Sentinel集群获取Redis主节点原理 SF-Sentinel中配置Redis链(mymaster1,mymaster2,mymaster3)，然后获取每一条链的Master，进行初始化Redis连接池 原生的Sentinel中配置Redis链，然后获取该链的Master，进行初始化Redis连接池 Jedie的Key是如何被存入Redis的某个节点的 参考:Jedis之ShardedJedis一致性哈希分析 Jedis初始化时会初始化160个虚拟节点，160个虚拟节点通过Map（Map&lt;ShardInfo, R&gt; resources）映射到实际的Redis-Master节点 Jedis在Set key时会对Key分片计算（计算落在160个节点的哪一个），然后再根据虚拟节点与实际节点的映射，把指令发给实际的节点 参考代码： redis.clients.util.Sharded#initialize redis.clients.util.Sharded#getShard(byte[]) Redis-Sentinel模式是如何扩容的 空 Jedis一致性分析 2019-11-28 git rebase -i HEAD~2 pick：保留该commit（缩写:p） reword：保留该commit，但我需要修改该commit的注释（缩写:r） edit：保留该commit, 但我要停下来修改该提交(不仅仅修改注释)（缩写:e） squash：将该commit和前一个commit合并（缩写:s） fixup：将该commit和前一个commit合并，但我不要保留该提交的注释信息（缩写:f） exec：执行shell命令（缩写:x） drop：我要丢弃该commit（缩写:d） Hibernate 基本知识 inverse属性表示本实体是否拥有主动权 inverse只有在非many方才有，也就是many-to-many或者one-to-many的set,List等 2019-11-25 数据库count() 官方解释 Returns a count of the number of non-NULL values of expr in the rows retrieved by a SELECT statement. The result is a BIGINT value. 返回行中 expr 的非 NULL 值的计数 count(*) 和 count(1) 5.7.18以后，两个函数执行计划都是一样的 如果该表没有任何索引，那么会扫描全表，统计行数 如果该表只有一个主键索引，没有任何二级索引的情况下，那么通过主键索引来统计行数的 如果该表有二级索引，则会通过占用空间最小的字段的二级索引进行统计 count(column） 如果字段定义为not null，则按行累加，如果允许有null，则会把值取出来判断一下是不是null，将不是null的值累加返回。 MyISAM 与 InnoDB MyISAM会记录每个表的行数，count()时直接返回 InnoDB会通过扫描全表或索引，得到行数 在使用count函数中加上where条件时，在两个存储引擎中的效果是一样的，都会扫描全表计算某字段有值项的次数 DB select count速度 count(*)=count(1)&gt;count(primary key)&gt;count(column) 参考 MySQL原理：count(*)为什么这么慢，带你重新认识count的方方面面 2019-11-22 [垂直]分库分表 目标 通过减少数据量，提升性能 原则 长度较短，访问频率较高的属性尽量放在一个表里，我们将其称为主表(base表) 字段较长，访问频率较低的属性尽量放在一个表里，我们将其称为扩展表(ext表) 经常一起访问的属性，也可以放在一个表里(备选) 大数据量场景注意事项 不能用Join 解决方式: 让应用自己拆分成两次查询 base表和ext表不能Join，因为一旦Join了，那么两张表就出现了耦合，这不利于日后拆表到别的数据库实例上 Join很消耗数据库的性能(分布式场景下,瓶颈往往是数据库) 提高性能的原理 减少单表的数据量，减少磁盘IO（降低每行记录大小） 更好的利用缓存 因为减少单表数据量还可以充分利用数据库缓存，减少磁盘IO 2019-11-20 数据库基本知识 MyISAM与InnoDB索引的区别 MyISAM: MyISAM不存在聚集索引,主键索引与普通索引没区别，叶子节点都是存储的都是数据的地址 InnoDB: InnoDB必然有[一个]聚集索引（为主键索引,没主键时会用第一个非空普通索引，都没有会生成一个基于行号的聚集索引） select * from t where name=‘lisi’; 会先通过name辅助索引定位到B+树的叶子节点得到id=5，再通过聚集索引定位到行记录 违反唯一索引场景: MyISAM会出现一个update语句，部分执行成功，部分执行失败(因为不支持事务) 2019-11-11 Elastic-Job 运行规则: 3台机器的一个集群 ,shardingCount=10 ,分片结果为：1=[0,1,2,9], 2=[3,4,5], 3=[6,7,8] (参考AverageAllocationJobShardingStrategy) 如果本机的数据分片分到了多个分片（即一个JVM进程分到了多个分片），则Elastic-Job会为每一个分片去启动一个线程来执行分片任务 线程: 每个任务对应一个线程池,其默认线程数为: 2*逻辑核心数(参考DefaultExecutorServiceHandler) 线程池配置为: new ThreadPoolExecutor(threadSize, threadSize, 5L, TimeUnit.MINUTES, workQueue, new BasicThreadFactory.Builder().namingPattern(Joiner.on(&quot;-&quot;).join(namingPattern, &quot;%s&quot;)).build()); (参考ExecutorServiceObject) 问题: 要注意单机线程数要 大于 单机获取到的分片数 - 参考 《Elastic job 线程模型 源码分析》 一个jvm实例 处理多个 job ， 每个job 在该实例上分片数又大于逻辑核心数*2 的数量 随着job不断增加 ， 单个job任务执行时间可能会变长 ，有可能超过平时的任务完成超时时间 ，造成任务失败 举个例子: 如果一台机器 处理器数 2 ， 线程池 就是 4 ， 如果 分片是 5 ， 就是说 一个分片会被排队 ，实际完成时间 &gt;2 个分片 完成时间 Elastic-Job其他 1. 失效转移 - 参考 【简单的HA】版失效转移 (默认) 在作业节点下线，或者zk的session超时（默认60s）时，会在下一轮任务分片时，把这个该问题节点的分片分给别的正常节点进行作业 （可能会存在作业重复处理的问题） 【真正的】'失败’转移 (需要开启) 当failover（默认值为false） 配置为true时，才会启动真正的失效转移； 当failover（默认值为false） 和 monitorExecution（默认值是true）这两个配置都为true时 只有对monitorExecution为true的情况下才可以开启失效转移； 如果任务1在A节点执行【失败】，那么会【转移】给别的存活的节点【竞争】执行这个任务1； - 参考 - 官方参考 2019-08-26 官方参考 MySQL锁 InnoDB锁机制是基于索引建立的 如果SQL语句中匹配不到索引,那么就会升级为表锁 记录锁 1234-- id 列为主键列或唯一索引列SELECT * FROM table WHERE id = 1 FOR UPDATE;或update table set age=2 WHERE id = 1; 通过唯一索引实现的记录锁,只会锁住当前记录(必须为=不然会退化为临键锁) 间隙锁 间隙锁只有在事务隔离级别 RR(可重复读)中才会生效. 为非唯一索引组成(如class,age等) 1select student where age&gt;26 and age&lt;28 lock in share mode ; -- 这里以读锁为例 使用间隙锁的条件 命中普通索引锁定； 使用多列唯一索引； 使用唯一索引命中多行记录 临键锁(Next-key Locks) 临键锁只有在事务隔离级别 RR(可重复读)中才会生效. 是记录锁与间隙锁的组合 可以是唯一索引,也可以是非唯一索引,对其都以间隙锁的形式进行锁定(以唯一索引匹配,并且只匹配到一条数据除外) 临键锁(Next-key Locks) 例子: tno(唯一索引) tname tsex tbirthday prof depart age(非唯一索引) 858 张旭 1 1969-03-12 讲师 电子工程系 25 857 张旭 女1 1969-03-12 讲师 电子工程系 25 856 张旭 男 1969-03-12 讲师 电子工程系 25 831 刘冰 女 1977-08-14 助教 电子工程系 29 825 王萍 女 1972-05-05 助教 计算机系 28 804 李诚 男 1958-12-02 副教授 计算机系 26 其中有唯一索引的临键为: (-∞,804] (804,825] (825,831] (831,856] (856,857] (857,858] (858,+∞] 其中有非唯一索引的临键为: (-∞,25] (25,26] (26,28] (28,29] (29,+∞] 非唯一索引临键锁验证 123-- session1select * from teacher WHERE age between 26 and 28 lock in share mode ; 这时候会锁定非唯一索引的临键 (25,29] 所以我们测试更新age=25–&gt;成功 插入age=27阻塞 更新age=29阻塞 插入age=30成功即可验证 12345678910111213-- session2-- 更新age=25--&gt;成功update teacher set tsex='女1' WHERE age=25;-- 插入age=27阻塞insert into `test`.`teacher` ( `tno`, `tname`, `tsex`, `tbirthday`, `prof`, `depart`,`age`) values ( '740', '张旭1', '12', '1969-03-12 00:00:00', '讲师', '电子工程系',27);-- 更新age=29--&gt;阻塞update teacher set tsex='女1' WHERE age=29;-- 更新age=30--&gt;成功insert into `test`.`teacher` ( `tno`, `tname`, `tsex`, `tbirthday`, `prof`, `depart`,`age`) values ( '740', '张旭1', '12', '1969-03-12 00:00:00', '讲师', '电子工程系',30); 唯一索引临键锁验证 12-- session1select * from teacher WHERE tno between &quot;831&quot; and &quot;856&quot; lock in share mode ; 根据上面的sql,我们匹配到唯一索引临键锁为:(825,857] 所以我们测试更新tno=825–&gt;成功 更新tno=857阻塞 更新age=858成功即可验证 123456-- 更新tno=&quot;825&quot;--&gt;成功update teacher set tsex='女1' WHERE tno=&quot;825&quot;;-- 更新tno=&quot;857&quot;--&gt;阻塞update teacher set tsex='女1' WHERE tno=&quot;857&quot;;-- 更新tno=&quot;858&quot;--&gt;成功update teacher set tsex='女1' WHERE tno=&quot;858&quot;; 2019-08-22 Spring事务/AOP增强 @EnableAspectJAutoProxy(exposeProxy = true) 进入代理时,通过AopContext.serCurrentProxy(proxy)把当前代理设置到ThreadLocal中 后续在线程销毁(请求结束)前调用代理内部之间的调用就可以通过((AService)AopContext.currentProxy()).b()进行调用了 PS. 性能影响不大 不过实际上代理内部之间还需要AOP增强的场景不多,一般没必要用 Spring LTW实现的静态织入（应该不能叫做代理） 需要添加配置： 代码添加: @EnableLoadTimeWeaving(aspectjWeaving=ENABLED)或&lt;context:load-time-weaver aspectj-weaving=&quot;enable&quot; /&gt; 添加JVM参数-javaagent:类加载器代理路径 LTW(LoadTime Weaving) 加载时织入。在通过JVM加载类时候会先调用ClassTransformer的transform()进行字节码替换后才会进行加载。 静态AOP 通过LTW可以实现静态AOP增强，加载到的类就是已经增强后的代码。这样我们调用方法的时候,直接就是调用了增强后的方法,比起动态代理的调用,更加地高效。 上述流程大致如下所示: graph TD A[Target] B[增强后的字节码] C[加载后的代码] D[注入后的Bean] E[调用方] A--ClassTransformer的transform方法进行字节码植入-->B B--JVM加载-->C C--Spring使用,创建/注入Bean-->D E--方法调用-->D 2019-08-01 Spring事务 对于this.b()这些类实例的内部调用，b()实际上是无事务的 但是可以用((AService)AopContext.currentProxy()).b() 结合@EnableAspectJAutoProxy(exposeProxy = true) 这样b()就包裹在事务里了 2019-7-20 seata seata需要管理所有的数据库操作，不然不能通过前镜像进行回滚 2019-7-17 Spring事务/Cglib final,static,private修饰符无法被增强 由于使用final,static,private修饰符的方法都不能被子类覆盖，相应的，这些方法将不能被实施的AOP增强 增强应该作用在实现类中 @Transactional 注解可以作用于接口、接口方法、类以及类方法上，但是 Spring 建议不要在接口或者接口方法上使用该注解，因为这只有在使用基于接口的代理时它才会生效。 2019-5-20 【GC日志】GC耗时解析 【Time: user=0.71 sys=0.01 real=0.02 secs】 user表示：本次GC过程中【所有线程】在用户态消耗的时间总和 sys表示： 本次GC过程中 【所有线程】在内核态所消耗的时间总和 real表示：本次GC过程中，实际GC消耗的时间 2019-5-1 数据库MVCC MVCC：多版本并发控制(Multi-Version Concurrency Control) 优势：查询速度快，并发环境尤是。对于大多数读操作，我们只需要通过MVCC进行简单的查询操作，而不需要获取任何一个锁。 劣势：需要多存储数据。对每一条记录都需要存储所有版本的数据 MVCC只工作在REPEATABLE READ和READ COMMITED隔离级别下 READ UNCOMMITED不是MVCC兼容：因为这个模式只能读取到最新的数据 SERIABLABLE也不与MVCC兼容：因为每个读操作都需要为读到的数据上锁 MVVC机制： 以下摘自《五分钟搞清楚 MVCC 机制》 每一条数据库表记录,都隐藏2个字段 数据行的版本号 （DB_TRX_ID） 删除版本号 (DB_ROLL_PT) 执行insert语句插入的时候,会把当前的事务ID写到该记录的数据行的版本号 （DB_TRX_ID）中: 123begin;-- 获取到全局事务ID 假设为2insert into `test_zq` (`id`, `test_id`) values('5','68');commit;-- 提交事务 id test_id DB_TRX_ID DB_ROLL_PT 5 68 2 NULL 6 78 1 3 修改数据库记录的时候 更新原记录的删除版本号 (DB_ROLL_PT)为当前事务ID 插入一行新的更新后的记录,且它的数据行的版本号 （DB_TRX_ID）为当前事务ID 123begin;-- 获取全局系统事务ID 假设为 10update test_zq set test_id = 22 where id = 5;commit; id test_id DB_TRX_ID DB_ROLL_PT 5 68 2 10 6 78 1 3 5 22 10 NULL 查询的时候需要根据数据行的版本号 （DB_TRX_ID） 和 删除版本号 (DB_ROLL_PT) 二者进行数据数据筛选，需要同时满足以下规则： 数据行的版本号 （DB_TRX_ID） &lt;= 当前事务 删除版本号 (DB_ROLL_PT) &gt; 当前事务 123begin;-- 假设拿到的系统事务ID为 10select * from test_zq;commit; id test_id DB_TRX_ID DB_ROLL_PT 6 22 10 NULL 2019-04-24 Spring的Lifecycle (SpringAppilication生命周期) Spring会拿到所有Lifecycle实现类，然后委托DefaultLifecycleProcessor进行逐个处理 Lifecycle 可以在SpringAppilication在初始化后执行start()方法,Spring停止的时候调用stop()方法 但是单单实现该类不能实现SpringAppilication在启动后,停止时调用Lifecycle对应的方法 这时候我们应该需要使用SmartLifecycle（Lifecycle的子类）,重写isAutoStartup()返回true，才能产生理想效果 2019-04-23 关于测试类的规范 单元测试应该是不依赖于别的单元测试的 所有单元测试应该都得回滚，如果存在异步处理的情况，应尽可能把主线程与fork线程拆成2个测试类方法进行测试 每个测试类／测试方法应写上对应的名称@DisplayName 每个接口，都必须写一个正向测试方法 关于测试类的类名：测试类与被测试的类的路径需要一致，名字也需要对应，如： 123com.fpx.wms.service.impl.InstockServiceImpl↓对应↓com.fpx.wms.service.impl.InstockServiceImplTest 关于测试类的方法名： 方法名尽可能为成功的条件如shouldSuccessAfterPay()，而方法具体用来测试哪个场景的，我们已经使用了@ DisplayName来描述，无须担心 对于结果，需要适应assert断言输出与结 2019-04-22 Spring @Lookup 作用 在单例A里 可能依赖到原型类型B,这时候如果用普通的Autowrite不能拿到原型的B，这时候就需要使用@Lockup了 使用参考 参考地址 官网地址参考地址 2019-04-21 架构设计三大原则 合适原则 简单原则 演化原则 即，合适优于先进，简单优于复杂，演化优于一步到位 →能不分，尽可能不分 2019-03-20 策略模式 vs 命令模式 1. 策略模式 1策略模式针对一个命令,多种实现方式 2. 命令模式 1命令模式针对多个命令,每种命令都有各自的实现 3. 总结 1命令模式等于菜单中的复制，移动，压缩等，而策略模式是其中一个菜单的例如复制到不同算法实现。 2019-03-15 策略模式 vs 代理模式 1. 策略模式 1需要调用方告知具体的策略 2. 代理模式 12需要调用方告知使用哪个[代理类]具体的【被代理类】由【代理类】生成，客户端不知道具体被代理的是谁 2.1 动态代理 1需要调用方告知[被代理类]及其接口 3.One More Thing 12以上模式都需要客户端告知具体的[策略]/[代理]/[被代理者]为了使实现其与调用方进行隔离,可以使用[**工厂模式**]进行隔离 2019-03-12 Spring循环依赖 场景现有3个类相互依赖，依赖关系分别为： graph LR A-->B B-->C C-->A 场景细分为3种 构造注入参数循环依赖(报错) 报错 根据Spring初始化方式,Spring容器会按照顺序创建&quot;无属性&quot;的A放到“当前创建Bean池”中，同理再B、C、A，但是在再次创建A的时候发现“当前创建Bean池”已经存在A了，那么这时候会报错循环依赖 Setter注入的循环依赖(单例) 没毛病，在set的时候对象ABC都已经实例化放在Spring缓存了好了 Setter注入的循环依赖(prototype) 报错 prototype修饰的bean不会被Spring缓存,都是使用的时候当场创建的 Spring注入方式选择 结合上面的循环依赖问题，Setter出现问题的概率会低一些 推荐使用Setter注入 构造注入 Setter注入 接口注入(没用过) 2019-03-11 一、集合操作 遍历 Enumeration(JDK1.0) 只提供读集合相关功能，因为没有fail-fast，速度较快一点 Iterator(推荐) 除了读功能，还有删除集合元素的能力，并且支持fail-fast（防止多线程同时对集合修改的一种机制） 修改 正例： 以List为例子,先得获取他的Iterator,通过iterator来进行修改操作 反例： 使用增强型foreach进行add/remove操作： 因为增强型foreach实际上是使用iterator实现的java语法糖: 1234567891011List&lt;String&gt; userNames = new ArrayList&lt;String&gt;() {{ add(&quot;test1&quot;); add(&quot;test12&quot;); add(&quot;test13&quot;); add(&quot;test14&quot;);}};for (String userName : userNames) { if (userName.equals(&quot;test12&quot;)) { userNames.remove(userName); }} 编译后 12345678910111213141516List&lt;String&gt; userNames = new ArrayList&lt;String&gt;() { { this.add(&quot;test1&quot;); this.add(&quot;test12&quot;); this.add(&quot;test13&quot;); this.add(&quot;test14&quot;); }};Iterator var1 = userNames.iterator();while(var1.hasNext()) { String userName = (String)var1.next(); if (userName.equals(&quot;test12&quot;)) { userNames.remove(userName); }} 123456所以实际上for (String userName : userNames) 这里每次都会去调用itertor.next()如果你在迭代期间,操作了list.add()和list.remove()等不通过Iterator的操作next()里会去调用checkForComodification()方法然后发现modCount != expectedModCount 抛出异常因为list.add()和list.remove()等不通过Iterator的操作,是不会修改expectedModCount的 其它 fail-fast： 防止多线程同时对集合修改的一种机制 modCount： ****List**中的一个成员变量。它表示该集合实际被修改的次数 expectedModCount： 是 ****List**中的一个内部类——Itr中的成员变量 二、Hystrix Feign-starter包含Hystrix以及ribbon(只用他的均衡负载 http请求还是用feign自己的) 一个@FeignClient对应一个线程池或信号量 隔离 线程池隔离 tomcat的请求线程会交给线程池的线程处理 超过线程池会排队或者降级，一个线程池对应的服务挂了，不会影响别的线程池的服务 信号量隔离 只作为开关 并发数超过X服务的信号量,多出来的Tomcat请求将会被拒绝 2019-03-09 2019-03-05 一、StringBuilder在高性能场景下的正确用法 StringBuilder在高性能场景下的正确用法(文中代码打错了一些字…) 正确写法应该是这样↓ StringBuilderUtil.java 2019-03-01 一、分布式锁 从需求上说，分布式锁要求是不一样的： 如果是用于聊天等社交场景,那么可以使用AP的分布式锁:Redis 如果是用于交易等不允许极端情况下获取锁不一致的，那么AP的Redis锁是不能接受的，这时候一定得用CP的分布式锁,如:etcd Zookeeper这一类 2019-02-22 一、ThreadLocal 每个线程都有一个ThreadLocalMap,ThreadLocalMap以Entry的形式保存着各个线程自己的数据 Entry为一个WeakReference,以你new的ThreadLocal为Key 基于2.当你new的ThreadLocal没被外部强引用时,线程该Thread下对应该ThreadLocal的Entry会在下次GC被回收 当一条线程创建了多个ThreadLocal，多个ThreadLocal放入ThreadLocalMap 会极大地增加冲突概率 ThreadLocalMap对冲突的处理方式与普通HashMap的链表处理不一样，而是以原来的位置+1，一直寻找到没有冲突的地方存入 ThreadLocal在ThreadLocalMap中是以一个弱引用身份被Entry中的Key引用的 ThreadLocal.remove(),移除ThreadLocalMap与Entry的关系，释放内存 2019-02-17 一、常量池 常量池包含: class常量池 存在于class文件中 运行时常量池 存在于方法区中 一个类对应一个运行时常量池 字符串常量池 全局唯一 JDK6存在于方法区(独立于运行时常量池) JDK6以后存在于堆中 二、字符串加载到字符串常量池的2种方式 graph LR A[编译后的class文件中的class常量池] B[运行时常量池*N] C[字符串常量池] D[Java代码运行] A-->B D-->B B-->C 2019-01-28 Mybatis 一级缓存 (范围为一个SqlSession) 有Session/STATEMENT级别: 默认是SESSION 级别，即在一个MyBatis会 话中执行的所有语句，都会共享这一个缓存。 一种是STATEMENT 级别，可以理解为缓存只对当前执行的 这一个Statement 有效 二级缓存 基于mapper 二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享 补充: 缓存为本地缓存, 在集群部署的系统里开启后,会导致A1查询与A2查询结果不一致的问题 看情况开启,一般为关闭;或者使用Redis等工具使用统一的第三方缓存 2018-11-06 一、 分布式事物要看场景的 举个例子: 流量充值涉及到订单支付，金钱交易严格用tcc; 订单支付完后要给用户增加积分，这个必要成功，用最终消息一致性方案; 订单支付完后还要给用户发送一条短信，短信一般是跟电信运营商的第三方接口对接，有可能成功有可能失败，用最大努力通知方案 2018-11-06 一、JVM逃逸分析与TLAB(Thread Local Allocation Buffer) 启动逃逸分析后,会分析没有逃逸的对象,把没有逃逸的对象分配在线程私有的栈里,性能提高5倍 TLAB(默认开启)存在于新生代,默认占其1%,为线程私有;因为线程私有,没有锁开销(对象分配的时候不需要锁住整个堆),效率高; 创建对象时内存分配流程: 逃逸分析,确定分配在哪,如果是分配在堆则2 尽量分配在当前线程的TLAB,不够就去再申请一个TLAB,还不够则3 加锁Eden区,在Eden申请内存,不够则4, 执行Young GC Young GC后,如果还不够,放入老年代 对象分配流程写的不错 参考:https://blog.csdn.net/yangzl2008/article/details/43202969 2018-10-19 一、Feign Consul 获取可用服务IP HealthConsulClient.getHealthServices获取可用IP 通过http://consul.uat.i4px.com:8500/v1/health/service/pds-pos-outer?token= 最终会在ConsulServerUtils.findHost()得到服务所对应的可用IP IP获取逻辑是: 获取Service.Address字段作为可用IP 取不到就取Node.Address 二、Consul 1.服务注销/删除 http://consul.uat.i4px.com:8500/v1/agent/service/deregister/fpx-prs-service-10-104-5-15-8002 2.查看可用服务 http://consul.uat.i4px.com:8500/v1/health/service/wims?passing=true 2018-10-18 一、多服务的【事务】阻塞（跨机器） 数据库锁分为读锁、写锁，读读共享，写写互斥，读写互斥 程序A正在开启事务,操作(包括CRUD) 数据库记录A时,A会被行级锁（读/写锁）; 其它程序若要对进行互斥锁操作,需要阻塞到该锁被释放(程序A提交事务)， 2018-09-29 一、接口返回的JSON数据,快速转换为实际数据 ObjectMapper mapper = new ObjectMapper(); SimsPudo simsPudo = mapper.convertValue(responseMessage.getData(), SimsPudo.class); 2018-09-29 一、-XX:+PrintFlagsFinal :=意味着值是被修改的, =表示默认值 2018-09-29 一、Feign重试 默认只会对connect timeout进行重试 OKToRetryOnAllOperations=true 会对connect timeout和socket read timeout都进行重试,对socket read timeout会引起后端重复处理请求问题(需要做幂等) Feign对于&gt;400的后端报错是不会重试的 设置了OKToRetryOnAllOperations=true所有后端需要幂等 OKToRetryOnAllOperations=false的前端需要做对应的超时异常处理,如: i.写代码自动重试 ii.直接返回前台成功 二、超时时间 (socket)connect timeout 连接超时 (socket)read timeout 读超时 对read timout,请求已经到达后端处理,但是没在指定时间内返回 三、Http状态码分类 1XX:正在处理 2XX:请求处理成功 3XX:请求需要重定向 4XX:服务器无法处理请求(U Fuck Off) 5XX:服务器处理请求出错(I Fuck Off) 四、String “ABC”: 是显示声明的 以&quot;ABC&quot;形式存在于常量池中(常量池也在堆里) new String(“ABC”): 以对象形式存在于堆中 str.intern(),字符串(或引用)是否存在于常量池,不存在就把该引用存在常量池 “ABC”.intern() 没意思,本来就是放在常量池的东西,再调intern没用 五、@Transaction @Transactional方法会覆盖类上的配置 调用被注入的代理类才能有效地激活@Transaction的效果 2018-09-28 一、JVM参数配置 -XX:+PrintCommandLineFlags 打印改动过的JVM参数 -XX:+PrintFlagsFinal打印最终在用的参数 -XX:+UnlockExperimentalVMOptions -XX:+UnlockDiagnosticVMOptions 显示隐藏参数 二、Feign前后端全局异常处理 后端【业务代码直接抛异常】 后端全局异常捕获时【返回带异常信息的ResponseMsg】(一般不含堆栈信息),同时返回状态码设置为500(也可以404,因为Feign默认后端报错就是返回404) 前端(调用者)ErrorDecode时,解析该[ResponseMsg的异常信息],重新throw对应的异常就能保证前后端异常一致了 [x] 对于需要进入fallback的调用 同上处理,但是按需可能需要使用FallbackFactory获取后端返回的异常信息进一步处理 如打印日志等 [ ] 问题:可能导致前端(调用方)不能切换实例重试 [ ] 加入Decode404=true后,404错误不会进入ErrorDecode和Fallback 2018-09-17 一、正确的kill进程 先kill -15(安全关闭 回收资源) 不行再kill -9(强制关闭) 2018-09-16 一、JDK8+移除了Perm jdk8移除了Perm 其方法区及常量池等数据,全部移到了元数据区(Metaspace)中 二、String.intern JDK7及以后版本,是复制其字符串引用到常量池中 实际数据还是存在于堆中 二、-XX:MetaspaceSize -XX:MetaspaceSize=200m不是初始元空间大小,而是达到了200m后才会对该区域进行GC 2018-09-06 一、获取全局唯一ID redis: 服务器时间戳+redis全局自增id=&gt;UUID 简单、快捷 zk:同上 比较慢 通过数据库 慢、并发低 twitter的雪花算法: 通过时间戳+机器ID=&gt;UUID 优势:速度快、无需依赖中间件、全局唯一 实现参考：https://github.com/souyunku/SnowFlake 2018-09-05 一、SQL的强制索引 select * from parcel FORCE INDEX(uniq_fpx_tracking_no_1) where fpx_tracking_no not in (‘901000486441’,‘901000497454’) ; 二、接口幂等理解 分布式锁实现幂等的方式 查询缓存结果,存在就返回 不存在,获取分布式锁(阻塞等待) 再尝试第一步(其实就是双重校验) 不存在,开始执行业务逻辑,并且缓存结果 释放锁 分布式锁实现的幂等,不完全可靠,因为缓存会过期 要保证其绝对可靠,还是得使用select+insert、唯一索引等方式 三、IO多路复用模型 https://mp.weixin.qq.com/s/xmSn9Xz6MiFb2s_0J7iXwQ 单Reactor单线程(Redis) 单Reactor多线程 多Reactor多线程(包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持) 单 Reactor 单线程，接待员、侍应生、后厨是同一个人，全程为顾客服务 单 Reactor 多线程，1个接待员，多个后厨 主从 Reactor 多线程，1个接待员，多个侍应生，多个后厨","link":"/Make-A-Little-Progress-Every-Day/Make-A-Little-Progress-Every-Day.html"},{"title":"Spring常见事件","text":"[转载]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Spring/Spring-events.html ContextRefreshedEvent：表示ApplicationContext已经初始化或刷新完成时触发。通常在应用程序启动时使用，用来执行初始化操作 ContextStartedEvent：表示ApplicationContext已经启动时触发。通常在应用程序启动时使用，用来执行一些启动任务 ContextStoppedEvent：表示ApplicationContext已经停止时触发。通常在应用程序停止时使用，用来执行一些清理任务 ContextClosedEvent：表示ApplicationContext已经关闭时触发。通常在应用程序关闭时使用，用来执行一些清理任务 RequestHandledEvent：表示Web请求已经处理完成时触发。通常在Web应用程序中使用，用来记录日志或统计数据 ApplicationStartedEvent：表示Spring Boot应用程序已经启动完成时触发。通常在Spring Boot应用程序中使用，用来执行启动任务 ApplicationReadyEvent：表示Spring Boot应用程序已经准备就绪时触发。通常在Spring Boot应用程序中使用，用来执行一些初始化任务 ApplicationFailedEvent：表示Spring Boot应用程序启动失败时触发。通常在Spring Boot应用程序中使用，用来执行一些异常处理任务","link":"/Spring/Spring-events.html"},{"title":"Spring生命周期","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Spring/Spring-life-cycle.html 以以下为准： 1. 获取beanDefinition 通过loadBeanDefinitions() -&gt; 读取配置文件 -&gt; 解析配置文件 -&gt; 封装成BeanDefinition -&gt; 注册到BeanDefinitionRegistry的beanDefinitionMap中 扩展1:BeanDefinitionRegistryPostProcessor.postProcessBeanDefinitionRegistry 获取BeanDefinitionRegistry，增删改BeanDefinition，因为后续按此顺序创建 扩展2:BeanFactoryPostProcessor.postProcessBeanFactory BeanDefinition加载完成之后，但实例化bean之前进行一些额外的处理 这时候所有的bean定义都已加载，但还没有实例化任何bean。这允许覆盖或添加属性，甚至是对急于初始化的bean 2. 遍历beanDefinitionMap，实例化bean 扩展: 实例化前后处理 InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation 3. 依赖注入(populateBean)–这里通过三级缓存解决循环依赖 扩展: 属性填充前后的处理 填充设值前: InstantiationAwareBeanPostProcessor.postProcessPropertyValues 设值后: InitializingBean.afterPropertiesSet() 4. 初始化bean 扩展: init-method 初始化前后:BeanPostProcessor.postProcessBeforeInitialization和BeanPostProcessor.postProcessAfterInitialization 5. 销毁bean 扩展: destroy-method 销毁前: DisposableBean.destroy","link":"/Spring/Spring-life-cycle.html"},{"title":"Spring白板源码整理","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Spring/Spring-whiteboard.html 这本经常出错的辣鸡书的读后整理：《Spring源码深度解析》 仅记录，日后有空加描述，嗯，有空的话，有空再说。。。 SpringAOP源码 Spring事务源码 SpringMVC Spring DispatcherServlet源码 Spring+Mybatis整合原理源码分析 Spring整合MyBatis的原理是将MyBatis的SqlSessionFactory和Spring的IoC容器进行集成，从而在Spring容器中管理SqlSessionFactory对象，进而管理MyBatis的SqlSession对象 在Spring整合MyBatis的过程中，主要用到了以下几个FactoryBean： SqlSessionFactoryBean： 它是一个FactoryBean，用于创建SqlSessionFactory对象，并将其纳入Spring容器进行管理。它通过配置DataSource等参数，将MyBatis的配置文件和映射文件加载进来，最终生成SqlSessionFactory对象 MapperFactoryBean： 它也是一个FactoryBean，用于创建Mapper接口的代理对象，并将其纳入Spring容器进行管理。它会自动扫描指定的包路径，找到所有的Mapper接口，并为其创建代理对象，实现了Mapper接口的自动注入和管理 SqlSessionTemplate： 他是一个Spring提供的工具类，用于简化SqlSession的使用。它包装了SqlSession对象，提供了方便的方法，如selectOne、selectList等，从而减少了代码的冗余和复杂度 同时，它还管理了SqlSession的生命周期，确保在需要时打开和关闭SqlSession 这些FactoryBean的作用是将MyBatis的核心对象SqlSessionFactory和Mapper接口纳入Spring容器进行管理，并提供了简化SqlSession使用的工具类SqlSessionTemplate，从而方便了应用开发","link":"/Spring/Spring-whiteboard.html"},{"title":"【Spring源码分析】循环依赖的处理","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/Spring/Spring-Circular-Dependencies.html 看源码的同学可以查看我的GitHub 上面在官方的基础上加入了大量中文注释，帮助理解 要了解的知识 什么是循环依赖 graph LR A-->B B-->C C-->A 存在哪些循环依赖 Setter循环依赖(可以被解决) 构造循环依赖(报错) 基于Prototype类型的循环依赖(报错) Bean的创建步骤 看源码的同学可以找到源码： 环节1~4的代码在AbstractAutowireCapableBeanFactory#doCreateBean方法中 环节5的代码在DefaultSingletonBeanRegistry#getSingleton(String,ObjectFactory)方法的addSingleton(beanName, singletonObject);中 Spring是怎么处理循环依赖的（对于单例Bean） 实现原理 Spring在创建单例BeanA的时候会先把BeanA(仅执行完构造方法)给放到三级缓存中， 当其他Bean或业务代码在BeanA[创建完之前]需要用到， 那么Spring就会把这个 还没进行[属性注入] [调用init方法]的BeanA提前暴露给这些Bean，并且把BeanA提到二级缓存中 三级缓存 首先咱们得知道三级缓存包括哪些： DefaultSingletonBeanRegistry#singletonObjects 单例对象的cache 只有[创建完成(只调用了构造方法)]&amp;&amp;[初始化属性完成]的才会放入这里 (这是一级缓存 我们平时说Spring是个大工厂，所有的创建好的bean都可以从Spring缓存里拿。 这里面说的缓存就是一级缓存) DefaultSingletonBeanRegistry#earlySingletonObjects 存放提前曝光的单例对象 只会放入[创建完成(只调用了构造方法)]&amp;&amp; [被提前曝光的] 的bean (用于解决[循环依赖]的2级缓存) DefaultSingletonBeanRegistry#singletonFactories 单例对象工厂的cache 只会放入[创建完成(只调用了构造方法)]的beanFactory (用于解决[循环依赖]的3级缓存) 解决循环依赖核心代码 123456789101112131415161718192021222324252627@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) { //desc 先从singletonObjects（一级缓存）取 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { //desc 取不到且创建中,那么这里使用同步锁阻塞一会,等待创建完成 //❤这里会发现 当真正创建完bean时会调用addSingletonFactory() 这时候也会锁住singletonObjects❤ synchronized (this.singletonObjects) { //desc 同步阻塞+尝试从earlySingletonObjects(二级缓存)获取 singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) { //desc 如果二级缓存取不到&amp;&amp;允许从singletonFactories通过getObject获取 //desc 通过singletonFactory.getObject()(三级缓存)获取工厂创建该bean ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { //desc 通过三级缓存的Factory创建目标bean 并放入2级缓存 singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } return singletonObject;} 其实这里做的事情和上面原理说的一样: 因为Spring在创建单例BeanA的时候会先把仅仅初始化完成,未注入属性的BeanA(对应图中步骤1)给放到三级缓存中， 如果其他Bean在BeanA创建完之前需要用到(循环依赖就是这种场景)， 那么Spring就会把这个BeanA提前暴露给这些Bean，并且把BeanA提到二级缓存中。 这样子，这些Bean就成功的获取到一个仅仅初始化完成,未注入属性的BeanA 场景分析 假设现在有3个Bean ABC发生了Setter循环依赖(如本文最上面的图) 通过如上方式,，Spring完全可以帮我们解决单例之间的Setter循环依赖问题让循环依赖的Bean之间获取到一个仅仅初始化完成,未注入属性的BeanA 这么说可能有些抽象，咱们尝试来还原该情况发生时发生了什么事情 现在getBeanA，会先去缓存里getA，这时候A还没被创建，故进行A的创建流程 因为A依赖于B，所以A会执行到createBean流程第三步的populateBean，然后会去getB(经过了第二步A已经被放入三级缓存中) 同理，B依赖C，所以B会执行到createBean流程第三步的populateBean，然后会去getC(经过了第二步B已经被放入三级缓存中) C依赖于A，也同理，但是这时候再去getA的时候，会发现又是一个getBeanA流程，但是这时候在三级缓存里getA已经能get到对象了 获取到这个缓存中的A之后，完成beanC的属性注入、初始化等操作。这样，就完成beanC的整个创建流程； 同理，B、A也一样： 这样逐级返回，这样，就完成了整个getBeanA的流程，虽然过程中存在循环依赖，但不会令getBean流程出现异常 至此，Spring完美地给我们处理了Setter循环依赖。 其实，换成代码理解可能更加简单:D 1234567A a = new A();B b = new B();C c = new C();a.setB(b);b.setC(c);c.setA(a); 其它一些补充 为什么构造循环依赖不能被解决（Bean创建过程中没有放入缓存） 参考createBean流程 根据上图的流程，createBeanInstance调用的实际上是构造方法，调用前还没把任何东西放入缓存中。 这时候如果出现基于构造方法的循环依赖，那么是不可能成功的，试想一下： newA的时候依赖于B newB的时候依赖于C newC的时候又反过来依赖于刚才的A 而这时候A还没被new出来！这时候异常就出现了 上述情况换成代码理解就成了 1A a = new A(new B(new C(new A(new ..........)))); 为什么prototype类型的循环依赖无法被解决 首先咱们得先了解下prototype的bean创建流程 graph TD A[createBeanInstance] C[populateBean] E[return Bean] A--调用Bean的构造方法得到一个空Bean-->C C--为Bean注入属性-->E 从流程可见，prototype的Bean创建过程中压根就没有对生成完的bean进行缓存 每一个Bean都是实时创建/使用的 根据上面的流程，我们很容易发现，这种不使用缓存的情况压根不允许存在循环依赖，因为： A依赖于B，这得实时去创建A和B B依赖于C，也得实时去创建C 创建C的时候发现C依赖于A，然鹅A没被缓存（当然，其实prototype压根不会去查缓存） 那这时候程序就会无限循环下去了(当然 spring会检测到这种异常,中断这次getBean) 所以，prototype类型的循环依赖是不能被解决、也不允许出现的 伪代码大致可以理解为： 1A a = new A(new B().setC(new C().setA(new A().setB(......)))); 总结 至此，循环依赖的讨论到此结束。其实，说白了就是： 只有[单例Bean之间]的的循环依赖才能被解决(因为只有单例Bean会被缓存到2级/3级缓存中 用以解决循环依赖) 只有[基于Setter属性注入]循环依赖才能被解决(因为只有基于Setter属性注入的Bean，才能在通过new调用构造方法后，把bean放入2级/3级缓存) [构造注入] 和 [prototype类型的bean]的循环依赖无法被解决 （因为没办法放入2级/3级缓存中）","link":"/Spring/Spring-Circular-Dependencies.html"},{"title":"架构已阅文档","text":"架构已阅文档 数据库相关 - 数据库索引，到底是什么做的 这篇文章还介绍了二叉搜索树,B树与B+树之间的区别 - 1分钟了解MyISAM与InnoDB的索引差异 - MySQL不为人知的主键与唯一索引约束 主要讲了MyISAM与InnoDB违反唯一索引时的场景,MyISAM会出现一个update语句，部分执行成功，部分执行失败(因为不支持事务) 分库分表 - 一分钟掌握数据库垂直拆分 - 炸！业界难题，跨库分页的几种常见方案","link":"/bookmarks/bookmarks.html"},{"title":"其他一些研发规范","text":"目录接口篇 接口篇 异常处理与日志篇 数据库篇 MQ篇 Redis篇 单元测试篇","link":"/code-rules/Code-Rules.html"},{"title":"目录接口篇","text":"1234567891011121314151617181920212223242526272829gds-parent 根目录 gds-wms-parent 仓库运营系统服务 gds-wms 仓库运营系统服务 src common 公共类 utils 工具类 命名以Util结尾的类 domain 业务对象 enums 枚举类 exception 放自定义异常类 mapper 如果用JPA操作数据库用repository 放命名以Repository结尾的类, 用mybaits操作数据库用mapper 放命名以Mapper结尾的类 remote 远程调用，放fegin调用接口 consumer 存放[调用]外部Feign服务的类 命名以Client结尾 fallback 存放consumer调用降级处理类 命名以FallbackFactory结尾 provider 存放对外提供的HTTP(Feign)类 命名以Remote结尾 service 放业务逻辑处理接口 命名以Service结尾的类 impl 放业务处理实现`类 命名以对应接口名+Impl结尾的类(后面同理) web 放controller 命名以Controller结尾的类 ... resources mapper 存放sql的xml文件 static 存放静态资源(js/css/img....) templates 存放页面模板 error 存放错误相关的页面 wms 存放业务相关的页面 gds-wms-api 仓库运营系统服务Api gds-wos-parent 仓库作业系统服务 gds-wos 仓库作业系统服务 gds-wos-api 仓库作业系统服务Api","link":"/code-rules/directory-code-rules.html"},{"title":"接口篇","text":"以下为以前开发自己设定的一些规范，供以后参考 1. 返回类型 所有接口返回类型都为ResponseMsg 除了与外界交互的接口,不允许其它返回类型为ResponseMsg的方法 2. 对外接口请求路径规则 提供给app用的接口统一以[/app]开头 提供给外部系统调用的接口统一以[/api]开头 提供给页面的接口统一以[/page]开头 3. Controller层做的事情 组装/校验参数 仅调用 “1次” Service层服务 组装返回ResponseMsg返回给调用方 其它补充 不要在Controller层写任何数据库操作的逻辑！包括查询！ 所有业务操作都放在Service层！Controller层只用来做校验，以及组装返回值！ 请务必注意！务必！务必！","link":"/code-rules/interface-code-rules.html"},{"title":"异常处理与日志篇","text":"异常处理 异常处理不需要手动输出日志 - 全局异常处理会帮你做这件事 遇到的所有异常都包装成[业务异常]or[系统异常]后往上抛 业务异常(校验异常等) 对应类:BusinessRuntimeException 常用方法: 1. throw BusinessRuntimeException.buildBusyException(EnumCommomSysErrorCode.MQ_ERROR, “消费异常”, parm); 2. throw BusinessRuntimeException.buildBusyException(parm,EnumCommomSysErrorCode.MQ_ERROR,); 系统异常(404,MQ联不通等) 对应类:SystemRuntimeException 常用方法: 1. throw SystemRuntimeException.buildSysException(EnumCommomSysErrorCode.FILE_TYPE_NOT_SUPPORT, e, parm); 2. throw SystemRuntimeException.buildSysException(EnumCommomSysErrorCode.FILE_TYPE_NOT_SUPPORT, “文件类型不支持”,e, parm); 业务日志打印 对HTTP请求(Controller)进来参数,不需要打印(对于Dubbo/MQ等入参还是需要打印的) - 已经做了拦截器全局进行打印","link":"/code-rules/exception-and-log-code-rules.html"},{"title":"数据库篇","text":"脚本提交 统一使用Flyway进行统一的管理 svn://172.16.30.16:20044/G2G_DS/trunk/WMS/wms_db_script Dao操作相关 对数据库表更新/删除操作不能使用ID作为’第一’条件, 如 错误用法 1update parcel set a=&quot;value&quot; where id=123 正确用法 应用业务主键作为条件 1update parcel set a=&quot;value&quot; where fpxTrackingNo=&quot;fpx20190402&quot; 数据库查询不允许使用select *, 应使用select a,b,c","link":"/code-rules/db-code-rules.html"},{"title":"MQ篇","text":"MQ队列命名规范 业务线_队列的生产者项目名_消费的项目名称_[Q/R/X]_自定义标识 如 : GDS_WMS_WOS_Q_FORECAST 对应的Exchange名为:GDS_WMS_WOS_X_FORECAST 对应的Routing key名为:GDS_WMS_WOS_R_FORECAST ; 对应的死信队列名为:GDS_WMS_WOS_Q_FORECAST_DEAD 对应的死信Exchange名为:GDS_WMS_WOS_X_FORECAST_DEAD 对应的死信Routing key名为:GDS_WMS_WOS_R_FORECAST_DEAD 生产者队列的消息统一通过 [MQ的shovels插件] 转发到消费者队列 生产者不需要创建死信队列 消费者队列必须测试一下消息失败是否会进入对应的死信 这,很重要 MQ队列/Exchange 定义规范 [生产者端]需要定义队列+Exchange 并且建立队列和Exchange的绑定关系 队列需要定义: durable=true exclusive=false, autoDelete=false 队列创建使用rabbitAdmin.declareQueue(queue); 防止队列窜到别的VH中 Exchange 需要定义 durable=true autoDelete=false Exchange创建使用rabbitAdmin.declareExchange(exchange);防止队列窜到别的VH中 建立绑定关系 rabbitAdmin.declareBinding(BindingBuilder.bind(queue).to(exchange).with(“GDS_WMS_WMS_R_TASK_ASYNC_CONSUME”)); 例子 1234567//定义队列Queue queue = new Queue(&quot;GDS_WMS_WMS_Q_TASK_ASYNC_CONSUME&quot;, true, false, false);DirectExchange exchange = new DirectExchange(&quot;GDS_WMS_WMS_X_TASK_ASYNC_CONSUME&quot;, true, false);rabbitAdmin.declareQueue(queue);rabbitAdmin.declareExchange(exchange);rabbitAdmin.declareBinding(BindingBuilder.bind(queue).to(exchange).with(&quot;GDS_WMS_WMS_R_TASK_ASYNC_CONSUME&quot;)); [消费者端]需要定义队列+Exchange 死信队列+死信Exchange 并且建立队列和Exchange的绑定关系 队列/死信队列需要定义: durable=true exclusive=false, autoDelete=false 队列创建使用rabbitAdmin.declareQueue(queue); 防止队列窜到别的VH中 Exchange/死信Exchange 需要定义 durable=true autoDelete=false Exchange创建使用rabbitAdmin.declareExchange(exchange);防止队列窜到别的VH中 建立绑定关系 rabbitAdmin.declareBinding(BindingBuilder.bind(queue).to(exchange).with(“GDS_WMS_WMS_R_TASK_ASYNC_CONSUME”)); 例子 123456789101112131415//定义队列Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(2);map.put(&quot;x-dead-letter-exchange&quot;, &quot;GDS_WMS_WMS_X_TASK_ASYNC_CONSUME_DEAD&quot;);map.put(&quot;x-dead-letter-routing-key&quot;, &quot;GDS_WMS_WMS_R_TASK_ASYNC_CONSUME_DEAD&quot;);Queue queue = new Queue(&quot;GDS_WMS_WMS_Q_TASK_ASYNC_CONSUME&quot;, true, false, false, map);DirectExchange exchange = new DirectExchange(&quot;GDS_WMS_WMS_X_TASK_ASYNC_CONSUME&quot;, true, false);rabbitAdmin.declareQueue(queue);rabbitAdmin.declareExchange(exchange);rabbitAdmin.declareBinding(BindingBuilder.bind(queue).to(exchange).with(&quot;GDS_WMS_WMS_R_TASK_ASYNC_CONSUME&quot;));//定义预报的死信队列(若配置转发生产者不需要定义死信队列)Queue deadQueue = new Queue(&quot;GDS_WMS_WMS_Q_TASK_ASYNC_CONSUME_DEAD&quot;, true, false, false);DirectExchange deadExchange = new DirectExchange(&quot;GDS_WMS_WMS_X_TASK_ASYNC_CONSUME_DEAD&quot;, true, false);rabbitAdmin.declareQueue(deadQueue);rabbitAdmin.declareExchange(deadExchange);rabbitAdmin.declareBinding(BindingBuilder.bind(deadQueue).to(deadExchange).with(&quot;GDS_WMS_WMS_R_TASK_ASYNC_CONSUME_DEAD&quot;));","link":"/code-rules/MQ-code-rules.html"},{"title":"Redis篇","text":"redis缓存Key规范 Key前缀统一使用常量: ConstantsString.RedisConstant.REDIS_CACHE_PREFIX","link":"/code-rules/MQ-code-rules.html"},{"title":"单元测试篇","text":"关于测试类的规范 (暂定) 单元测试应该是不依赖于别的单元测试的 所有单元测试应该都得回滚，如果存在异步处理的情况，应尽可能把主线程与fork线程拆成2个测试类方法进行测试 每个测试类／测试方法应写上对应的名称@DisplayName 每个接口，都必须写一个正向测试方法 关于测试类的类名：测试类与被测试的类的路径需要一致，名字也需要对应，如： 123com.fpx.wms.service.impl.InstockServiceImpl↓对应↓com.fpx.wms.service.impl.InstockServiceImplTest 关于测试类的方法名： 方法名尽可能为成功的条件如shouldSuccessAfterPay()，而方法具体用来测试哪个场景的，我们已经使用了@ DisplayName来描述，无须担心 对于结果，需要适应assert断言输出与结果是否一致（这才能算是一个单元测试） 断言统一使用AssertJ框架，使用Assertions.assertThat()进行处理 可以参考\\gds-parent\\gds-wms-parent\\gds-wms\\src\\test\\java\\com\\fpx\\gds\\wms\\service\\exceptionhandle\\impl在SVN版本为2962时提交的代码为参考","link":"/code-rules/JUnit-code-rules.html"},{"title":"待办篇","text":"待办目录 [X] 基于Junit5的新测试用例规范 [ ] 基于新测试用例的demo [ ] MQ重复消费问题解决 [X] 根据请求ID追踪调用链所有日志 系统改造 [ ] 新建GDS公用工程,存放Wms与Wos公用代码(暂定)","link":"/code-rules/todo-code-rules.html"},{"title":"MySQL锁","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/database/innodb-record-level-locks.html 官方参考 MySQL锁 InnoDB锁机制是基于索引建立的 如果SQL语句中匹配不到索引,那么就会升级为表锁 记录锁 1234-- id 列为主键列或唯一索引列SELECT * FROM table WHERE id = 1 FOR UPDATE;或update table set age=2 WHERE id = 1; 通过唯一索引实现的记录锁,只会锁住当前记录(必须为=不然会退化为临键锁) 间隙锁 间隙锁只有在事务隔离级别 RR(可重复读) 中才会生效. 为非唯一索引组成(如class,age等) 1select student where age&gt;26 and age&lt;28 lock in share mode ; 使用间隙锁的条件 命中普通索引锁定； 使用多列唯一索引； 使用唯一索引命中多行记录 临键锁(Next-key Locks) 临键锁只有在事务隔离级别 RR(可重复读) 中才会生效 是记录锁与间隙锁的组合 可以是唯一索引,也可以是非唯一索引,对其都以间隙锁的形式进行锁定(以唯一索引匹配,并且只匹配到一条数据除外) 临键锁(Next-key Locks) 例子: tno(唯一索引) tname tsex tbirthday prof depart age(非唯一索引) 858 张旭 1 1969-03-12 讲师 电子工程系 25 857 张旭 女1 1969-03-12 讲师 电子工程系 25 856 张旭 男 1969-03-12 讲师 电子工程系 25 831 刘冰 女 1977-08-14 助教 电子工程系 29 825 王萍 女 1972-05-05 助教 计算机系 28 804 李诚 男 1958-12-02 副教授 计算机系 26 其中有唯一索引的临键为: (-∞,804] (804,825] (825,831] (831,856] (856,857] (857,858] (858,+∞] 其中有非唯一索引的临键为: (-∞,25] (25,26] (26,28] (28,29] (29,+∞] 非唯一索引临键锁验证 123-- session1select * from teacher WHERE age between 26 and 28 lock in share mode ; 这时候会锁定非唯一索引的临键 (25,29] 所以我们测试更新age=25成功 插入age=27阻塞 更新age=29阻塞 插入age=30成功即可验证 12345678910111213-- session2-- 更新age=25--&gt;成功update teacher set tsex='女1' WHERE age=25;-- 插入age=27阻塞insert into `test`.`teacher` ( `tno`, `tname`, `tsex`, `tbirthday`, `prof`, `depart`,`age`) values ( '740', '张旭1', '12', '1969-03-12 00:00:00', '讲师', '电子工程系',27);-- 更新age=29--&gt;阻塞update teacher set tsex='女1' WHERE age=29;-- 更新age=30--&gt;成功insert into `test`.`teacher` ( `tno`, `tname`, `tsex`, `tbirthday`, `prof`, `depart`,`age`) values ( '740', '张旭1', '12', '1969-03-12 00:00:00', '讲师', '电子工程系',30); 唯一索引临键锁验证 12-- session1select * from teacher WHERE tno between &quot;831&quot; and &quot;856&quot; lock in share mode ; 根据上面的sql,我们匹配到唯一索引临键锁为:(825,857] 所以我们测试更新tno=825--&gt;成功 更新tno=857阻塞 更新age=858成功即可验证 123456-- 更新tno=&quot;825&quot;--&gt;成功update teacher set tsex='女1' WHERE tno=&quot;825&quot;;-- 更新tno=&quot;857&quot;--&gt;阻塞update teacher set tsex='女1' WHERE tno=&quot;857&quot;;-- 更新tno=&quot;858&quot;--&gt;成功update teacher set tsex='女1' WHERE tno=&quot;858&quot;;","link":"/database/innodb-record-level-locks.html"},{"title":"使用mycat后注意要点","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/database/careful-when-use-mycat.html 忙死，简单贴个笔记截图吧 主要就是注意一下mycat分发sql给到对应1~n个数据库,其数据库都会执行这一条sql,然后再去mycat那里聚合结果,所以要注意一下sql的写法 一些笔记","link":"/database/careful-when-use-mycat.html"},{"title":"分库分表","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/database/sub_library_and_sub_table.html 学习自：单KEY业务，数据库水平切分架构实践 | 架构师之路 一些笔记 图中水平分库的基因法虽然好用，但是只支持2个字段的分库，如果要支持2个字段以上，那么就得使用索引表法了，缺点是需要多查一次表。","link":"/database/sub_library_and_sub_table.html"},{"title":"ES文档结构优化","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/es-structure-optimization.html 一个不错的优化： 背景 因为我们对订单的ES索引模板中，orderExtendInfoList存储多个扩展属性，用作外部订单号、二程运单号等信息的存储，业务上需要对其作为条件进行索引，为此我们把他设置为嵌套nested类型。 偶然学习发现这种嵌套nested类型会导致每个订单下的orderExtendInfo都会生成多个文档，导致索引数据量放大几倍，会导致查询性能下降，故重新设计进行优化。 优化ES存储订单数据的结构 把orderExtendInfoList打平并改为keyword类型（原来为嵌套类型）, 内部额外存储一个作为索引用的值为原orderExtendInfo的key和value对应的Map 描述起来比较麻烦 大概是把下图左边的变成变成右边的 效果 4亿+数据量减少到只剩下5kw数据量，降低了十倍左右 查询时的CPU与内存压力均降低10%左右","link":"/design/es-structure-optimization.html"},{"title":"记一次ES查询优化","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/ES-Query-Optimization.html 背景 难得有数据留存,写一篇^_^ 原逻辑 ES接收新单、改单、状态数据（占总数据的70%），写入ES的7天索引中 ES存在以天为单位的7个索引（如：20210101~20210107，7个索引） 存储逻辑： 根据订单创建时间，保存到对应月日的索引内，如：1月1日的保存到20210101 如果不再最近7天内的特殊订单,那么会存到今天最新的一天的索引内 查询查询: 接收到查单请求后，根据订单创建时间，根据月日指定去查询这7个索引的某一个或多个 如果是在最近7天的，那么保存到该日期对应的索引内 如果在最近7天以外的订单，那么会保存到今天最新的一天的索引内 更新逻辑: 先查询出原来的订单，然后更新，更新后保存到原来的索引内 初步分析 监控问题分析 大数据监控显示：在双十一前后ES监控IO读写次数过高，出现读/写拒绝，CPU占用高，初步分析主要原因有以下： 量大：写入ES的数据为新单、改单、状态变化3种，其中状态变化占据最多，共2亿/天的量 查询多：接收新单、改单、状态都需要查询一次ES 大部分查询无法使用索引：状态数据没有有效索引，会触发ES全局查询 初步分析人话结论 其实之中最主要的问题是因为接收状态数据的时候，没有创建时间字段，导致触发了ES全索引查询 状态数据量大，占大头，导致触发ES查询的量占超过70%，蛇打七寸，解决状态数据的查询问题，基本就可以解决问题了 场景论证 原逻辑场景分析 场景1 改单数据在7天外 操作状态数据无CreateTm字段，故7天内的单对应的状态与7天外的改单一致 有效查询率： 仅为1/35=2.85% 场景2 下改单数据为7天内的数据 有效查询率： 仅为1/5=20% 思路与方案 思路 其实经过场景论证后思路很明显，真正的问题所在便是接收新单、改单、状态数据的时候时间字段无法很有效地为ES查询指定分区，导致一个查询查了7个索引。 那么，问题解决思路就简单了： 为新单、改单、状态数据选择新的字段匹配ES索引，不再使用或者不再仅使用createTm字段 如1无法实现，ES换一个索引分区方式，如按照地区分区 很幸运的是，在思路1中，我们的内部订单号里包含着订单的创建时间，所以我们可以直接使用订单号来匹配ES索引，这样就可以很好地解决问题了。 优化方案 根据订单号规则，优化索引： 订单号00415022212022830806377748，其中0222为为订单生成日期 故直接以其为分区素引，直接查询、 更新该素引，根据场景不同至少减 少6/7的查询量 Other More 其实在上面演示的图解里还能发现，在每个索引里还存在5个分片，也许是因为当初大数据团队操作问题又或是什么原因没有把内部订单号作为ID， 导致通过内部订单号到ES查询订单信息的时候，ES会把这个订单号的所有分片都查询一遍，这也是导致ES查询量过大的一个原因。 额外优化 通过ES-API 指定查询路由/D，可以指定查询到唯一—个分片，减少80%的查询量 优化后 优化后逻辑 优化后逻辑(7天外）减少6/7(85.7%)查询量 优化后逻辑(7天内）减少4/5(80%)查询量 优化后效果(监控)","link":"/design/ES-Query-Optimization.html"},{"title":"Hystrix熔断优化","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/Hystrix-optimization.html 简述 本文说的其实就是 合理配置熔断，防止依赖的第三方接口响应过慢导致系统tomcat链接大量阻塞，最终导致系统崩溃的问题 顺便，将熔断配置从配置文件中提取出来，动态配置中心中，这样就可以通过动态配置中心来动态配置熔断参数了 除此，主要是团队里大家对单线程并发数与QPS概念有些混淆且计算方式了解不多，以及信号量与线程池方案选择上有些歧义，需要花了不少时间在会议上让团队达成一致。 背景&amp;分析问题 SISP客服系统、SISP查单系统等系统提供的服务都通过HTTP依赖于大量外部各种接口的响应， 这些接口的响应时间不可控，有时候会出现响应时间过长的情况，这时候如果不做任何处理，那么这些请求就会一直等待，这样就会导致系统的响应时间过长，甚至出现系统崩溃的情况。 双十一期间，SISP客服系统出现了系统崩溃问题，经排查发现tomcat线程池被耗尽，进一步排查是因为所依赖的PIS接口响应慢了 简单来说问题大概长这样： 其实在进入团队前，其实关键服务已经配置了相关的熔断，不过仔细看了下配置：execution.isolation.semaphore.maxConcurrentRequests=100000 这代表着需要同时有100000个线程进入该程序里才有可能触发熔断，在这种接口响应缓慢要死不死的情况下简直形同虚设 而hystrix错误率50%因为时间窗口太短+外部接口可用性也并不是在50%以下,难以触发,故难以触发熔断机制,导致系统崩溃; 以下是系统曾经的配置: 123456789101112131415161718@HystrixCommand( fallbackMethod = &quot;singleBack&quot;, commandProperties = { @HystrixProperty(name = &quot;execution.timeout.enabled&quot;, value = &quot;false&quot;), // 该属性用来设置在滚动时间窗中，断路器熔断的最小请求数。例如，默认该值为 20 的时候， // 当在配置时间窗口内达到此数量19的失败后，进行短路,默认20。 @HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;, value = &quot;20&quot;), // 该属性用来设置在滚动时间窗中，表示在滚动时间窗中，在请求数量超过 circuitBreaker.requestVolumeThreshold 的情况下， // 如果错误请求数的百分比超过50, 就把断路器设置为 &quot;打开&quot; 状态，否则就设置为 &quot;关闭&quot; 状态。 @HystrixProperty(name = &quot;circuitBreaker.errorThresholdPercentage&quot;, value = &quot;50&quot;), // 滚动时间窗设置，该时间用于断路器判断健康度时需要收集信息的持续时间.默认：10000 @HystrixProperty(name = &quot;metrics.rollingStats.timeInMilliseconds&quot;, value = &quot;10000&quot;), // 该属性用来设置当断路器打开之后的休眠时间窗。 休眠时间窗结束之后，会将断路器置为 &quot;半开&quot; 状态，尝试熔断的请求命令， // 如果依然失败就将断路器继续设置为 &quot;打开&quot; 状态，如果成功就设置为 &quot;关闭&quot; 状态。默认：5000 @HystrixProperty(name = &quot;circuitBreaker.sleepWindowInMilliseconds&quot;, value = &quot;10000&quot;), @HystrixProperty(name = &quot;execution.isolation.strategy&quot;, value = &quot;SEMAPHORE&quot;), @HystrixProperty(name = &quot;execution.isolation.semaphore.maxConcurrentRequests&quot;, value = &quot;100000&quot;) }) 方案论述 看出问题就得出方案了，其实上面问题总结来说就2点： 1. 熔断配置在配置文件中，不方便动态调整（人看着都已经出问题了，还不能手动熔断快速恢复，领导都急疯了hhh） 2. 熔断配置maxConcurrentRequests不合理，导致熔断不起作用 maxConcurrentRequests配置 对于1.就不做过多叙述了，对于2.这里与团队成员有点分歧。。。 他们认为maxConcurrentRequests应该配置为接口的并发数。。。实际上，这个配置应该是单个节点最大并发数，而不是接口的并发数，这里花了我不少时间给团队成员解释这个问题。。。有点醉了。。。 这里简单说下，如果是单节点调用，那么maxConcurrentRequests就是接口的并发数，如果是多节点调用，那么maxConcurrentRequests就是单个节点的并发数 所以得出QPS和RT的关系： 对于单线程：QPS=1000/RT 对于多线程：QPS=1000*单节点并发线程数量/RT 对于多线程多接点：QPS=1000单节点并发线程数量节点数量/RT 因此，我们可以得出： 123maxConcurrentRequests（单节点线程数） = QPS /节点数/ ( 1000 / 被熔断方法的P99耗时ms )即:27000/128/(1000/20)=4.2QPS 所以得出,maxConcurrentRequests配置为5,理论上即可满足需求。 考虑到我们主要是为了解决单节点因为单个服务耗光tomcat容器所有http线程，这个值不需要设置得太严格，只要能保证单节点不会因为单个服务耗光tomcat容器所有http线程即可。所以，我们保守地设置为100 其实查阅官网，maxConcurrentRequests默认是10，并且说对于绝大部分、正常服务，一般来说都不需要修改这个值，他可以很好的满足绝大部分的场景，一定程度上说明我们上面求出的服务的maxConcurrentRequests=5也算是合理的 Other More 部门新来了架构师，在我在团队方案论述的说Hystrix就得用线程池，不要用信号量，他们以前公司就是这样用的，他和网上也推荐这样用，说可以异步、不占用tomcat线程什么的。 也许这个架构师不太理解我们的系统，又或者多Hystrix有什么误解，又或者过于相信网上的言论，当然，也可能是我个人理解有误，但是我觉得这个方案是不合理的，我这里说下我的理解： （信号量和线程池的区别这里就不多叙述了，自查吧 ） 因为我们系统有大量面向前端的服务，这些服务很多都依赖于其他第三方接口服务，如果每个都加上熔断，每个都设置自己的线程池，那么将会是一个恐怖的线程开销； 同时，我们99%的前端、后端业务调用这些服务，都需要这些服务有一个同步的响应，因此额外开线程池，释放tomcat线程就无从说起了，因此线程池的方式并不适合我们的场景。 因此当时否决回去了，但因团队成员坚持保守看法，所以后面又开了个会论述了一下这个事，终于如愿达成一致，最后还是采用了信号量的方式。 关键代码 动态配置关键代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 描述：熔断配置加载类，项目启动时会加载一次，然后修改动态配置中心的配置时会自动加载 * * &lt;pre&gt; * HISTORY * **************************************************************************** * ID DATE PERSON REASON * 1 2022/7/6 01390559 Create * **************************************************************************** * &lt;/pre&gt; * * @author Chris Cai * @version 1.0 */@Component@DisconfFile(filename = HystrixConfig.HYSTRIX_CONFIG_NAME)@DisconfUpdateService(classes = {HystrixConfig.class})public class HystrixConfig implements InitializingBean { /** * 熔断配置文件名 */ public static final String HYSTRIX_CONFIG_NAME = &quot;hystrix.properties&quot;; private static final Logger logger = LoggerFactory.getLogger(HystrixConfig.class); private static final int REFRESH_TIME = (int) TimeUnit.SECONDS.toMillis(30L); @Override public void afterPropertiesSet() { // 读取配置文件实现类 PolledConfigurationSource source = newConfigurationSource(); // 设置定时器，每隔30s检查一次读取一次配置文件 AbstractPollingScheduler scheduler = new FixedDelayPollingScheduler(REFRESH_TIME, REFRESH_TIME, false); // 创建动态配置类，并设置定时器和配置文件读取类，如配置发生变化，会更新对应的配置属性 DynamicConfiguration configuration = new DynamicConfiguration(source, scheduler); // 加入配置管理器 ConfigurationManager.install(configuration); } // 具体轮询业务逻辑 private PolledConfigurationSource newConfigurationSource() { return (initial, checkPoint) -&gt; { Properties properties = new Properties(); try (InputStream is = Thread.currentThread().getContextClassLoader().getResourceAsStream(HYSTRIX_CONFIG_NAME)) { properties.load(is); } catch (Exception e) { logger.error(&quot;fail load hystrix configs&quot;, e); throw e; } return PollResult.createFull((Map) properties); }; }} 熔断配置文件 各个服务通用default,各个服务可以单独配置，配置会覆盖default配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182### 全局默认配置 实例配置刷新清空时会临时取全局默认配置## 执行/隔离策略hystrix.command.default.execution.isolation.strategy=SEMAPHORE## 最大同时处理请求数hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests=100000hystrix.command.default.execution.timeout.enabled=false#熔断开关hystrix.command.default.circuitBreaker.enabled=true#熔断开关 如果为true 将会拒绝所有请求进入降级方法hystrix.command.default.circuitBreaker.forceOpen=false#熔断开关 如果为true 将会强制关闭熔断功能,无论错误百分比如何,它都会允许请求hystrix.command.default.circuitBreaker.forceClosed=false##该属性用来设置在滚动时间窗中,断路器熔断的最小请求数。例如,默认该值为 20 的时候,##当在配置时间窗口内达到此数量19的失败后,进行短路,默认20。hystrix.command.default.circuitBreaker.requestVolumeThreshold=20## 该属性用来设置在滚动时间窗中,表示在滚动时间窗中,在请求数量超过 circuitBreaker.requestVolumeThreshold 的情况下,## 如果错误请求数的百分比超过50, 就把断路器设置为 &quot;打开&quot; 状态,否则就设置为 &quot;关闭&quot; 状态。hystrix.command.default.circuitBreaker.errorThresholdPercentage=50##该属性用来设置当断路器打开之后的休眠时间窗。 休眠时间窗结束之后,会将断路器置为 &quot;半开&quot; 状态,尝试熔断的请求命令,##如果依然失败就将断路器继续设置为 &quot;打开&quot; 状态,如果成功就设置为 &quot;关闭&quot; 状态。默认:5000hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds=5000##滚动时间窗设置,该时间用于断路器判断健康度时需要收集信息的持续时间.默认:10000毫秒.hystrix.command.default.metrics.rollingStats.timeInMilliseconds=10000### 实例配置 ###### 备注脱敏接口熔断配置## 最大同时处理请求数hystrix.command.remarkMask.execution.isolation.semaphore.maxConcurrentRequests=100### 运单查询接口熔断配置## 最大同时处理请求数hystrix.command.waybillQuery.execution.isolation.semaphore.maxConcurrentRequests=100### 批量运单查询接口熔断配置## 最大同时处理请求数hystrix.command.batchWaybillQuery.execution.isolation.semaphore.maxConcurrentRequests=100### 批量子单查询接口熔断配置## 最大同时处理请求数hystrix.command.batchChildWaybillQuery.execution.isolation.semaphore.maxConcurrentRequests=100### 历史运单查询接口熔断配置## 最大同时处理请求数hystrix.command.hisWaybillQuery.execution.isolation.semaphore.maxConcurrentRequests=100### 操作运单DSL查询接口熔断配置## 最大同时处理请求数hystrix.command.dslWaybillQuery.execution.isolation.semaphore.maxConcurrentRequests=100### 综合查单接口熔断配置## 最大同时处理请求数hystrix.command.conditionsWaybillQuery.execution.isolation.semaphore.maxConcurrentRequests=100### PIS时效查询接口熔断配置## 最大同时处理请求数hystrix.command.pisTimeQuery.execution.isolation.semaphore.maxConcurrentRequests=100### 对内路由查询接口熔断配置## 最大同时处理请求数hystrix.command.insideRoute.execution.isolation.semaphore.maxConcurrentRequests=100### 对外路由查询接口熔断配置## 最大同时处理请求数hystrix.command.outsideRoute.execution.isolation.semaphore.maxConcurrentRequests=100","link":"/design/Hystrix-optimization.html"},{"title":"Kafka延时队列方案探讨","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/Kafka-Delay-Queue.html 目前在用方案:直接重新丢回队列后面 实现逻辑 引入延迟消息消费服务,消费延迟消息 每条消息消费时,Sleep3秒(很长),再处理; 处理时判断是否到点,没到点的数据丢回kafka 优点 不引入新依赖(不依赖DB,不依赖其他第三方) 缺点 1. 处理效率慢,并发低 2. 延时时间不精准,颗粒度非常大 3. 浪费Kafka空间,同一数据在Kafka多次存储(其实Kafka底层是一种文件/文档存储,消息的消费只读不删) 优化方案1: 延迟消息存DB,通过Redis的zset结构支持 ### 实现逻辑 #### 1. 发送延时消息: > 延时消息发送到延时队列TopicA ### 2. 消费延时消息: > 延时程序(消费者)消费延迟队列的消息,把延时消息存入DB,再把[发送时间]+[延时消息在DB记录ID]作为zset设到Redis ### 3. 监控&&发送[到时的消息]: > 1. 通过监控程序,监控Redis 发现[到时的任务],发送到真正的消费队列 进行真正的业务处理 > 2. 标识消息为已处理 或 删除(数据量大选立即删除,否则还是选择存几天,方便异常补数据) 缺点 强依赖Redis，数据存在: Redis出现异常会或会出现1s的数据丢失,补偿方案实现麻烦、效果不好(1.人工发现,人工通过日志/DB补偿 2.程序定时比对补偿) 会出现数据倾斜: 单个队列数据量大时,Redis会出现数据倾斜,导致Redis单点数据量大,更容易出现热点数据&amp;单点容量不足的问题 (这一点可以通过key,优化解决,就是每次存的时候麻烦点) 优化方案2: 分级队列+sleep方案 [分级延迟后面(5分钟 10分钟 30分钟…)] 实现逻辑 1. 根据需求,丢到对应的延迟主题中,如5分钟延迟主题 2. 五分钟主题按顺序消费前面的一条or多条数据时,判断该消息是否到达延迟时间,没到时间就sleep对应的时间; 到时间就消费掉&amp;&amp;发到业务主题中 (PS.得带上当前延迟主题分级DelayLevel，延迟次数tryCount，以方便业务主题消费失败时根据需求进行增量延迟操作) 3. 业务主题消费者消费时,根据[重试次数tryCount]&amp;[延迟主题分级DelayLevel]以及消费情况 决定正常消费掉消息 还是 丢到之前或别的分级延迟主题中； 缺点 1. Sleep太久，kafka会认为该消费者不可用，然后把消息给到别的消费者。。。 优化方案3: 分级队列方案+原生wait方案 缺点 1. 文档难找。。。没找到wait接口怎么用。。。只找到特性","link":"/design/Kafka-Delay-Queue.html"},{"title":"【Hbase优化_2】Hbase存储优化：Hbase数据压缩","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/hbase-data-compress.html 背景 接: 【Hbase优化_1】HBase 行键设计优化：解决数据倾斜问题 随着业务扩张，Hbase使用率越来越高，大数据那边反馈已经没有资源了，全公司都没有了，要扩资源得等公司出去采购，可以的话问我们能否看能不能优化一下Hbase存储，减少一下空间占用。 基于SISP巴枪数据使用业务场景，每行数据是整体从HBase中查询出来，不存在通过字段过滤查询数据、以及只查询某些字段的使用场景，都是将整条数据拿出来、或者整个运单的所有巴枪数据拿出来解析 方案 在可以放弃根据字段过滤的前提下，可以整行巴枪数据序列化存储到HBase。在查询数据时，再将数据做反序列化。序列化可以大幅减少空间占用。以下数据基于本地测试，使用 protobuf 方式进行序列化. 同时，对于历史数据集群，因为其存储为多列数据，因为不需要根据字段过滤，把字段合并为一列，减少列数，也进一步减少空间占用。 预计效果 基于当前实时和历史两个HBASE集群占用的空间大小，可以大致计算出序列化后所需要的 region 数量 （ 超过10g就算大的region 查询会慢些，region超过20g会自动分裂 。每台机器region不要超过500，超过500就会影响性能。 ） 当前集群情况 集群 当前集群占用 当前机器数量 当前集群region数量 实时数据集群 83692GB 18台 20762 历史数据集群 527976GB 32台 24845 预计优化后集群情况 集群 当前集群占用 当前机器数量 当前集群region数量 实时数据集群 36825GB(原来的44%) 18台 1800 历史数据集群 58078GB(原来的11%) 32台 2900 切换方案 生产上分为实时库与历史库，分别存3+1个月与1年。因为实施方案一样，这里只介绍实时库： 上线后3+1个月内读取方式不变，写库时改为新方案双写，以新规则写入新库同时也以旧的规则写入旧库 等3+1个月后，读取时只读取新库，写库时只写入新库 以上两步做一个开关，一键切换 半年后，删除旧库 题外话 这里最后因为使用了数据冗余的兼容过度方案，实际上在过度期间还浪费了不少Hbase资源，好在理论优化幅度确实高，领导们能批hhhh~","link":"/design/hbase-data-compress.html"},{"title":"Redis压缩方案设计--各种压缩方案单机的比较(CPU)","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/Redis-compress-design.html 1、 CPU性能对比（通过对比CPU时间） 对比论证： 选择序列化CPU使用率最低，约原来的16%~73%，其中FST序列化方式为原来的16%，速度最快 选择纯字符串压缩的方式因为是在原toJSON和parseObject的逻辑之间,再加入压缩逻辑,故性能比原生JSON会略差一些 （对比序列化&amp;压缩方案）每轮十万次测试 压缩方案单轮测试耗时最高，为0.42s，约每次使用该方案消耗0.04ms，对比原方案单次多次0.01ms的CPU时间，故认为以上方案对性能的损耗问题可忽略 序列化方案单论测试耗时最低，为0.05s，约每次使用该方案可节约0.027ms的CPU时间,对比压缩方案,可节约0.037ms的CPU时间，故认为序列化对性能提升不高 总结 纯序列化方案占用CPU时间少，纯压缩方案占用CPU时间稍多，但是都对整体性能影响极小 2、使用序列化实践的方案（速度快，压缩度高） 2.0 简要 核心参考资料 FST @Version官方文档 序列化总结 背景 发送给下游与Redis存储的对象为同一个对象 原理 对象通过直接序列化转byte，考虑到对象后续需要新增字段，可通过添加注解的形式进行扩展（必须给每个字段都加上唯一注解,包括原有字段） 2.1 FST方案设计(只针对大对象) 方案1描述 直接在需要存入Redis的对象中为每个新增字段加入新注解,新字段顺序有要求得放在其他字段之后 在自己相关工程，升级下游依赖到的相关包的版本号（需要梳理） 存取Redis时，进行序列化反序列化操作 方案1优点 一劳永逸,改动小 方案1缺陷 下游引入新的额外无用依赖 需要梳理自己项目，有哪些jar包给下游依赖到了，得逐个进行升级（容易疏漏？） 存到Redis的对象,如果想阉割属性,比较困难(比较简单有效的方案还是得新建类) 方案2描述 copy一个和原来的类(称为A类)一致的类(称为A’类)，在A’类上添加注解 保存redis前，通过属性copy，把A对象Copy到A’对象中，最终序列化保存A’对象 读取Redis时，同理把反序列化读到的A’对象,Copy给A对象 方案2优点 容易存储Redis的对象阉割字段(如:我们对于对于A类里有个大属性:jsonObject，我们不想存，那么只需要在A’上去掉这个字段) 下游无感知 方案2缺陷 对于每个需要扩展字段的对象对应的类，都得存在2份，可能会导致新建了非常多的类（如订单里引用的所有类型 都可能需要被扩展。。。） 每次存取都需要进行copy操作 在添加字段时，容易把A’类给忘了 序列化方案其他缺陷(核心难点) 被序列化的类,其涉及到的相关所有类,都得注册到serializer中；且序列化反序列化得用同一个serializer 改造较为复杂容易出错，需要嵌入到目前项目的RedisCache工具类中 少注册类时，反序列化会出错，且难以排查 切换新方案后,以前的key无法匹配到了,需要重新cache一次 2.2、Snappy方案设计（速度比原来略慢约增加，压缩度较高可减少约50%(实际存到redis可减少到75%左右)）(只针对大对象) 方案描述(Snappy压缩字符串) 存Redis前，先通过JsonUtil.toJsonString得到Json字符串后，然后对json进行Snappy压缩后，再存入Redis； 取Redis时，先通过Snappy解压，再通过JsonUtil.parseObject转回对象 方案优点 简单，说白了其实就是存取加入了进行压缩解压操作 下游无感知 对老数据可做兼容,业务开发时字段增减不会影响 Redis&lt;–&gt;对象 的读写与转换 方案缺点 增加的压缩逻辑导致耗时在原来基础上增加30%左右的CPU时间，但10w次读写也就+1s的处理时间，影响","link":"/design/Redis-compress-design.html"},{"title":"缓存强一致性方案","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/cache-consistency-solution.html 背景 考虑到部分场景可能需要强一致性缓存： 后端更新时，需要保证使用端查询缓存时立马就能查询出最新的缓存值，且需要考虑并发场景导致的不一致情况 所谓的『强一致性』问题确认 首先，确认的是，我们讨论的一致性问题不是最终一致性这种，而是强一致性，前者可以通过数据库消费binlog设置缓存的形式实现，后者则需要考虑并发场景下的问题 方案设计–基于类似分布式锁实现 在后端更新数据库前，先将缓存值设置为『LOCK』，并设置一个过期时间，这个过期时间需要根据业务场景来设置，一般来说，这个过期时间需要大于后端更新缓存的时间，这样可以保证在后端更新缓存时，缓存值一直是『LOCK』状态 后端更新数据库、提交事务后，再将缓存值设置为『正常值』，这样就可以保证缓存值一直是『LOCK』状态 用户侧使用缓存前时先判断缓存值不为『LOCK』，为『LOCK』则阻塞等待更新完成，否则直接使用缓存值 至此，就可以保证缓存的强一致性了 可能的问题点 缓存频繁更新可能影响读取效率 redis故障或网络问题导致等缓存更新失败，会导致缓存处于『LOCK』状态一段时间，影响读取效率 结语 一般来说，这种场景下，缓存的更新频率不会很高，所以影响不大 以上场景在实际业务上其实比较少，更多的还是用延迟双删，或者消费binlog设置缓存实现近实时的最终一致性就行了","link":"/design/cache-consistency-solution.html"},{"title":"冷热分离场景分析&amp;实际业务落地","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/cold-hot-separation.html 前言 在数据库的读写研发中，我们遇到最多的可能就是数据量过多导致的『读/写慢』了。针对这些问题，我们一般主要会采取的措施有： 优化SQL 优化索引 优化硬件 分库分表 业务拆分 冷热分离 读写分离 这次我们主要讲讲冷热分离的实际使用场景，以及如何以前刚出来时候的项目实际落地方案。 冷热分离 使用冷热分离条件： 数据总量足够大，导致影响读写 冷数据不更新，只读。或者，冷数据更新频率极低，可以忽略不计 冷数据占比较大，热数据占比较小 以之前在联通做的一次工单业务为业务场景 每天新增工单10w左右，数据存放6个月，过期数据定期删除，项目上线6个月，数据库该表数据量预计大约有近2000w，上线到第四个月用户反馈工单查询/操作很慢。 问题分析排查 表数据95%以上都是已归档状态的工单 大部分用户、大部分场景下只关心未归档工单 上线后根据业务反馈，以及表数据排查，一般客服、业务人员对归档工单基本不会再去做查询 业务上不允许对已经归档的更新操作 以上场景满足冷热的使用条件，很适合做冷热分离，以下来看看我们具体怎么做的 解决方案 将归档工单单独拆分出来，单独存放一张表（归档工单表，即冷表），不参与查询 将工单表的查询功能进行拆分，拆分为『工单查询』、『归档工单查询』2个功能，其中『工单查询』查询工单表，『归档工单查询』查询工单归档表 落实的细节 工单归档时候，如何把数据move到冷表中（其实不在同个数据库） (✓)修改数据时，触发业务代码将数据同步到冷库的冷表中（我们采用的是这种，保证了实时性，而且是用了另一个库，采用XA的分布式事务） 具体是: 修改工单为归档时，先写冷表，再写热表，如果热表写失败，冷表回滚 优点：实时性高，数据准确性高 缺点： 业务代码需要改动，需要引入分布式事务（当然，其实也可以不引入分布式事务，这样做主要是快准狠） 消费binlog，（异步）将数据同步到冷库的冷表中 优点：这种方式业务代码不需要改动 缺点：实时性不高、需要canal这些数据库binlog同步工具 定时任务，将数据同步到冷库的冷表中 优点：这种方式业务代码不需要改动 缺点：需要定时任务、实时性不高 优化效果 优化后原表数据从近2000w减少到热表的不到100w的数据量，用户对其更新、查询响应效果明显大幅提升 问题 由于归档工单表数据量还是很大，对其查询效率也不高 当时只有mysql数据库，要做优化可以通过分区存储、或者分库分表存储 现在有了es、hbase这种大数据存储，现在看来，解决起来还是比较简单，无非是es存索引+hbase的rowkey，hbase存储实际数据 笔记 冷数据如何分离 业务修改时,同步到冷库 (异步)消费binlog (异步)定时任务扫表同步 前提：冷热分离硬性要求：冷数据不更新，只读。或者，冷数据更新频率极低，可以忽略不计 Other more 其实除了这些归档数据，一些大部分业务的历史数据也是可以做冷热分离的。 在顺丰这些公司也有不少类似功能，查询历史订单、运单、图片等数据，但因为数据量问题，冷库一般使用es、hbase这些大数据组件实现。 这次先写到这，后面再写『通过实际业务分析读写分离的使用场景』","link":"/design/cold-hot-separation.html"},{"title":"【Hbase优化_1】HBase 行键设计优化：解决数据倾斜问题","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/hbase-region-data-skew.html 这次分享/记录如何通过优化行键设计来解决 HBase 中的数据倾斜问题 在大数据场景下，我们的系统使用 HBase 存储了大量的巴枪信息。其中巴枪信息分布在两个表中，分别是巴枪索引表和巴枪主表。 生产中经常会出现Hbase超时问题，用户也经常反馈原始路由查询、巴枪扫描数据导出等功能查询时间过长、超时等问题。经过分析，发现这些问题的根本原因是 HBase 数据倾斜问题。 1. 巴枪信息表结构 1.1 巴枪索引表 表结构 rowKey: [3位0~499分区号][5位网点编码]|[4位巴枪码]|[操作14位时间字符串]|操作号 value: 巴枪主表的rowkey 示例 rowKey: 2700755W|0030|202204060000129|031801088694 1.2 巴枪主表 表结构 rowKey: [3位0~499分区号][12位运单号]|[4位巴枪码]|[14位时间字符串]|[操作号] value: 巴枪数据JSON字符串 示例 rowKey: 330SF1352340043135|0021|20220404213004|SF1352340043135 2. HBase 数据倾斜问题 由于运单号生成规则问题，运单号的前几位具有很高的相似度。HBase 在数据写入 Region 时，根据 rowKey 进行字符串排序。在 Region 达到阈值分裂后，会出现“数据倾斜”现象，即部分 Region 数据量很大，部分 Region 数据量很小。这会导致大量小 Region 出现，严重消耗 HBase 存储资源、查询资源，同时降低查询效率。 具体点就是: Hbase根据分区把数据写入Region后，其数据根据RowKey进行字符串排序，分裂的时候会根据字符串顺序，从大到小切分一半数据到两个Region内，如原Region数据为SF00000-SF99999，切分后可能就是SF00000-SF49999，SF50000-SF99999两个分区 因为运单号生成规则问题，前几位相似度很高，因此可见巴枪主表rowKey,除去分区号后，其前几位区分度很低，所以如果hbase Region达到阈值分裂之后，新数据写入会出现『数据倾斜』现象，一些Region很大，一些Region极小，长期写入数据后，会出现大量的小region 3. 优化方案 3.1 新的巴枪主表 rowKey 规则 新的 rowKey 结构 rowKey: [3位0~499分区号][运单逆序hash取模3位][先逆序运单号]|[4位巴枪码]|[14位时间字符串] 3.2 对比 方案 总 Region 数量 最大 Region 存储数 最小 Region 存储数 分区量 数据倾斜度 现有方案 5129 113277 1 多 大 新方案 2500 26461 25380 少 小 结论 新的 rowKey 设计方案可以大幅减少 Region 数量，数据倾斜度极小，从而有效解决数据倾斜问题。 3.3 生产切换方案 生产上分为实时库与历史库，分别存3+1个月与1年。因为实施方案一样，这里只介绍实时库： 上线后3+1个月内读取方式不变，写库时改为新方案双写，以新规则写入新库同时也以旧的规则写入旧库 等3+1个月后，读取时只读取新库，写库时只写入新库 以上两步做一个开关，一键切换 半年后，删除旧库 4. 总结 优化效果因为需要时间沉淀，所以暂无数据对比结果; 通过优化 HBase 行键设计，我们可以解决数据倾斜问题，提高查询效率，降低存储和查询资源消耗。 在实际应用中，根据具体场景和需求，我们需要灵活调整行键设计策略，以实现更高效的数据存储和查询 附录（自己看）","link":"/design/hbase-region-data-skew.html"},{"title":"snappy压缩redis方案可行性验证","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/snappy-compress-redis.html Snappy压缩方案 研发环境(redis单节点，两个哨兵) 1. 压缩率 压缩前的redis内存： String类型保存1万份不同key，相同value的运单内存为119.61-1.02=118MB： Byte[]类型保存1万份不同key，相同value的运单内存为31.74-1.02=30MB： 结论：改造后的压缩率提升(118-30)/118=74% 2. cpu对比 1. 单线程1万次写入redis String类型，基本维持在5%以下： Byte[]类型，基本维持在5%以下： 结论：cpu对比无明显变化 2. 单线程一万次读取对比： String类型： Byte[]类型： 结论：cpu对比无明显变化 3. 耗时对比 单线程1万次写入redis耗时 单线程1万次读取redi耗时 String类型 135677ms 130027ms byte[]类型 128804ms（提升5%） 124215ms(提升4.5%) 结论：读写均有略微提升 二、测试环境 redis2主2备(4G内存/分片) 1、压缩率 压缩前的redis内存： String类型保存1万次，两个master共新增118MB Byte[]类型保存一万次，两个master共新增30MB 结论：改造后的压缩率提升(118-30)/118=74%，与研发环境结论一致 2、CPU对比 写优化前84%： 写优化后41%： 读优化前23%： 读优化后18%： 三、压缩改造 改造前： 将操作运单对象转换成String类型的Json，保存redis 改造后： 风险点： 1、所有查询的地方都需改造和兼容(包括web应用)，否则读取错误 2、只能用自己的web应用查看redis 回退方案：将功能开关关闭","link":"/design/snappy-compress-redis.html"},{"title":"业务优化","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/business-optimization.html 背景实在太复杂了。。。简单放图，日后完善描述 一个报表需求由不可为，优化到可行并落地：通过多线程以及业务商讨优化，性能优化百倍以上，并满足业务需求。 除了技术手段外关键在于：通过与业务协商，控制查询范围到15天内、删除不必要的字段、筛选数据等各种业务手段减少查询量、http请求量实现。","link":"/design/business-optimization.html"},{"title":"关于上游同一数据大批量重复推送问题处理","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/same-data-push.html 先粗略写，日后有缘完善 背景 上游系统在推送数据到下游系统时,由于网络、代码、又或者是运维上（主要是sql重推没去重之类的），导致上游短时间推送大量同一单号给到OMS系统，导致数据库压力剧增 解决方案 新增字段，Version，接收上游数据时先判断Version是否比OMS的大，如果大则更新，否则不更新 Other More 为什么不只用数据库锁版本号或者锁版本号？ 先确认概念: Version（数据版本号,解决的是数据新旧问题）： version字段用于判断数据版本的新旧。在某些业务场景下，需要检查数据是否被其他操作修改过，以避免数据冲突或脏读的问题。通过比较version字段的值，可以判断当前数据是否是最新版本，如果版本不匹配，则可能意味着数据已被其他操作修改，需要采取相应的处理措施（如回滚、重新读取等）。 lockVersion（乐观锁锁版本号,解决数据并发更新问题）： lockVersion字段用于乐观锁机制。乐观锁是一种并发控制的策略，通过在数据上加上一个版本号或时间戳，来实现对数据的并发修改控制。在更新数据时，会检查lockVersion字段的值是否与当前操作的期望值一致，如果一致，则允许更新操作，否则可能意味着数据已被其他操作修改，需要进行冲突处理（如回滚、抛出异常等）。 1234仅使用lockVersion字段在并发场景下，可能出现：&gt; - 由于lockVersion字段的值是在更新时才会更新，因此在更新前后，lockVersion字段的值是不变的。如果在更新前后，有其他操作修改了数据，那么lockVersion字段的值就会不一致，此时更新操作就会失败仅使用Version字段在并发场景下，可能会出现：&gt; - 例如：A、B两个线程同时读取到version=1的数据，A线程将version更新为2，B线程将version更新为2，此时version=2的数据被更新了两次，这导致了其中一次更新被覆盖，数据版本不一致 先记录一些标签备忘 Version–&gt;针对数据在业务上更新的版本号,对应上下游业务操作导致的一次更新，针对性的场景是:用户点击一次更新按钮 lockVersion–&gt;针对系统内部的一次更新,不论是业务上,还是系统自己重试,每次更新都会更新lockVersion+1,针对性的场景是:重推","link":"/design/same-data-push.html"},{"title":"通用kafka延迟队列生产实践","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/general-kafka-delay-queue.html 接: Kafka延时队列方案探讨","link":"/design/general-kafka-delay-queue.html"},{"title":"前后端合并可行性","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/front-end-merge.html 这里描述的是前后分离，非动静分离 简单放图，日后完善描述 前后端分离优劣 为什么要使用前后分离 微服务：1个或多个后端为多个前端服务 安全：保护后端接口，防止暴露后端IP 提高吞吐量：后端压力大，需要支持水平扩展，多个后端提供服务分担压力 劣势 部署麻烦：需要前后分离部署，节点数*2 增加开发工作量：约20%的工作量 查错麻烦：查询日志需要前、后端日志一并查询 分析结果 前后分离更多的是为了保护后端，并且更多的是为了水平扩展，提高后端吞吐量。但实际业务上只对内部用户开放，无太多安全需求，对并发需求也不高，前后分离没有带来更多收益，反而增加了不少工作量与资源浪费，因此将前后端合并。","link":"/design/front-end-merge.html"},{"title":"生产数据库扩库","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/database-scale.html 背景","link":"/design/database-scale.html"},{"title":"精准定时任务设计思路","text":"type: drafts [原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/precise-timing-task-design.html 这里主要是以订单超时取消为例 粗略记录，日后完善 取消任务先加入数据库（持久化存储）,后加入当前节点时间轮（本地内存） 通过时间轮任务,触发订单取消逻辑、同时把数据库的任务删除 节点重启后，先通过数据库加载属于自己节点的任务到本地时间轮 注意，此处存在一些已经超时的任务，需要加载的时候顺便执行取消订单逻辑，把过期的任务从数据库删除 节点的时间轮恢复，后续继续通过1. 2. 步骤继续运行","link":"/design/precise-timing-task-design.html"},{"title":"读写分离场景分析&amp;实际业务落地","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/read-write-separation.html 接: 冷热分离场景分析&amp;实际业务落地 前言 在数据库的读写研发中，我们遇到最多的可能就是数据量过多导致的『读/写慢』了。针对这些问题，我们一般主要会采取的措施有： 优化SQL 优化索引 优化硬件 分库分表 业务拆分 冷热分离 读写分离 这次我们主要讲讲读写分离的实际使用场景，以及如何以前刚出来时候的项目实际落地方案，这次的业务对应的场景有好几个，且因为涉及的数据量比较大、实时性与一致性要求都不一样，所以有几种读写分离方案。 主要涉及到以下： 通过redis做读写分离 通过ES做读写分离 通过Hive做读写分离 重要说明：这里所说的读写是针对与数据库与其他外部存储中间件的读写分离 读写分离 使用读写分离条件： 数据量大(↑) 查询响应慢(↓) 写入响应可以接受(OK) 所有数据随时需要update(★主要★) 这里以SF订单中台为场景（下面数值可能会比较敏感，这里随便扯个一个量级的数值分析就好哈） 订单中台每日新增单量5000w，数据存mysql，查询场景主要分2种： 接单系统(主要是B类)下单后进行查询、更新：业务方根据订单号、业务订单号到本中台系统查询订单信息 下游各类业务系统根据各种复杂条件查询订单信息 业务场景分析 3个月数据量可达到近50e 上游查询订单信息，一般是根据我们订单系统返回的内部订单号、业务订单号查询，查询条件是唯一索引，但是查询量较大，每日查询量达到亿级，90%以上场景都是下单后当日内查询订单信息 下游查询订单信息，查询条件是各种复杂条件，查询量不定 订单信息是需要随时更新的，主要是业务上存在部分特殊情况（主要是预约单，业务上发现过预约到1个月后还是2个月后揽收的件。。。)，需要更新订单信息、状态等 以上场景不太满足因为第4点的原因，3个月内数据不满足冷热分离条件，但却满足读写分离的使用条件，很适合做读写分离，以下来看看我们具体怎么做的 （其实我们当然还是做了冷热分离，3个月后的数据只能去大数据查询了） （甚至还做了分库分表，分库分表有基因法和索引表法，因为设计分库查询条件比较多，所以采用的后者） （但是这里不是我们讨论的重点所以忽略了哈哈哈） 解决方案 针对上游根据唯一索引查询订单的功能做Redis读写分离： 采用Redis缓存一天内的订单订单数据（采用过期LRU算法）拦截绝大部分查询请求，其余剩下的非热点数据查询数据库并设置到缓存 针对下游复杂条件查询的功能，分两种： 1. （7天内创建、修改的）热点数据，采用ES存储、查询（其实按照情况，也会采用ES+hbase，我们这里的需求上大部分字段都可能用作查询，所以就直接把所有数据存到es了） 2. （7天外创建的）非热点数据，存hive，业务人员提工单查询，目前没有对应的实时查询接口支持，实际业务场景上也没这块的需求，业务提工单主要是想对客户做月度分析之类的 落实的细节 针对场景1的『针对上游根据唯一索引查询订单的功能做Redis读写分离』，其实大多逻辑没有什么特别好说的，唯一要注意的是一致性问题： 这里以前我们采用的方案是响应给上游内部订单号,同时异步设置订单信息到Redis，但异步设置缓存与用户根据内部订单号发起订单查询请求的先后顺序无法保证，所以有时候会导致上游接单系统查到的是旧数据 为了解决该问题,我们采用了『类似延迟双删』的方案，先设置旧缓存数据过期时间为50ms，执行数据库更新/保存事务，设置新的缓存（需要通过lua脚本比较新老数据版本号） 针对场景2，采用了通过flink消费kfk的方式，将数据同步到ES、hive等大数据组件中： 这些主要是综合查询 或者历史数据查询，所以需要的实时性其实没有那么高，所以采用了异步的方式处理，flink这些我也不是很熟悉，之所以用了团队flink那是因为公司平台限制。。。有一说一的是，多批量数据实时并发处理的话，flink确实有他的独到之处，尤其是stream处理？ 效果 订单中台系统后台数据库日均压力不到5%，双十一双十二不到10%。。。轻松。。。 问题 关于场景1的: 还是一致性问题，上下游更新操作是异步的，期间查询的还是旧数据，要做这种超强一致性的话可以参考这篇实现超强一致性『 缓存强一致性方案』，虽然可以这么做，但是没必要🤷‍ 关于场景2: ES数据数据实时性不高（毕竟采用了异步方式，要实时的话。。。 方式可能有很多，比方说至少要订单中台这边改同步写入es的方式,且需要手动调用es的refresh api,让其buffer刷新到os cache中，上游还得配合改造； 当然也可以通过加入中间状态的方式处理。。。嗯。。不过。。。其实没必要，近实时就可以了，需要实时的话咱们还是得实际场景实际分析） 7天外且没做过任何更新的数据，业务人员只能提工单通过hive查，这个其实也没必要，因为这需求很少，而且也不是很重要，所以没必要做实时查询接口，业务人员提工单查询就行了 笔记 使用读写分离应用场景： 数据量大(↑) 查询响应慢(↓) 写入响应可以接受(OK) 所有数据随时需要update(★主要★) 读写分离的作用 为了提高『读/写』的性能，将读写分离，将读请求分发到不同的数据库实例上，减轻主库的压力，提高主库的写性能(读写二八定律) 问题 一致性问题，实时性问题 Other more 其实还有很多细节，但是没必要一一说明，因为这些都是根据实际业务场景来的，每个公司的业务场景都不一样，所以这里只是提供一个思路，具体的还是要根据实际情况来的","link":"/design/read-write-separation.html"},{"title":"顺丰Redis-Sentinel架构部署","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/sf-redis-sentinel-design.html 接: Redis-Sentinel总结 背景 介于Redis-Sentinel的高可用性，我们在顺丰内部的Redis集群中，大量使用了Redis-Sentinel来保证Redis的高可用性 但是由于Redis主从的复制是异步的，从节点数据略微落后于主节点数据，为了业务的一致性，一般从节点是闲置的，也就是说不会做读写分离 但这种情况下，Redis的最高吞吐量会被限制死在单机的吞吐量上，这对于一些高吞吐量的业务来说，是不够的。 因此有了下面的架构 大概架构思想 当然没下面这么简单,实际上还有一致性hash分片的概念,这里简化了,一致性hash分片的概念可以参考下面的文章 参考:Jedis之ShardedJedis一致性哈希分析 部署3套Redis-Sentinel集群，每套集群包含3个Sentinel节点，3个Redis节点 用户事先配置好所有的Redis-Sentinel节点； 用户连接上Redis-Sentinel节点，通过Sentinel节点获取到当前的主节点； 用户get/set时，根据key的hash值取余，确定选择到哪个Redis集群操作 通过以上方式，可以让Redis吞吐量提升到N倍，N为Redis集群的数量。 扩容&amp;数据迁移 可能用的更多的是数据迁移工具，如redis-migrate-tool，但是这个工具是基于redis的复制机制，会更好一些，不会那么麻烦，运维自己玩就好😄 当然，也有别的方案，麻烦点，但是也可以实现，如下图 存在的风险是，数据同步完成后 到 新集群模式应用前这段时间的数据会丢失，根据业务，可能需要走兼容性方案，如双写等 其他补充-Redis-Sentinel的连接流程 客户端首次连接：客户端初始化时，会与Sentinel节点建立连接，并获取当前可用的Redis主节点信息 客户端连接到主节点：根据Sentinel提供的主节点信息，客户端选择一个主节点进行连接，并发送读写请求 后续通信直接与主节点：一旦客户端与主节点成功建立连接，后续的读写请求将直接与该主节点进行通信，无需再经过Sentinel节点 在正常情况下，客户端与主节点之间的通信是直接的，不需要再与Sentinel节点交互。然而，如果发生主节点故障或主节点不可用，Sentinel会通知客户端重新连接，并通过Sentinel节点获取新的可用主节点信息","link":"/design/sf-redis-sentinel-design.html"},{"title":"docker部署redis集群(Sentinel版)","text":"拉取Redis镜像 1docker pull redis 通过镜像启动容器(Redis集群实例*3 1主2从,集群部署完再设密码) 1234567docker run -it --name redis9000 -d -p 9000:6379 redis redis-server --requirepass 123456 --port 6379docker run -it --name redis9001 -d -p 9001:6379 redis redis-server --requirepass 123456 --port 6379docker run -it --name redis9002 -d -p 9002:6379 redis redis-server --requirepass 123456 --port 6379#docker run -it --name redis9003 -d -p 9003:6379 redis redis-server --requirepass 123456 --port 6379#docker run -it --name redis9004 -d -p 9004:6379 redis redis-server --requirepass 123456 --port 6379#docker run -it --name redis9005 -d -p 9005:6379 redis redis-server --requirepass 123456 --port 6379 查询各个实例的容器IP 123docker inspect redis9000 | grep IPAddressdocker inspect redis9001 | grep IPAddress...以及其他的... 进入某个容器执行命令(修改各个redis节点密码) 12345678910111213141516171819202122# docker exec -it redis9000 bash# 连接第1个实例,设置密码redis-cli -a 123456 -p 6379 -h 172.17.0.9config set masterauth 123456ctrl+c退出# 连接第2个实例,设置密码&amp;设置为第1个节点的从节点redis-cli -a 123456 -p 6379 -h 172.17.0.10config set masterauth 123456slaveof 172.17.0.9 6379ctrl+c退出# 连接第3个实例,设置密码&amp;设置为第1个节点的从节点redis-cli -a 123456 -p 6379 -h 172.17.0.11config set masterauth 123456slaveof 172.17.0.9 6379检查主从集群部署情况:`info Replication`&lt;div align=center&gt;&lt;img src=&quot;/images/docker/redis-sentinel/redis主从部署情况.png&quot; alt=&quot;通过Redis哨兵查看集群信息&quot;/&gt;&lt;/div&gt;ctrl+c退出 下载sentinel.conf 1http://download.redis.io/redis-stable/sentinel.conf 修改配置 12345678# mymaster:自定义集群名，如果需要监控多个redis集群，只需要配置多次并定义不同的&lt;master-name&gt; &lt;master-redis-ip&gt;:主库ip &lt;master-redis-port&gt;:主库port &lt;quorum&gt;:最小投票数，由于有三台redis-sentinel实例，所以可以设置成2sentinel monitor mymaster &lt;master-redis-ip&gt; &lt;master-redis-port&gt; &lt;quorum&gt;# 注：redis主从库搭建的时候，要么都不配置密码(这样下面这句也不需要配置)，不然都需要设置成一样的密码sentinel auth-pass mymaster redispassword# 添加后台运行daemonize yes 创建redis-sentinel集群 1234# sentinel900*.conf不需要修改 但需要时不同的副本,供不同容器使用docker run -it --name redis-sentinel9000 -v d:/user/01390559/desktop/tmp-setting/sentinel9000.conf:/usr/local/etc/redis/sentinel.conf -d -p 29000:26379 redis /bin/bashdocker run -it --name redis-sentinel9001 -v d:/user/01390559/desktop/tmp-setting/sentinel9001.conf:/usr/local/etc/redis/sentinel.conf -d -p 29001:26379 redis /bin/bashdocker run -it --name redis-sentinel9002 -v d:/user/01390559/desktop/tmp-setting/sentinel9002.conf:/usr/local/etc/redis/sentinel.conf -d -p 29002:26379 redis /bin/bash 启动哨兵 1234docker exec -it redis-sentinel9000 bashredis-sentinel /usr/local/etc/redis/sentinel.conf...启动其他哨兵... 查看集群信息验证 1234567docker exec -it redis-sentinel9000 bashredis-cli -p 26379 -h 172.17.0.12## 通过哨兵获取mymaster集群的master节点信息sentinel master mymaster## 通过哨兵获取mymaster集群的slave节点信息sentinel slaves mymaster&lt;div align=center&gt;&lt;img src=&quot;/images/docker/redis-sentinel/sentinel master mymaster.png&quot; alt=&quot;通过Redis哨兵查看集群信息&quot;/&gt;&lt;/div&gt; 结束 至此，完事","link":"/%E9%83%A8%E7%BD%B2/docker/redis/redis-Sentinel-with-docker.html"},{"title":"（零拷贝）优化转发型文件下载","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/zero-copy-file-download.html 背景 现有报表系统异步导出报表，生成的报表会上传到对象存储中，因为安全问题，用户不能直接上对象存储系统中下载文件，需要通过报表服务代劳，因为不需要对其做修改，只需做转发，所以这里考虑使用零拷贝技术进行优化 现有做法 把文件数据『下载』下来，然后把对应的文件返回给客户端 数据经过两次拷贝，一次是从对象存储下载到报表服务，一次是从报表服务下载到客户端 12345678910111213141516@Controllerpublic class DownloadController { @RequestMapping(value = &quot;/download&quot;, method = RequestMethod.GET) public ResponseEntity&lt;byte[]&gt; downloadFile() throws IOException { HttpClient client = HttpClientBuilder.create().build(); HttpGet request = new HttpGet(&quot;http://xxxx/xxxx.zip&quot;); HttpResponse response = client.execute(request); byte[] zipContent = EntityUtils.toByteArray(response.getEntity()); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); headers.setContentDispositionFormData(&quot;attachment&quot;, &quot;xxx.zip&quot;); headers.setContentLength(zipContent.length); return new ResponseEntity&lt;byte[]&gt;(zipContent, headers, HttpStatus.OK); }} 零拷贝优化 通过ZeroCopyInputStreamWrapper把文件数据直接『转发』给客户端 数据只经过2次拷贝，不需要经过报表服务，直接从对象存储转发给客户端 12345678910111213141516@Controllerpublic class DownloadController { @RequestMapping(value = &quot;/download&quot;, method = RequestMethod.GET) public ResponseEntity&lt;InputStreamResource&gt; downloadFile() throws IOException { CloseableHttpClient client = HttpClients.createDefault(); HttpGet request = new HttpGet(&quot;http://xxxx/xxxx.zip&quot;); HttpResponse response = client.execute(request); HttpEntity entity = response.getEntity(); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); headers.setContentDispositionFormData(&quot;attachment&quot;, &quot;xxx.zip&quot;); headers.setContentLength(entity.getContentLength()); InputStream stream = new ZeroCopyInputStreamWrapper(entity.getContent()); return new ResponseEntity&lt;InputStreamResource&gt;(new InputStreamResource(stream), headers, HttpStatus.OK); }} PS PS: 使用ZeroCopyInputStreamWrapper将HttpEntity的输入流包装成ZeroCopyInputStream，实际上是将HttpEntity的输入流传递给了ZeroCopyInputStream，而不是将响应数据读取到Java的用户内存中 原理 在ZeroCopyInputStreamWrapper中，它通过使用Java NIO的Direct ByteBuffer和底层的通道来实现DMA的零拷贝操作 数据直接从通道读取到Direct ByteBuffer中，跳过了CPU拷贝的过程，实现了高效的数据传输 其他","link":"/design/zero-copy-file-download.html"},{"title":"docker部署redis集群(Cluster版)","text":"拉取Redis镜像 1docker pull redis 拉取Redis-trib镜像 1docker pull inem0o/redis-trib 通过镜像启动容器(Redis集群实例*6) 123456docker run --name redis7000 -p 7000:6379 -d redis redis-server --appendonly yes --protected-mode no --cluster-enabled yesdocker run --name redis7001 -p 7001:6379 -d redis redis-server --appendonly yes --protected-mode no --cluster-enabled yesdocker run --name redis7002 -p 7002:6379 -d redis redis-server --appendonly yes --protected-mode no --cluster-enabled yesdocker run --name redis7003 -p 7003:6379 -d redis redis-server --appendonly yes --protected-mode no --cluster-enabled yesdocker run --name redis7004 -p 7004:6379 -d redis redis-server --appendonly yes --protected-mode no --cluster-enabled yesdocker run --name redis7005 -p 7005:6379 -d redis redis-server --appendonly yes --protected-mode no --cluster-enabled yes 查询各个实例的容器IP 123docker inspect redis7000 | grep IPAddressdocker inspect redis7001 | grep IPAddress...以及其他的... 通过redis-trib搭建集群 1docker run --rm -it inem0o/redis-trib create --replicas 1 172.17.0.2:6379 172.17.0.4:6379 172.17.0.5:6379 172.17.0.6:6379 172.17.0.7:6379 172.17.0.8:6379 进入某个容器执行命令(准备修改密码) 1docker exec -it redis7000 bash 连接各个Redis实例修改密码 123456789redis-cli -p 6379 -h 172.17.0.2config set masterauth 123456config set requirepass 123456config rewriteredis-cli -p 6379 -h 172.17.0.3config set masterauth 123456config set requirepass 123456config rewrite 验证集群信息 12CLUSTER INFOcluster nodes 结束 至此，完事 补充 一种错误的集群创建方式 创建集群后,主节点宕机不能触发FailOver 1redis-cli -a 123456 --cluster create 172.17.0.3:6379 172.17.0.4:6379 172.17.0.5:6379 172.17.0.6:6379 172.17.0.7:6379 172.17.0.8:6379 --cluster-replicas 1","link":"/%E9%83%A8%E7%BD%B2/docker/redis/redis-cluster-with-docker.html"},{"title":"docker部署zookeeper集群","text":"1234// 查看config命令参数$ docker-compose -f zookeeper-compose.yml config --help// 校验配置文件，不打印$ docker-compose -f zookeeper-compose.yml config -q 启动zookeeper集群 12// -d 后台启动$ docker-compose -f zookeeper-compose.yml up -d 查看容器启动情况 1$ docker-compose -f zookeeper-compose.yml ps 查看zookeeper集群状态 12$ docker exec -it zoo1 /bin/sh/zoo1 # zkServer.sh status zookeeper-compose.yml 12345678910111213141516171819202122232425262728293031version: '3'services: zoo1: image: zookeeper restart: always container_name: zoo1 ports: - &quot;2181:2181&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper restart: always container_name: zoo2 ports: - &quot;2182:2181&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper restart: always container_name: zoo3 ports: - &quot;2183:2181&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888","link":"/%E9%83%A8%E7%BD%B2/docker/zookeeper/zookeeper-cluster-with-docker.html"},{"title":"自用docker-compose","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191version: '2' # 定义版本，不指定默认为版本 1，新版本功能更多services: # 容器 zoo1: image: zookeeper:3.4.14 restart: always container_name: zoo1 hostname: zoo1 ports: - &quot;2181:2181&quot; environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: mynet: #ipv4_address: 172.20.0.2 zoo2: image: zookeeper:3.4.14 restart: always container_name: zoo2 hostname: zoo2 ports: - &quot;2182:2181&quot; environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: mynet: #ipv4_address: 172.20.0.3 zoo3: image: zookeeper:3.4.14 restart: always container_name: zoo3 hostname: zoo3 ports: - &quot;2183:2181&quot; environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 networks: mynet: #ipv4_address: 172.20.0.4 broker1: image: wurstmeister/kafka:0.8.2.1 restart: always container_name: broker1 ports: - &quot;9091:9092&quot; depends_on: - zoo1 - zoo2 - zoo3 hostname: '{{.Node.Hostname}}' environment: KAFKA_BROKER_ID: 1 KAFKA_ADVERTISED_HOST_NAME: broker1 KAFKA_ADVERTISED_PORT: 9092 KAFKA_HOST_NAME: broker1 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2182,zoo3:2183 KAFKA_LISTENERS: PLAINTEXT://broker1:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker1:9092 volumes: - /Users/chris-cai/Documents/docker/runningFile/brocker1/docker.sock:/var/run/docker.sock networks: mynet: #ipv4_address: 172.20.0.5 broker2: image: wurstmeister/kafka:0.8.2.1 restart: always container_name: broker2 ports: - &quot;9092:9092&quot; depends_on: - zoo1 - zoo2 - zoo3 hostname: '{{.Node.Hostname}}' environment: KAFKA_BROKER_ID: 2 KAFKA_ADVERTISED_HOST_NAME: broker2 KAFKA_ADVERTISED_PORT: 9092 KAFKA_HOST_NAME: broker2 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2182,zoo3:2183 KAFKA_LISTENERS: PLAINTEXT://broker2:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker2:9092 volumes: - /Users/chris-cai/Documents/docker/runningFile/brocker2/docker.sock:/var/run/docker.sock networks: mynet: #ipv4_address: 172.20.0.6 broker3: image: wurstmeister/kafka:0.8.2.1 restart: always container_name: broker3 ports: - &quot;9093:9092&quot; depends_on: - zoo1 - zoo2 - zoo3 hostname: '{{.Node.Hostname}}' environment: KAFKA_BROKER_ID: 3 KAFKA_ADVERTISED_HOST_NAME: broker3 KAFKA_ADVERTISED_PORT: 9092 KAFKA_HOST_NAME: broker3 KAFKA_ZOOKEEPER_CONNECT: zoo1:2181,zoo2:2182,zoo3:2183 KAFKA_LISTENERS: PLAINTEXT://broker3:9092 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker3:9092 volumes: - /Users/chris-cai/Documents/docker/runningFile/brocker3/docker.sock:/var/run/docker.sock networks: mynet: #ipv4_address: 172.20.0.7 kafka-manager: image: sheepkiller/kafka-manager restart: always depends_on: - zoo1 - zoo2 - zoo3 - broker1 - broker2 - broker3 environment: ZK_HOSTS: zoo1:2181,zoo2:2182,zoo3:2183 ports: - &quot;9000:9000&quot; container_name: kafka-manager networks: mynet: kafka-offset-monitor: image: 564239555/kafkaoffsetmonitor volumes: - /Users/chris-cai/Documents/docker/runningFile/kafkaoffsetmonitor/conf:/kafkaoffsetmonitor ports: - &quot;8089:8089&quot; depends_on: - zoo1 - zoo2 - zoo3 - broker1 - broker2 - broker3 environment: ZK_HOSTS: zoo1:2181,zoo2:2182,zoo3:2183 KAFKA_BROKERS: broker1:9091,broker2:9092,broker3:9093 REFRESH_SECENDS: 10 RETAIN_DAYS: 2 container_name: kafka-monitor mysql1: image: mysql:5.7.29 restart: always environment: MYSQL_ROOT_PASSWORD: 123456 MYSQL_USER: test MYSQL_PASS: 123456 volumes: - &quot;/Users/chris-cai/Documents/docker/runningFile/mysql/db:/var/lib/mysql&quot; - &quot;/Users/chris-cai/Documents/docker/runningFile/mysql/conf/my.cnf:/etc/my.cnf&quot; - &quot;/Users/chris-cai/Documents/docker/runningFile/mysql/init:/docker-entrypoint-initdb.d/&quot; ports: - 3306:3306 networks: mynet: #ipv4_address: 172.20.0.10 container_name: mysql1 nginx: restart: always image: nginx:stable ports: - 8080:80 - 80:80 - 443:443 volumes: - /Users/chris-cai/Documents/docker/runningFile/nginx/conf.d:/etc/nginx/conf.d - /Users/chris-cai/Documents/docker/runningFile/nginx/log:/var/log/nginx - /Users/chris-cai/Documents/docker/runningFile/nginx/www:/var/www jenkins: image: 'jenkins/jenkins:2.60.3' # 镜像 container_name: jenkins # 容器名称 restart: always # 同 --restart 参数 ports: # 端口映射，同 -p 参数，本地端口:容器端口 - '8080:8080' - '50000:50000' volumes: # 数据卷,本地文件夹:容器文件夹 - '/c/Users/01390559/dockerTmp/jenkins:/var/jenkins_home' environment: TZ: Asia/Shanghainetworks: mynet: driver: bridge","link":"/%E9%83%A8%E7%BD%B2/docker/undefined.html"},{"title":"docker容器中安装ping","text":"apt-get update &amp; apt-get install iputils-ping 安装ifconfig指令为apt-get install net-tools","link":"/%E9%83%A8%E7%BD%B2/docker/zookeeper/zookeeper-cluster-with-docker.html"},{"title":"dubbo调用流程","text":"[半转载]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/dubbo/dubbo-call-flow.html 概要精简版流程 客户端从注册中心拉取和订阅服务列表 聚合服务列表，形成Invoker 客户端通过路由和负载均衡选择合适的服务提供者 将请求交给底层的I/O线程池处理 在I/O线程池中进行序列化和反序列化等操作 将请求交给业务线程池处理业务方法调用 Dubbo的调用流程主要在客户端完成，通过注册中心、路由、负载均衡等机制实现服务的发现和选择，然后通过底层的I/O线程池和业务线程池处理请求。这样的设计使得Dubbo具备高性能、高并发的特点，适用于分布式系统中的服务调用场景。 补充版流程 客户端启动时，会从注册中心拉取并订阅对应的服务列表。这些服务列表会被聚合成一个Invoker（调用器）。Cluster模块会将多个服务提供者聚合成一个Invoker。 在发起RPC调用之前，客户端会通过Directory#list方法获取服务提供者的地址列表，这些地址列表将被用于后续的路由和负载均衡操作。Dubbo内部还有一个实现了Directory接口的RegistryDirectory类，它和接口名是一对一的关系，负责拉取和订阅服务提供者、动态配置和路由项。 在Dubbo发起服务调用时，所有的路由和负载均衡操作都是在客户端进行的。首先会触发路由操作，然后将路由结果得到的服务列表作为负载均衡的参数。经过负载均衡算法的选择，将选出一台合适的机器进行RPC调用。 客户端经过路由和负载均衡后，将请求交给底层的I/O线程池（比如Netty）进行处理。I/O线程池主要负责处理读写、序列化和反序列化等操作。在这个阶段，必须避免阻塞操作，Dubbo提供了相应的参数控制。在处理反序列化对象时，可以选择在业务线程池中进行处理。 在整个流程中，涉及到两种线程池。一种是I/O线程池（比如Netty），主要负责底层的I/O操作。另一种是Dubbo业务线程池（Dubbo线程池）：Dubbo还提供了一个业务线程池，用于承载业务方法的调用。在处理完底层的I/O操作后，Dubbo将请求交给业务线程池处理。这样可以避免阻塞I/O线程，提高系统的并发处理能力。 dubbo的多线程并发调用如何正确响应对应的线程(类似http2连接复用原理) 当客户端多个线程并发请求时，框架内部会调用DefaultFuture对象的get方法进行等待 在请求发起时，框架内部会创建Request对象，这个时候会被分配一个唯一 id, DefaultFuture 可以从Request对象中获取id,并将关联关系存储到静态HashMap中，就是上图中的Futures 集合 当客户端收到响应时，会根据Response对象中的id,从Futures集合中查找对应 DefaultFuture对象，最终会唤醒对应的线程并通知结果 同时客户端也会启动一个定时扫描线程去 探测超时没有返回的请求","link":"/dubbo/dubbo-call-flow.html"},{"title":"秒杀架构设计","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/framework-design/sec-kill-framework-design.html 常见的三类高并发场景 高并发压力主要来自,并发时出现大量锁冲突 1.细颗粒度操作-锁冲突少 如:QQ微信等即时通讯业务个人读个人自己的数据 数据结构 个人信息 user(uid…) 几十亿 个人的好友信息 friend(uid,friend_id…) 几百亿 个人的群 user_group(uid,group_id…) 几百亿 群成员 group_member(gid,uid…) 几千亿 个人消息(msg_id,uid…) 几千亿 群消息(msg_id,gid…) 几千亿 个人和群都是读写自己的数据 在高并发时(单个用户单位时间发出N个读写请求)，锁冲突极小，每个【人】、【群】、【消息】只会锁住自己部分的消息 在出现IO瓶颈的时候 只需要进行水平分库 把【人】、【群】、【消息】进行切分 2.读多写少,存在少量写冲突 如:微博 自己的写为别人的读 拉模式的大概数据结构 参考:微博Feed业务架构–推拉模式 个人信息 user (uid…) 几十亿 个人的关注列表 user_follow (id,uid,follow_id…) 几百亿 个人发出的微博 msg (msg_id,uid…) 几百亿 大概流程: 假设用的是拉模式，多个粉丝拉取别的某位用户的发件箱时容易出现读写锁冲突 如： 在某明星粉丝刷微博时,明星消息表、评论表被快速读写，出现锁冲突，宕机 3.(同一份数据)多读多写，存在大量写冲突 如：12306秒杀业务 大概数据结构 stock(s_id,time) //列车 ticket(t_id,num,s_id) //列车余票 用户量大,并发很大时, 有极大的锁冲突，极容易把系统搞垮 一辆车几百万请求，有效请求200，成功请求数0，最终请求成功率≈0% 解决【多读多写，存在大量写冲突】的锁冲突问题 主要方向为降低【数据库层面的锁冲突】 （1）降低读请求：利用缓存 （2）降低写请求：上游尽量过滤无效请求 （1）降低读请求：尽可能利用缓存 前端: 浏览器、Nginx等静态页面缓存 站点层、服务层: 缓存结果、缓存数据… （2）降低写请求：上游尽量过滤无效请求 前端: 通过JS做限速,减少99%请求(如:频繁点击,显示频率过快) 站点层: 拦截同个用户的重复请求(通过web层缓存或缓存集群 对[UID+TOKEN]进行计数&amp;限速) 服务层: 通过MQ、内存队列收集请求（队列长度根据数据库抗压能力、库存数量设置） 数据库层: 单个主从","link":"/framework-design/sec-kill-framework-design.html"},{"title":"性能优化核心思想","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/idea/performance-optimization-core-ideas.html 性能优化核心思想 1. 网络传输上 选择合适的传输协议，如Http-&gt;dubbo，以二进制传输+长连接请求 开启序列化、压缩等，对于大数据量的传输可能有特别大的提升 对于重复请求同一个url的连接池，使用长连接 对于不需立即响应的，使用异步请求 对即时聊天等双向实时性要求高的，使用webSocket全双工等 2. JVM 选择合适的GC算法，如CMS、Parallel、G1等 CMS（JDK&lt;1.9）关注低停顿，Parallel关注吞吐量，G1通过较精准把控停顿时间,也可以说是关注整体吞吐量和延迟吧，当前市场上主要用于大内存场景 选择合适的GC参数，如堆内存大小、新生代大小、老年代大小、GC线程数、GC触发条件等 这个属于调优方面的了，需要结合jstat命令与gc detail或者监控工具等配置； 3. 系统架构上的优化(核心) 合理模块依赖关系，减少不必要的依赖，减少不必要的调用 异步处理 比如，一个请求以前需要123456步完成，但是通过业务梳理，发现只有123步需要当时完成，第4步是更新汇总表，第5步是写日志，第6步是通知外围系统，456步都可以异步完成，这样一次业务操作只需要完成123步，大大提升性能 并行处理 没有先后依赖关系的 启动多线程处理，但是如果是CPU密集型的任务，一般不要启动太多线程，因为线程切换成本可能会超过性能提升（每个请求过来都开启多线程竞争CPU计算资源没啥意义） 缓存(需要关注刷新实现) 客户端缓存 CDN缓存 本地缓存 分布式缓存(Redis) 池化 创建成本高的、可重复利用的，都可以采用预先创建的方式创建资源 连接池 线程池 对象池 4. 数据库层面 选择合适的数据库 关系型一般采用Mysql没话说 非关系型，根据业务场景选择，如Redis、MongoDB、HBase等，在超高并发查询的场景下可能还需要结合ES+Hbase的形式 选择合适的数据库引擎 Mysql一般采用InnoDB引擎，如果是只读的，可以考虑MyISAM引擎，因为MyISAM引擎不支持事务，但是读性能比InnoDB高不少 读写分离 读写分离，一般是主从复制，主库写，从库读，但是从库读到的数据可能不是最新的，因为主从复制有延迟，一般是毫秒级别的，但是对于一些对数据一致性要求不高的场景，可以采用读写分离，提升读性能 这里对于读写分离的读写延迟问题，有很多处理方式，处理通过小事务、5.7以上的mysql并行同步，配置mysql同步时效等减少延迟、只读主等处理 但是实际业务场景上，对外的读取，对实时性要求其实没那么地高，一般都是对内的读取（如需要查询最新数据做更新），对实时性要求高的，这时候才需要真正的去面对、解决主从延迟问题。 对于这种系统内部的延迟问题，一般都是通过缓存来处理，便可解决 分库分表 分库分表，一般是为了解决单库单表数据量过大的问题，导致查询性能下降，一般是通过分库分表，将数据分散到多个库、多个表中，提升查询性能 索引 SQL优化","link":"/idea/performance-optimization-core-ideas.html"},{"title":"HashMap-JDK1.8","text":"参考链接：HashMap在JDK1.8之前和之后的区别 JDK1.8之前 new HashMap(n)中的n为其容量 元素插入使用头插法 并发插入（resize时）会产生循环链表，在get一个不存在的元素时会导致死循环。参考：Java HashMap的死循环 JDK1.8之后 元素使用尾插法 new HashMap(n)中的n最接近的2^m为其容量 并发插入还是有问题，但不会产生死循环 插入时数组长度&gt;64，桶元素&gt;8时，会树型化 发生resize时，resize后，桶元素个数&lt;=6的，都会被解树型化 取模用与操作(hash &amp; (arrayLength-1))会比较快，所以数组的大小永远是2的N次方。你随便给一个初始值比如17会转为32 resize实现逻辑参考：Java HashMap工作原理及实现 HashMap关于static final int UNTREEIFY_THRESHOLD = 6的分析 遍历整个原始桶，把桶内数据分配到原桶与新桶中 具体图解分析可以参考以下链接的第六点：Java HashMap工作原理及实现 判断新桶元素个数&lt;=UNTREEIFY_THRESHOLD(也就是6)，那么解开树型化 所以，结论来说：只要是resize后，桶元素个数&lt;=6的，都是链表 indexFor为什么要用h&amp;(h-1) 位运算快 比方说h=16，不减1，那么算出来的结果全是0或16，这样会出现中间的槽完全不存东西 什么时候扩容 当前大小&gt;当前容量*扩展因子0.75，且计算出来的下标的卡槽不为空。","link":"/java/HashMap-JDK1.8.html"},{"title":"常见排序算法应用总结","text":"前言 其实多算法涉及不是很深，也不打算在使用前深究，究了没多久就忘了纯属浪费时间。这里做下记录，日后用到直接来这里找就完事啦~~ 常见排序算法时间： 1. 冒泡排序（Bubble Sort） 时间复杂度：最好情况 O(n)，最坏情况 O(n^2) 空间复杂度：O(1) 使用场景：适用于数据规模较小的情况，且数据分布情况不明显 优势：实现简单易懂 缺点：效率较低，不适用于大规模数据的排序 具体案例：对于一个由数值大小不一的小数组进行排序，例如对一个长度为 10 的数组进行排序 2. 选择排序（Selection Sort） 时间复杂度：最好情况 O(n^2)，最坏情况 O(n^2) 空间复杂度：O(1) 使用场景：适用于数据规模较小的情况 优势：实现简单易懂 缺点：效率较低，不适用于大规模数据的排序 具体案例：对于一个由数值大小不一的小数组进行排序，例如对一个长度为 10 的数组进行排序 3. 插入排序（Insertion Sort） 时间复杂度：最好情况 O(n)，最坏情况 O(n^2) 空间复杂度：O(1) 使用场景：适用于数据基本有序的情况，或者数据规模较小的情况 优势：对于基本有序的数据进行排序时，效率较高 缺点：在数据规模较大时，效率较低 具体案例：对于一个已经基本有序的数组进行排序，例如对一个长度为 100 的数组进行排序 4. 希尔排序（Shell Sort） 时间复杂度：最好情况 O(n log n)，最坏情况 O(n^2) 空间复杂度：O(1) 使用场景：适用于数据规模中等的情况 优势：在效率和实现难度之间做了很好的平衡 缺点：对于较大规模数据的排序效率相对较低 具体案例：对于一个数值大小不一的大数组进行排序，例如对一个长度为 1000 的数组进行排序 5. 归并排序（Merge Sort） 时间复杂度：最好情况时间复杂度：O(n log n)，最坏情况：O(n log n) 空间复杂度：O(n) 优势：稳定，效率较高，适用于大规模数据的排序 缺点：需要较大的内存空间 具体案例：对于一个长度为 10000 的数组进行排序，或者对于一个长度为 10000 的链表进行排序 6. 快速排序（Quick Sort） 时间复杂度：最好情况 O(n log n)，最坏情况 O(n^2) 空间复杂度：O(log n) ~ O(n) 使用场景：适用于数据规模较大的情况，但是需要注意最坏情况下的时间复杂度 优势：效率较高，适用于大规模数据的排序 缺点：对于近乎有序的数据排序，效率会变得很低，最坏情况下的时间复杂度为 O(n^2) 具体案例：对于一个随机数值大小的大数组进行排序，例如对一个长度为 100000 的数组进行排序 7. 堆排序（Heap Sort） 时间复杂度：最好情况 O(n log n)，最坏情况 O(n log n) 空间复杂度：O(1) 使用场景：适用于数据规模较大的情况，相对于归并排序使用更少的空间 优势：效率较高，适用于大规模数据的排序 缺点：不稳定，相对于归并排序和快速排序，实现较为复杂 具体案例：对于一个长度为 10000 的数组进行排序 8. 计数排序（Counting Sort） 时间复杂度：O(n+k) 空间复杂度：O(n+k) 使用场景：适用于数据范围不大的整数排序 优势：时间复杂度较低，适用于小范围整数的排序 缺点：需要较大的内存空间，数据分布不均匀时效率会变得很低 具体案例：对于一个长度为 10000，数值范围在 0-999 之间的整数数组进行排序。 在选择排序算法时，需要综合考虑数据规模、数据分布、效率等因素，并且不同排序算法之间有优劣之分，所以需要选择适合的排序算法进行应用。","link":"/java/sort-algorithm-summary.html"},{"title":"常见查找算法应用总结2","text":"接: 常见排序算法应用总结 前言 其实多算法涉及不是很深，也不打算在使用前深究，究了没多久就忘了纯属浪费时间。这里做下记录，日后用到直接来这里找就完事啦~~ 常见搜索算法及其特点 1. 线性搜索（Linear Search） 时间复杂度：最好情况 O(1)，最坏情况 O(n) 使用场景：适用于数据规模较小，或者数据分布随机的情况 优势：实现简单易懂 缺点：效率较低，不适用于大规模数据的搜索 具体案例：在一个由数值大小不一的小数组中查找特定的数值，例如在一个长度为 10 的数组中查找数值 5 2. 二分搜索（Binary Search） 时间复杂度：O(log n) 使用场景：适用于数据已排序的情况 优势：效率较高，适用于大规模数据的搜索 缺点：需要数据已排序，实现较为复杂 具体案例：在一个由数值大小递增的大数组中查找特定的数值，例如在一个长度为 10000 的数组中查找数值 5000 3. 插值搜索（Interpolation Search） 时间复杂度：最好情况 O(1)，最坏情况 O(n) 使用场景：适用于数据有序且分布均匀的情况 优势：效率较高，比二分搜索更快，适用于大规模数据的搜索 缺点：数据分布不均匀时效率会变得很低 具体案例：在一个由数值大小递增的大数组中查找特定的数值，例如在一个长度为 10000 的数组中查找数值 5000 4. 哈希表（Hash Table） 时间复杂度：最好情况 O(1)，最坏情况 O(n) 使用场景：适用于数据随机分布的情况 优势：效率较高，适用于大规模数据的搜索 缺点：需要占用较大的内存空间，实现较为复杂 具体案例：在一个由随机数值构成的大数组中查找特定的数值，例如在一个长度为 10000 的数组中查找数值 5000 5. 广度优先搜索（Breadth-First Search，BFS） 时间复杂度：O(V+E)，其中 V 表示节点数量，E 表示边数量 使用场景：适用于无权图或者权值较小的图的搜索 优势：能够找到最短路径，实现简单易懂 缺点：占用内存空间较大，不适用于权值较大的图 具体案例：在一个无向图中查找从起点到终点的最短路径，例如在一个迷宫中查找从起点到终点的最短路径 6. 深度优先搜索（Depth-First Search，DFS） 时间复杂度：O(V+E)，其中 V 表示节点数量，E 表示边数量 使用场景：适用于遍历图、寻找所有路径的情况 优势：实现简单易懂 缺点：不保证找到最短路径，可能陷入死循环 具体案例：在一个由数个节点构成的地图中查找从 A 到 B 的所有路径 7. A* 算法（A-star Algorithm） 时间复杂度：最好情况 O(1)，最坏情况 O(b^d)，其中 b 表示每个节点的平均分支数，d 表示起点到终点的最短距离 使用场景：适用于有权图的最短路径搜索 优势：在广度优先搜索和启发式搜索的基础上，引入估价函数，实现了更高效的搜索 缺点：需要事先知道起点和终点的位置，实现较为复杂 具体案例：在一个由数个节点和边权值构成的地图中查找从 A 到 B 的最短路径 8. 二叉搜索树（Binary Search Tree，BST） 时间复杂度：平均情况 O(log n)，最坏情况 O(n)，其中 n 表示节点数量 使用场景：适用于有序数据的搜索，或者需要维护数据有序性的情况 优势：效率较高，实现简单易懂，能够维护数据有序性 缺点：极端情况下会退化成链表，影响搜索效率 具体案例：在一个由数值大小递增的大数组中构建二叉搜索树，进行数据搜索。 不同的算法适用于不同的场景。在选择搜索算法时，需要综合考虑数据规模、数据分布、搜索目标等因素，并选择适合的算法进行应用 同时，在实际应用中，还可以结合具体场景，选择合适的算法进行优化，例如： 在一个大规模数据的搜索中，可以通过使用哈希表或者二分搜索等高效算法来提升搜索效率 在寻找最短路径的场景中，可以使用 A* 算法或者广度优先搜索来找到最优解。在数据有序性较强的场景中，可以使用二叉搜索树来维护数据有序性并进行快速搜索","link":"/java/query-algorithm-summary.html"},{"title":"Redis-Sentinel总结","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/redis/Redis-Sentinel-Summary.html 1.Redis主从架构 主节点负责写入操作 从节点可以提供读取操作(可配置,有延迟,高一致性的场景下需要注意) 2.Redis主从复制流程 Redis Slave 与Master建立连接 Master执行bgsave生成rdb快照文件 Master发送rdb快照文件给到Slave Slave接收到rdb快照文件后,清空自己的数据,然后加载rdb快照文件 同时,Master会继续将新的写操作同步给Slave(这里用了老版本用的环形结构,高并发情况下可能会丢数据,新版本用的无盘复制不会有这个问题) Slave加载完rdb快照文件后,开始接收Master的写操作,完成同步 之后Slave会周期性的向Master发送sync命令,Master接收到sync命令后,会将新的写操作同步给Slave,保证数据的一致性 3.Redis-Sentinel高可用集群 每个Sentinel节点每秒钟会向所有Redis节点以及所有Sentinel节点发送ping命令(实际上是info命令),来确认节点是否正常工作 3.1 Redis故障发现&amp;故障转移 故障发现 如果Sentinel主节点发现Master节点挂了(Ping命令响应超时,对应配置为own-after-millisecond),那么Sentinel会将这个节点标记为主观下线 Sentinel主节点通知Sentinel从节点们ping这个Master节点,如果有足够多Sentinel节点认为Master节点挂了(可配置,一般配置为过半,也就是2个节点),那么Sentinel会将这个节点标记为客观下线,即『真下线』 故障转移 Sentinel主节点会剔除无效节点(最近一次ping超时)，并且选取一个偏移量最新的Redis Slave节点作为新的Master节点（偏移量一致会根据节点id，选最小的） Sentinel主节点下发slave of no one命令给新的Master节点,让它升级为Master节点 Sentinel从节点订阅原有的Redis从节点信息发现该节点已经变成了Master节点,于是将自己的Master节点信息更新为新的Master节点,同时把原来的主节点信息给剔除掉 Sentinel主节点向其他所有的Redis从节点下达slave of命令,让它们成为新的Master节点的从节点 新的从节点会重新执行一次主从复制流程,从新的Master节点同步数据 故障转移完成 PS.原有的Master在故障恢复后会变成新的Master的从节点,启动后执行主从复制流程,与新Master保持数据一致 4. Sentinel集群的高可用 Sentinel相互感知发现 每个Sentinel节点都会在Redis注册自己的信息 Sentinel的故障发现与选举 基于Raft算法,大意是说: 主节点与从节点之间维持心跳(心跳的时候还会顺带带上新的日志信息) 从节点如果一定时间内收不到主节点的心跳信息,自己就会发起选举选自己为主节点 其他节点会根据选举周期、日志偏移量确定是否能让他升主节点 就这样🤷 raft算法详细可以参考: 这个up主的视频","link":"/redis/Redis-Sentinel-Summary.html"},{"title":"1分钟教你redis集群搭建（2服務器）","text":"遇到有疑惑的可参考这个链接 注意: 关闭redis集群不能直接kill掉进程，或者关机，我们要通过命令redis-cli -p 7001 shutdown进行关闭，这样在关闭之前，数据才能够进行保存 1. 安装 redis 详：略 2. 创建 n 个 redis.conf 文件(redis 集群需要至少6个节点[3主3从]) 详： 1234567daemonize yes //redis后台运行pidfile /var/run/redis_7000.pid //pidfile文件对应7000,7002,7003port 7000 //端口7000,7002,7003cluster-enabled yes //开启集群 把注释#去掉cluster-config-file nodes_7000.conf //集群的配置 配置文件首次启动自动生成 7000,7001,7002cluster-node-timeout 5000 //请求超时 设置5秒够了appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志 3. 用redis.server 启动 redis 12345678101服務器redis-server ./7000/redis.confredis-server ./7001/redis.confredis-server ./7002/redis.conf102服務器redis-server ./7003/redis.confredis-server ./7004/redis.confredis-server ./7005/redis.conf 4. 安装 redis (不安装也行 主要是为了安装redis-trib.rb脚本而已) 1gem install redis（需要ruby rubygems） 5. 关联集群 1redis-trib.rb create --replicas 1 172.16.86.101:7000 172.16.86.101:7001 172.16.86.101:7002 172.16.86.102:7003 172.16.86.102:7004 172.16.86.102:7005 6. 检查集群是否搭建完成 12345678910111213[chris-cai@localhost cluster]$ redis-cli -c -p 7000127.0.0.1:7000&gt; CLUSTER INFOcluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_sent:228cluster_stats_messages_received:228 其他说明 1. redis常用命令放到Linux系统目录中，方便直接使用 这3个文件可以复制到/usr/local/bin 中，日后可以直接在linux命令行调用，无需切换目录输入路径等 123redis-cliredis-serverredis-trib.rb 2. 常用命令 1234redis-cli -h 172.16.86.102 -p 7003redis-cli -c -p 7003cluster nodesCLUSTER INFO 让0b00721a509444db793d28448d8f02168b94bd38成为7000的从节点 1redis-cli -c -p 7000 cluster replicate 0b00721a509444db793d28448d8f02168b94bd38","link":"/redis/Redis-Install-Settring.html"},{"title":"Redis分片方案概要(Cluster or Codis)","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/redis/Redis-Partitioning.html Redis分片方案概要(Cluster or Codis) 客户端分片 常见的主要是Memcached 通过客户端Hash等方式决定数据要存到哪个节点 服务器端分片 Codis分片方案 Codis是一整套缓存解决方案，包含高可用、数据分片、监控、管理、动态扩态 etc. 走的是 Client-&gt;代理-&gt;redis，一定规模后基本都采用这种方式 限制 批量操作可能受影响: 不支持pipeline/watch/scan等批操作 不支持事务 支持mset/mget ** 另一种分片方案 ** 官方Redis Cluster分片方案 走的是Client-&gt;redis server jump redis server 限制 批量操作可能受影响: mset/mget/pipeline/watch/scan等批操作需要所有key都存在以同个节点上 并且手动分片期间,批操作不可用 (参考官方文档的Implemented subset) 客户端必须支持集群协议 不支持事务","link":"/redis/Redis-Partitioning.html"},{"title":"Redis集群--sentinel 与 cluster的区别","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/redis/Different-Between-Sentinel-And-Cluster.html 一、sentinel 与 cluster的区别 Sentinel的作用 监控+自动故障迁移(自动升主) 定期监控redis是否按照预期良好地运行; 当一个master节点不可用时，能够选举出master的多个slave 并令其自动升主 PS. sentinel本身支持集群 Cluster的作用 分布式集群 对Redis进行16384个槽按照节点分片(默认为均分16384个槽到每个节点) 主从复制 监控+自动故障迁移(同Sentinel) 总结 Cluster 包含Sentinel的功能 Sentinel主要用于： 不需要分片的情况 监控+自动升主进程不想与Redis服务器部署在一起的情况 Redis3.x以下","link":"/redis/Different-Between-Sentinel-And-Cluster.html"},{"title":"IO模型","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/system/IO-model.html 背景 服务器网络模型 这篇IO模型是《每天进步一点点》里的第一篇学习记录，真的是忘了看看了忘了。。其实不用记服务器的，大概理一下JAVA自己的就简单多了，这里稍微总结一下： JAVA IO模型 JAVA的IO模型分为BIO、NIO、AIO三种，其中BIO是阻塞IO，NIO是非阻塞IO，AIO是异步IO 阻塞IO模型： Java中常见的阻塞IO操作包括InputStream的read()方法和OutputStream的write()方法。这些操作在底层系统中对应着同步阻塞IO模型，即当应用程序调用这些操作时，如果数据没有准备好，操作将会一直阻塞，直到数据准备就绪才会返回结果。 非阻塞IO模型： Java中的非阻塞IO操作包括SocketChannel的read()和write()方法。这些操作在底层系统中对应着同步非阻塞IO模型，即当应用程序调用这些操作时，如果数据没有准备好，操作会立即返回并告诉应用程序数据是否准备就绪，如果数据没有准备好，应用程序可以继续执行其他任务而不是等待IO操作完成。 异步IO模型： Java中常见的异步IO操作包括AsynchronousSocketChannel的read()和write()方法。这些操作在底层系统中对应着异步IO模型，即当应用程序调用这些操作时，操作的完成会通过回调函数的方式通知应用程序，应用程序可以继续执行其他任务而不需要等待IO操作完成。 NIO与AIO的异同 其中非阻塞IO和异步IO看着很相似，其实说白了就是异步IO多了个回调，用户线程完全不需要等待（不用跟NIO那样一直在epoll那里等待） 一些笔记","link":"/system/IO-model.html"},{"title":"Java I&#x2F;O模型与系统I&#x2F;O模型","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/system/IO-model2.html 接: IO模型 Java I/O模型与系统I/O模型的映射关系 Java的I/O模型是建立在底层系统I/O模型之上的，它通过对底层系统I/O调用的封装，提供了更高层次的抽象和统一的I/O接口。Java的I/O类库支持的I/O模型和底层系统I/O模型之间的映射关系如下： 阻塞式I/O模型 Java的I/O类库默认使用阻塞式I/O模型。在该模型下，I/O操作会一直阻塞，直到数据准备好或者操作完成才返回。对应的系统I/O模型是传统的阻塞式I/O模型。主要对应的系统I/O模型是Linux系统中的read(), write() 这里主要是各种Stream、Reader、Writer、Socket的读写，其中Socket为： 1234567891011121314ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();// 监听 8080 端口进来的 TCP 链接serverSocketChannel.socket().bind(new InetSocketAddress(8080));while (true) { // 这里会阻塞，直到有一个请求的连接进来 SocketChannel socketChannel = serverSocketChannel.accept(); // 开启一个新的线程来处理这个请求，然后在 while 循环中继续监听 8080 端口 SocketHandler handler = new SocketHandler(socketChannel); new Thread(handler).start();} 非阻塞式I/O模型 Java的I/O类库可以使用非阻塞式I/O模型。在该模型下，I/O操作会立即返回，不会阻塞，但此时数据可能还没有准备好或者操作没有完成。需要使用轮询的方式检查操作是否完成。对应的系统I/O模型是非阻塞式I/O模型。主要对应的系统I/O模型是Linux系统中的select()或poll()函数 java中主要是通过selector轮询socket的事件： 123456789101112131415Selector selector = Selector.open(); ServerSocketChannel server = ServerSocketChannel.open(); server.socket().bind(new InetSocketAddress(8080)); // 将其注册到 Selector 中，监听 OP_ACCEPT 事件 server.configureBlocking(false); server.register(selector, SelectionKey.OP_ACCEPT); while (true){ int readyChannels=selector.select(); if(readyChannels==0){ continue; } doSomething(); } 选择器模型 Java的NIO（New I/O）类库提供了选择器模型，它支持同时管理多个I/O操作。在该模型下，可以使用一个线程同时管理多个通道，每个通道上可以注册多个I/O操作，并且可以检查这些操作是否已经准备好或者完成。主要对应的系统I/O模型是Linux系统中的epoll模型和FreeBSD系统中的kqueue模型 这个主要是java各种Nio包里的非Async开头的channel实现的 异步I/O模型 Java的AIO（Asynchronous I/O）类库提供了异步I/O模型，它支持在I/O操作完成时通知应用程序。在该模型下，可以异步地提交I/O操作，I/O操作的完成时会通过回调函数通知应用程序。主要对应的系统I/O模型是Windows系统中的I/O Completion Port模型 这个主要是在各种Asynchronous***Channel实现 注: Java的I/O类库是跨平台的，因此在不同的操作系统上可能使用不同的底层系统I/O模型 例如，在Linux上使用Java的I/O类库默认会使用epoll模型，在Windows上则会使用I/O Completion Port模型 系统各个I/O模型对应的函数 不同的操作系统实现I/O模型的方式可能不同，因此每种I/O模型对应的系统函数也会有所不同。下面是常见的操作系统中，各个I/O模型对应的系统函数： 阻塞式I/O模型 Linux/Unix: read(), write() Windows: ReadFile(), WriteFile() 非阻塞式I/O模型 Linux/Unix: fcntl() 或 ioctl()，也可以使用select()或poll()函数 Windows: ioctlsocket()，也可以使用select()或WSAPoll()函数 选择器模型 Linux/Unix: epoll_wait() 或者 select() Windows: select() 或者 WSAEventSelect() 异步I/O模型 Linux/Unix: io_submit() 或者 aio_read() Windows: WSASend() 或者 WSARecv() 需要注意的是，Java的I/O类库是跨平台的，因此它使用的系统函数可能会因操作系统而异 Java的I/O类库是建立在底层系统I/O模型之上的，因此它可以使用操作系统提供的任何I/O模型对应的函数来实现I/O操作","link":"/system/IO-model2.html"},{"title":"jstack定位线上问题","text":"jstack定位问题 出现死循环后，我们可以使用jstack命令来定位问题。 1. 查找JVM进程ID（pid=23199） 1`ps -ef | grep java` 2. 查找发生死循环的线程ID（threadId=23214），CPU利用率暴表的第一条记录就是了。将十进制23214转为十六进制5aae。 1`top -H -p 23199` 3. 使用jstack导出线程dump信息。 1`jstack -l 23199 &gt; ~/threaddump.txt` 4. 分析dump数据，查找CPU最高的线程的运行堆栈。可以看出，死循环发生在HashMap的put()方法。 1`cat threaddump.txt | grep -A10 5aae` 附：查看线程ID方法，windows工具下载地址 最后在Windows下揪出Java程序占用CPU很高的线程并找到问题代码，死循环线程代码","link":"/system/jstack-ding-wei-xian-shang-wen-ti.html"},{"title":"如何提高服务可用性","text":"如何提高服务可用性 [原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/system/how-to-improve-service-availability.html 低层次的说，大概有如下方法 容灾(lvs+keepalived等) 负载均衡+心跳 限流 熔断&amp;降级 重试 业务重试 框架切换节点重试等 监控+预警 业务上下游流量监控+接口流量监控 JVM等指标监控 指定日志监控 主动发送预警 (补充)解耦:动静分离/前后分离 归纳一下针对服务本身，其实也就4种类情况 单点故障 服务响应慢 服务超出自身的承载能力 故障发现与恢复？ 1. 单点故障 解决单点故障的其实比较『简单』，就是把单点给去掉，进行一定的『冗余+故障转移』处理。。。 比如把单点的服务部署多份，然后通过负载策略来分发请求，这样就可以避免单点故障了； （当然其实再怎么避免，最靠近用户侧的地方都会有个单点的，我们不讨论这种情况 没啥意义） 设备冗余（跨机房、多机房冗余） 应用冗余（集群化部署） 数据冗余（主从、多主、分片、缓存） 2. 服务响应慢 这里抛开代码层面，只考虑架构设计层面，代码层面无非就是减少操作步骤，进行异步处理、并行处理、集中批处理等等。。。 算了一起写吧 这里主要需要提高单机的吞吐量，也就是提高单机的性能，这里主要有两种方式： 单机吞吐量： 多级缓存: 减少非必要更新、查询、调用量 代码层面: 就是减少操作步骤，进行异步处理、并行处理、集中批处理等等 提高单机的性能: 比如增加CPU、内存、磁盘等等 提高集群吞吐量: 集群扩容: 增加应用/机器数量 3. 服务超出自身的承载能力 其实这里主要是服务治理相关的问题 限流(流量特大的时候一般用代理层限流，应用层一般用hystrix、sentinel等，其中前者为滑动窗口限流，后者基于漏洞实现，前者有流量突刺，后者稳流，个人认为后者应用起来比较贴合实际一些) 熔断&amp;降级 4. 故障发现与恢复 监控+预警 业务上下游流量监控、接口流量监控、P99、接口成功率监控等 JVM等指标监控 指定日志监控 主动发送预警","link":"/system/how-to-improve-service-availability.html"},{"title":"shell-系统优雅停机","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/system/system-graceful-shutdown.html 脚本 1234567891011#!/bin/bashecho &quot;请输入进程ID：&quot;read pidecho &quot;正在尝试使用kill -15终止进程$pid ...&quot;kill -15 $pidsleep 5 # 等待5秒，给进程清理和资源回收的时间if ps -p $pid &gt; /dev/null; then # 如果进程仍然存在，则使用kill -9进行强制终止 echo &quot;进程$pid 仍在运行，正在尝试使用kill -9强制终止 ...&quot; kill -9 $pidfiecho &quot;进程$pid 已终止&quot;","link":"/system/system-graceful-shutdown.html"},{"title":"跨域请求减少一半请求","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/web/Reduce-half-of-the-cross-domain-requests.html 简述 点很小，作用挺大，简单写写 客服系统重构后，前端对应的后端服务域名不在同一个（这里没有用nginx解决跨域问题），每次请求都会发送两次请求，一次是预检请求，一次是正式请求。 这样就会导致请求的次数增加一倍，这样就会影响到用户的体验，尤其是对网络不好、国外的用户访问体验带来沉重的打机，新版客服系统上线后叫苦连连。 解决方案 这个问题困扰了好些日子，前些天突然查到一个配置可以很很简单快捷的解决这个问题，这个配置是Access-Control-Max-Age 原理： 后端返回的Access-Control-Max-Age 大于浏览器支持的最大值 那么取浏览器最大值作为缓存时间 否则取后端返回的Access-Control-Max-Age作为缓存时间 缓存时间内不会再发option请求 点这源码 配置 后端对CorsConfiguration配置Access-Control-Max-Age，前端请求时接收到Access-Control-Max-Age，在该有效时间内不会再发出Option请求 CorsConfiguration config = new CorsConfiguration(); config.setMaxAge(3600L); 我们粗暴地设置了1个小时，一个小时内，相同URL请求不需要再发两个同步请求，减少了一半请求量，大幅提高了用户体验 吐槽 其实我一直吐槽用nginx反向代理解决跨域问题就好了，但是架构已定，大动还得经过领导层层审批，且基本不可能通过，所以在跨域问题上花费大量时间。。。","link":"/web/Reduce-half-of-the-cross-domain-requests.html"},{"title":"JVM内存结构-总纲","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/JVM/JVM-Memory-Structure-Menu.html 学习JVM的可以去我的GitHub 上查看我的Xmind详细笔记 对整本《深入理解JVM》都有详尽的笔记，帮助理解 前言 网上有不少描述JVM内存结构的文章，但是要么比较老久了，要么描述有误，今天根据自己的理解整理下，有误请指正。 整体图解 程序计数器 记录Java程序运行到哪里 线程私有，可以看做当前线程执行到哪行【字节码】 字节码解析器工作就是通过改变这个【计数器】来选择下一行要执行什么，分支、循环、线程恢复都依赖于它 若为Java方法，则记录当前执行的字节码指令地址； 若执行的是native方法，则为空 Java 虚拟机栈 描述java【方法】执行的【内存模型】 每个方法对应一个栈帧,在线程运行到该方法时才创建 一条线程拥有的栈帧之和最大为-Xss(我们这里把它叫做线程栈) 当前所有线程栈之和=当前Java虚拟机栈已用大小 Java虚拟机栈总空间最大值：JVM 可分配内存-堆最大值-其他空间最大值–&gt;剩下的作为栈的总空间最大值 详细可参考: java虚拟机栈的内存结构 栈帧结构(待填坑) Java虚拟机栈异常及其处理方案(待填坑) 本地方法栈 同虚拟机栈，区别在于：虚拟机栈服务于Java方法（字节码），本地方法栈服务于Native方法 堆 随JVM启动而创建，是虚拟机最大的一块内存，被所有线程共享 存放着对象与数组等一切new出来的对象 垃圾收集器主要管理的区域 还存放着常量池 (1.7及以后的版本,都移到堆里存储了,需要注意的地方比较多 后面会说 不在这里描述) 详细可参考我另外的这篇博客(待填坑) 字符串常量池 存放字符串常量池,不同JDK版本存放的内容不一样 **1. 怎样的String会被存到常量池 简单来说以下这些情况都会存入常量池: 直接使用双引号声明出来的String对象 调用intern()方法 这个可以参考这篇《深入解析String#intern》 何时存放String字符串也可以参考 String放入运行时常量池的时机与String.intern()方法解惑 2. 存储结构在不同JDK下的区别 JDK≤6 常量池存于方法区中 常量池里的内容全部为字符串具体的值 JDK≥7 常量池存于堆中来自官网原文:the string pool was relocated to the heap 存储的东西为字符串值或引用(引用堆里的值),具体可以参考美团的《深入解析String#intern》 3. String 加载进字符串常量池的方式/时机 首先要知道字符串常量池是位于运行时常量池中的 编译完刚启动: 加载String进字符串常量池的过程大致为： graph LR A[编译后的class文件中的class常量池] B[运行时常量池中的字符串常量池] A-->B; 运行期间 graph LR A[代码] B[运行时常量池中的字符串常量池] A-->B; 参考《常量池结构及其加载过程》 方法区(永久代) 存放类的结构：版本、常量、全局变量、静态变量、方法、接口、即JIT编译后的代码等信息（JDK8后完全移出方法区 可以参考:Java 8: From PermGen to Metaspace) 具体里面存了啥 可以参考 JVM虚拟机结构 (不在JVM里的)元数据区 JDK8开始,替代方法区的存在；很大程度的避免了因为类加载过多导致的\bOOM问题 实际上元数据区不属于JVM内存的一部分；其为本地内存的一部分；大小取决于\b开发人员配置或可用的本地内存大小 有一点必须注意的是： -XX:MetaspaceSize=128m 不是初始元空间大小,而是达到了128m后才会对该区域进行GC 初始化大小20.8m 默认MetaspaceSize也是20.8m","link":"/JVM/JVM-Memory-Structure-Menu.html"},{"title":"java虚拟机栈的内存结构","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/JVM/JVM-Memory-Structure-Stack.html 学习JVM的可以去我的GitHub 上查看我的Xmind详细笔记 对整本《深入理解JVM》都有详尽的笔记，帮助理解 一、 前言 Java栈分为两种： Java虚拟机栈： 描述java【方法】执行的【内存模型】 每个线程进入每个方法对应一个栈帧 本地方法栈(本文不做描述) 同虚拟机栈，区别在于：虚拟机栈服务于Java方法（字节码），本地方法栈服务于Native方法 本文主要讲Java虚拟机栈的内存结构 一图胜千言 二、Java虚拟机栈的组成： 1. 栈帧 每个方法对应一个栈帧，在线程运行到该方法时才创建，随着方法结束而销毁 2. 线程栈 栈帧内存在线程内存上进行分配，每条线程能为栈帧分配的总大小最大值为-Xss 为了方便，我们这里 [把这条线程对应的内存] 称为 [线程栈] 3. Java虚拟机栈 Java虚拟机栈是描述java【方法】执行的【内存模型】–&gt; 实际上它是 当前时刻[所有的线程栈]集合的统称 三、 Java虚拟机栈会出现的异常: 经过上面的描述，我们可以清晰地知道： 【Java虚拟机栈】由【当前所有的线程栈】组成 【每个线程栈由】由【这条线程所对应的所有栈帧】组成 因此，可能会出现2种内存溢出的情况 （也可参考Oracle JavaSE8的JVM规范：The Structure of the Java Virtual Machine-Java Virtual Machine Stacks） [x] 线程栈溢出(Stack Overflow)： 某条线程对应的栈帧内存之和 超过线程栈内存的最大值-Xss 根据栈帧的定义可以理解到：该问题主要是一条线程在某一时间点同时存在于多个方法中（网上称作方法深度过深，最常见的案例就是递归调用） [x] 从Java虚拟机栈层面溢出(OOM)： 当前时刻[所有的线程栈]内存之和 超过 Java虚拟机栈所允许的最大值 导致这个问题的原因是当前新建的线程数太多(当然,换句话也以说是当前计算机可分配给Java虚拟机的空间太少) 每条线程占用的空间都未-Xss，新建多了也就OOM了；这种情况一般较少发生，主要有以下因素： 系统对线程数上限的限制 线程过多，会导致CPU崩溃，也就是说系统早就挂了 Java虚拟机栈所允许的最大值：JVM 可分配内存-其他JVM内存结构空间最大值(主要是堆)–&gt;剩下的作为栈的总空间最大值(来自《深入理解Java虚拟机》P54) 四、验证 4.1. 线程栈溢出（StackOverFlow） 通过-Xss调整线程栈大小测试[线程栈最大占用内存为-Xss] 1234567891011121314151617181920212223242526272829private static AtomicLong i = new AtomicLong(0);public static void main(String[] args) throws InterruptedException { //1. 测试错误StackOverFlow testStackOverFlow(); //2.测试错误OOM //testOOM();}/** * StackOverFlow每次深度不一样是因为JIT优化 * -Djava.compiler=NONE禁用JIT优化后每次深度一样 * * * 测试参数：-Xss256k*/private static void testStackOverFlow() { //new Thread(() -&gt; { StackErrorTest testData = new StackErrorTest(); try { testData.test1(); } catch (Throwable e) { System.out.println(Thread.currentThread().getName() + &quot; &quot; + i.get()); } //}).start();} 运行参数设置-Xss256k -Djava.compiler=NONE,多次运行输出结果一致: 1main 1882 运行参数设置-Xss512k -Djava.compiler=NONE,多次运行输出结果一致: 1main 4861 2.2.2 从Java虚拟机栈溢出（OOM） 注意 Mac有单进程线程数量限制,16G的Mac电脑限制为5000,修改方式参考(不好意思 不能修改 ) 在一些配置较低的电脑可能会死机，请小心运行 建议使用虚拟机运行 影响因素 描述 系统限制 系统允许进程的最大线程数 -Xss 每条线程栈占用的内存 -Xmx 堆空间最大值 详细验证可以参考这篇文章 ---","link":"/JVM/JVM-Memory-Structure-Stack.html"},{"title":"垃圾回收器选型","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/JVM/jvm-gc.html 总揽 吞吐量和最短停顿时间本来就互相矛盾 Parallel Old追求的是吞吐量，CMS追求的是STW的最短 而G1通过把堆分成多个相对独立的Region块，并行的进行选择性的回收，实现一个两者兼顾的回收器 Parallel GC： 适用于吞吐量优先的场景 原理: 通过参数-XX:GCTimeRatio 设置垃圾回收时间占总时间的比例，默认值为99，即垃圾回收时间不超过1%，实现吞吐量优先 CMS（Concurrent Mark Sweep）GC： 适用于响应时间优先的场景 原理1：通过-XX:CMSInitiatingOccupancyFraction预留空间实现一边回收垃圾，一边执行业务逻辑，实现响应时间优先 原理2：通过并发标记等，实现尽可能低的停顿 缺点1: 内存使用率低，为了一边干活一边回收垃圾，预留了一定的内存 缺点2：产生碎片，虽然FullGC时候，但是运行期间会产生大量碎片 （新增）G1（Garbage First）GC： 适用于大堆内存场景，通过Region分区,既实现超短GC暂停时间，同时保证吞吐量 原理1:通过Region分区+预测模型,优先回收垃圾最多的Region，实现可控制时间的超短GC暂停时间 原理2：使用复制算法，没有碎片 缺点1: 内存使用率低，因为新生代与老年代都用了复制算法，需要预留一定的内存 缺点2: GC效率低，每次都为不完全GC 缺点2: 默认内存使用45%开始FullGC （新增）什么时候使用G1 G1 的第一个重点是为运行需要大堆且 GC 延迟有限的应用程序的用户提供解决方案 非官方提示大约 6GB 或更大的堆大小，以及低于 0.5 秒的稳定且可预测的暂停时间选择G1 如果应用程序具有以下一个或多个特征，则现在使用 CMS 或 ParallelOldGC 垃圾收集器运行的应用程序将受益于切换到 G1。 Full GC 持续时间太长或太频繁。 对象分配率或提升率差异很大 不需要的长时间垃圾收集或压缩暂停（超过 0.5 到 1 秒） 附录1.现有系统垃圾回收器选型 admin（-Xmx8g -Xms8g）服务于前端，提供实时同步的http接口，注重高效响应，当前使用的是默认的Parallel GC，应该考虑使用CMS G1回收器，并限制最大停顿时间&lt;20 Cache（-Xmx4g -Xms4g）不单独提供服务，主要负责数据消费与写入，注重吞吐量，当前使用的是CMS，不妥，应考虑使用Parallel GC Report（-Xmx5g -Xms5g）,主要报表异步导出，注重吞吐量，当前使用的是G1，其实用Parallel GC可能也差不多 Order：(Xmx4G -Xms4G)，G1回收器，注重吞吐量，或许Parallel也是个很好的选择 Operation：(Xmx12G -Xms12G) 想说G1回收器没跑了，目前也是用的这个，但作为数据消费者与生产者其实基本不怎么GC，其业务只注重吞吐量，其实或许Parallel也是个很好的选择，但这是个坑，因为这可能导致超长停顿，让与中间件等服务器之间的连接超时，出现故障 附录2:","link":"/JVM/jvm-gc.html"},{"title":"深入理解Java虚拟机-阅读整理","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/JVM/JVM-Xmind.html 看完《深入理解Java虚拟机》了(好像是教这个名字吧😂)，花了小几个月边看边整理，终于呕心沥血地整理完的，书籍作者基于jdk7写的，加入分析对比了一些jdk8的新特性，以及官方文献的引用，因为JVM还是比较底层灰色，难免有些地方可能有误，欢迎指正。 图片很大，需要放大看，实在看不清，可以去github上自取源Xmind文件:点这里跳转 （有一章类结构偷懒没看，自我感觉用处不是很大）","link":"/JVM/JVM-Xmind.html"},{"title":"报表JVM调优","text":"[原创]个人理解，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/JVM/report-jvm-optimize.html 忘记记录了。。凭记忆记录下😂，下面是大概流程 背景 之前上线的一个新报表项目，我们的报表服务主要通过定时任务异步生成报表，报表比较大，每次运行时长长，实时性要求较低。 但在生产环境普罗米修斯监控中，发现服务频繁进行GC，且GC前后释放的内存不多，GC期间CPU占用略高。但是GC时长看着很短，为了解决这个问题，我进行了一次针对报表服务的JVM调优 过程 1. 看监控 使用Prometheus监控JVM指标，并结合Grafana进行数据可视化。通过Prometheus收集报表服务的JVM指标，如GC情况、内存使用、线程状态等 发现回收间隔时间较短，且回收前后大部分时候释放的内存不是特别多，但有时候却特别多，看了下GC配置，G1+默认200ms的回收间隔，估计是这个时间间隔搞个鬼，不太适合我们的业务场景（报表比较大，每次运行时长长）。 2. jstat确认GC前后内存变化 1jstat -gc 12345 1000 10 样例： S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 68224.0 68224.0 0.0 34080.7 272896.0 272896.0 68224.0 68224.0 68224.0 27327.0 34080.7 10258.0 20 0.269 2 0.044 0.313 68224.0 68224.0 0.0 34080.7 272896.0 272896.0 68224.0 68224.0 68224.0 27327.0 34080.7 10258.0 20 0.269 2 0.044 0.313 结果发现 每次老年代回收率较高，报表服务的对象不该存放在老年代，应该调整到新生代 GC时间较短，我们用的是G1回收器，所以认为其实每次都不能很好的回收足够的内存，导致频繁的GC 3. jmap确认内存占用 1jmap -dump:format=b,file=heapdump.hprof 12345 因为当前服务实时性与可用性要求不是特别高，直接打dump问题不大； 但如果是实时性要求较高的服务，可以使用jmap -histo:live 12345查看内存占用情况，然后再决定是否打dump： 12jmap -histo:live 12345 | sort -n -r -k 2 | head -10 # 类实例实例数前10jmap -histo:live 12345 | sort -n -r -k 3 | head -10 #类实例总大小前10 4. MAT分析dump 使用MAT（Memory Analyzer Tool）分析heap dump，找出内存中的大对象以及引用关系 结合源码，发现在处理历史巴枪数据导出大任务报表时，查询的是Hbase，因为业务关系，后端没有进行分段查询，前端也没有做太多限制，前端用户贪方便，直接把网点近3个月的巴枪数据一口气导出来了，后端接受请求把数据一口气都查询出来了，然后单个任务写入报表也创建了大量的临时对象，在多个任务运行时很容易触发GC，GC后又不能有效释放这些内存，导致频繁GC。 5. 做出的调整 其实这个问题就是因为GC频繁，以及新生代对象过快晋升导致的；解决就相对简单了： 调整G1的暂停时间目标（-XX:MaxGCPauseMillis=500，默认200） 2. 调整新生代晋升阈值（-XX:MaxTenuringThreshold=20，默认15） 本来想调整这个参数,但是从对象头决定了该参数最大值就是15(4个byte),无法调整哦…调整MaxGCPauseMillis就行了,G1回收器会自动调整新生代与老年代比例，如果后期还不行，可以考虑调整G1ReservePercent参数（老年代会预留的空间来给新生代的对象晋升，默认10%） 调整业务限制，该巴枪扫描业务单次查询数量限制30天内，业务代码内进行7天一段分段查询，单次查询数据量限制在10w内，以防单次处理量过大，消耗大量内存 habse工具类调整，查询habse单次限制在10w，业务调用时按需扩大、缩小，以防再次出现类似问题 新生代与老年代稳妥起见的比例暂不调整，因为该服务还加在了大量本地缓存等，理论上老年代还是相对要比较大一点的 除此以外，其实把垃圾回收器换成Parallel GC可能会更好，但是考虑到系统迭代会有更多的报表任务需要处理，以后内存可能还要逐步加，对大内存来说，还是先继续用G1吧 6. 效果 通过以上调优措施，报表服务的老年代回收率得到了有效改善，频繁GC现象得到缓解，进而提升了服务的性能和稳定性。 7. 其他顺手优化 巡检了一下，Cache服务（-Xmx4g -Xms4g）不单独提供服务，主要负责数据消费与写入，注重吞吐量，对停顿几乎无要求，当前使用的是CMS，同时也因为预留空间的特性浪费内存；不妥，正式改用Parallel GC。 优化后，通过jstat -gc 12345 1000 10查看老年代的使用率能打满，合理。 8. 其他参考记录 不要手动设置新生代和老年代的大小，只设置堆的大小 G1收集器在运行过程中，会自己调整新生代和老年代的大小，如果手动设置了大小就意味着放弃了G1的自动调优 主要调优目标：MaxGCPauseMillis 默认值为200ms，如果暂停时间设置的太短，就会导致出现G1跟不上垃圾产生的速度，最终退化成Full GC MixedGC调优 -XX:InitiatingHeapOccupancyPercent 通过-XX:InitiatingHeapOccupancyPercent指定触发全局并发标记的老年代使用占比，默认值45%，也就是老年代占堆的比例超过45%。如果Mixed GC周期结束后老年代使用率还是超过45%,那么会再次触发全局并发标记过程，这样就会导致频繁的老年代GC，影响应用吞吐量。同时老年代空间不大，Mixed GC回收的空间肯定是偏少的。可以适当调高IHOP的值，当然如果此值太高，很容易导致年轻代晋升失败而触发Full GC，所以需要多次调整测试 -XX:G1MixedGCLiveThresholdPercent 通过-XX:G1MixedGCLiveThresholdPercent指定被纳入Cset的Region的存活空间占比阈值，不同版本默认值不同，有65%和85%。在全局并发标记阶段，如果一个Region的存活对象的空间占比低于此值，则会被纳入Cset。此值直接影响到Mixed GC选择回收的区域，当发现GC时间较长时，可以尝试调低此阈值，尽量优先选择回收垃圾占比高的Region，但此举也可能导致垃圾回收的不够彻底，最终触发Full GC 附录：优化前系统垃圾回收器选型 admin（-Xmx8g -Xms8g）服务于前端，提供实时同步的http接口，注重高效响应，当前使用的是默认的Parallel GC，应该考虑使用CMS G1回收器，并限制最大停顿时间&lt;20 Cache（-Xmx4g -Xms4g）不单独提供服务，主要负责数据消费与写入，注重吞吐量，当前使用的是CMS，不妥，应考虑使用Parallel GC Report（-Xmx5g -Xms5g）,主要报表异步导出，注重吞吐量，当前使用的是G1，其实用Parallel GC可能也差不多 Order：(Xmx4G -Xms4G)，G1回收器，注重吞吐量，或许Parallel也是个很好的选择 Operation：(Xmx12G -Xms12G) 想说G1回收器没跑了，目前也是用的这个，但作为数据消费者与生产者其实基本不怎么GC，其业务只注重吞吐量，其实或许Parallel也是个很好的选择，但这是个坑，因为这可能导致超长停顿，让与中间件等服务器之间的连接超时，出现故障","link":"/JVM/report-jvm-optimize.html"},{"title":"微博Feed流读扩散设计","text":"参考主要来自58沈剑← [知识整理]根据个人理解整理后分享，请批判接受，有误请指正。转载请注明出处: https://heyfl.gitee.io/design/Weibo-feed-design.html 什么是Feed流 Feed流即持续更新并呈现给用户内容的信息流 , 对于微博.微信朋友圈等业务刷新的数据都为Feed流 每条微博 朋友圈 为一条Feed 关键动作,关键数据 关键动作 关注 , 取关 发布Feed(朋友圈or微博) 获取自己主页的Feed流 核心数据 关系数据 Feed数据 难点 自己的主页由他人的Feed流组成 如果大家都是读写同一条Feed,会出现较大的读写冲突 造成系统的主要瓶颈 获取Feed流解决方案 模式有2种类: 拉模式 推模式 拉取模式 大致的数据结构 用户关系 用户的关注关系 user_follow(id,uid,follow_id…) 用户的粉丝关系 user_fans(id,uid,fans_id) //之所以要分成正反表是为了大数据量高并发情况下 可以做到分库 用户的消息列表(Feed) 用户发出的消息 user_msg(msg_id,uid,create_tm…) 流程 消息发布流程 用户A发出消息,只需要在[user_msg]表里插入一条消息 关注&amp;取关流程 以用户A取消关注用户B为例: 在A的关注列表里 删除B的记录 在B的粉丝列表里 删除A的记录 这里关注表和粉丝表不在同个库 但是不需要用到分布式事务, 用最终一致性就可以保证业务需求了 获取用户A主页的Feed流流程 [拉列表]获取用户A的所有的关注列表followList [通过列表再拉列表]遍历followList,获取所有被关注人发的所有消息的集合msgList (当然 这里得limit一下) [汇总排序]对每个msgList进行汇总排序 (这里可以利用最大堆把2,3合在一起) 优点： 存储结构简单，数据存储量较小，关系数据与feed数据都只存一份 取消关注，发布feed的业务流程非常简单 存储结构，业务流程都比较容易理解，非常适合项目早期用户量、数据量、并发量不大时的快速实现 缺点： 拉取朋友圈feed流列表的业务流程非常复杂 有多次数据访问，并且要进行大量的内存计算，大量数据的网络传输，性能较低 在拉模式中，系统的瓶颈容易出现在“用户所发布feed列表”的读取上，而每个用户发布feed的频率其实是很低的; 此时，架构优化的核心是通过缓存降低数据存储磁盘IO","link":"/design/Weibo-feed-design.html"}],"tags":[{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"优化","slug":"优化","link":"/tags/%E4%BC%98%E5%8C%96/"},{"name":"架构设计","slug":"架构设计","link":"/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"},{"name":"ElasticSearch","slug":"ElasticSearch","link":"/tags/ElasticSearch/"},{"name":"BUG","slug":"BUG","link":"/tags/BUG/"},{"name":"JAVA","slug":"JAVA","link":"/tags/JAVA/"},{"name":"Spring-Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"},{"name":"Consul","slug":"Consul","link":"/tags/Consul/"},{"name":"MYSQL","slug":"MYSQL","link":"/tags/MYSQL/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Kafka","slug":"Kafka","link":"/tags/Kafka/"},{"name":"知识点整理","slug":"知识点整理","link":"/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/"},{"name":"MQ","slug":"MQ","link":"/tags/MQ/"},{"name":"每天进步一点点","slug":"每天进步一点点","link":"/tags/%E6%AF%8F%E5%A4%A9%E8%BF%9B%E6%AD%A5%E4%B8%80%E7%82%B9%E7%82%B9/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"白板","slug":"白板","link":"/tags/%E7%99%BD%E6%9D%BF/"},{"name":"Mybatis","slug":"Mybatis","link":"/tags/Mybatis/"},{"name":"Code-Rule","slug":"Code-Rule","link":"/tags/Code-Rule/"},{"name":"DATABASE","slug":"DATABASE","link":"/tags/DATABASE/"},{"name":"LOCK","slug":"LOCK","link":"/tags/LOCK/"},{"name":"MYCAT","slug":"MYCAT","link":"/tags/MYCAT/"},{"name":"Hystrix","slug":"Hystrix","link":"/tags/Hystrix/"},{"name":"KAFKA","slug":"KAFKA","link":"/tags/KAFKA/"},{"name":"Hbase","slug":"Hbase","link":"/tags/Hbase/"},{"name":"REDIS","slug":"REDIS","link":"/tags/REDIS/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"部署","slug":"部署","link":"/tags/%E9%83%A8%E7%BD%B2/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"zookeeper","slug":"zookeeper","link":"/tags/zookeeper/"},{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"高并发","slug":"高并发","link":"/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"name":"idea","slug":"idea","link":"/tags/idea/"},{"name":"基础","slug":"基础","link":"/tags/%E5%9F%BA%E7%A1%80/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"redis集群","slug":"redis集群","link":"/tags/redis%E9%9B%86%E7%BE%A4/"},{"name":"SYSTEM","slug":"SYSTEM","link":"/tags/SYSTEM/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"JVM内存结构","slug":"JVM内存结构","link":"/tags/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"},{"name":"读后感","slug":"读后感","link":"/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"}],"categories":[{"name":"about","slug":"about","link":"/categories/about/"},{"name":"bookmarks","slug":"bookmarks","link":"/categories/bookmarks/"},{"name":"部署","slug":"部署","link":"/categories/%E9%83%A8%E7%BD%B2/"},{"name":"docker","slug":"部署/docker","link":"/categories/%E9%83%A8%E7%BD%B2/docker/"},{"name":"zookeeper","slug":"部署/docker/zookeeper","link":"/categories/%E9%83%A8%E7%BD%B2/docker/zookeeper/"},{"name":"redis","slug":"部署/docker/redis","link":"/categories/%E9%83%A8%E7%BD%B2/docker/redis/"},{"name":"redis","slug":"redis","link":"/categories/redis/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"Bug-Log&amp;Optimization","slug":"Bug-Log-Optimization","link":"/categories/Bug-Log-Optimization/"},{"name":"MQ","slug":"MQ","link":"/categories/MQ/"},{"name":"Make-A-Little-Progress-Every-Day","slug":"Make-A-Little-Progress-Every-Day","link":"/categories/Make-A-Little-Progress-Every-Day/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"code-rules","slug":"code-rules","link":"/categories/code-rules/"},{"name":"Distributed","slug":"Distributed","link":"/categories/Distributed/"},{"name":"database","slug":"database","link":"/categories/database/"},{"name":"design","slug":"design","link":"/categories/design/"},{"name":"dubbo","slug":"dubbo","link":"/categories/dubbo/"},{"name":"framework-design","slug":"framework-design","link":"/categories/framework-design/"},{"name":"idea","slug":"idea","link":"/categories/idea/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"system","slug":"system","link":"/categories/system/"},{"name":"web","slug":"web","link":"/categories/web/"}],"pages":[]}